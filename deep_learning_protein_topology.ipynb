{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "deep_learning_protein_topology.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IvstU4gdcNTjnTIKVQALRqMHT_e22xCq",
      "authorship_tag": "ABX9TyNcRb+hr92AEe276FwVsZzz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maduprey/DelayExplore/blob/master/deep_learning_protein_topology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3qznmgak2XM"
      },
      "source": [
        "# Deep Learning Protein Topology\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N00qk9k07QHN"
      },
      "source": [
        "What is being done in the [Frontiers](https://www.frontiersin.org/articles/10.3389/frai.2021.681174/full) paper is building several binary classifiers -- 55 to be exact -- in which each predicts whether all the proteins are either, for example, a.3.1 or not.\n",
        "\n",
        "Improvements to MLP accuracy\n",
        "*   Increased `n_perm`, the number of points to subsample, to 1,000, for 5% gain, 40% total; Increased to 2,000 and saw decrease (surprisingly). Now using 1,300 (about median) seems decent, but not sure if better/worse\n",
        "*   Using only $H_1$ and $H_2$ increased by about 2.5% to a point, and then overfit\n",
        "*   Increased the number of epochs from 800 to 1,000 resulted in increased accuracy without much overfitting: 42% total\n",
        "*   A learning rate (Adam opt) of 0.001 seems to hit the sweet spot (tried 0.01 and 0.001 with suboptimal results)\n",
        "*   No meaningful difference between NAdam and Adam optimizers\n",
        "*   Changed persistence parameters `thresh`, `globalmaxdeath`, `meshstop` from 10 to 20, didn't see any improvement\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKuId4wiAfxg"
      },
      "source": [
        "!pip install -q git+https://github.com/azlawson/PersistenceCurves.git\n",
        "!pip install -q biopython\n",
        "!pip install -q py3Dmol\n",
        "!pip install -q scikit-tda"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5yvkkN3AJ7o"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import persistencecurves as pc\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import py3Dmol\n",
        "import random\n",
        "\n",
        "from xgboost import XGBClassifier # Might not need\n",
        "from lightgbm import LGBMClassifier # Might not need\n",
        "from Bio.PDB import PDBParser\n",
        "from ripser import ripser\n",
        "from persim import plot_diagrams\n",
        "from sklearn.preprocessing import OneHotEncoder, label_binarize\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoPkRMLYA06C"
      },
      "source": [
        "parser = PDBParser(PERMISSIVE=1, QUIET=True)\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/data')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7_yBNwsXLFN"
      },
      "source": [
        "## Exploratory analysis\n",
        "Let's look at the number of coordinates to determine how we might want to set Ripster's [n_perm](https://ripser.scikit-tda.org/en/latest/reference/stubs/ripser.ripser.html#ripser.ripser) parameter which controls the number of points to subsample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkIJAOzLaRk8"
      },
      "source": [
        "# Inspect the number of coordinates\n",
        "n_atoms = np.empty((0, 1), int)\n",
        "for file in os.listdir(\"./SCOP40mini\"):\n",
        "    structure_id = os.path.splitext(file)[0]\n",
        "    structure = parser.get_structure(structure_id, \"./SCOP40mini/\" + file)\n",
        "    \n",
        "    # Generate a list of its atoms' coordinates in R^3\n",
        "    coords = []\n",
        "    for atom in structure.get_atoms():\n",
        "        coords.append(list(atom.get_vector()))\n",
        "    coords = np.array(coords)\n",
        "\n",
        "    n_atoms = np.append(n_atoms, len(coords))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "3fIoqh2HbYfr",
        "outputId": "134f2ae1-ce81-4ee5-f382-7978285258c3"
      },
      "source": [
        "# Histogram\n",
        "plt.hist(n_atoms, bins=50)\n",
        "plt.show()\n",
        "\n",
        "# Boxplot omitting outliers\n",
        "plt.boxplot(n_atoms, showfliers=False, vert=0)\n",
        "plt.show()\n",
        "\n",
        "print(np.median(n_atoms))\n",
        "print(np.mean(n_atoms))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1379.0\n",
            "3071.304347826087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUf0YBNgBsWo"
      },
      "source": [
        "## Generate persistence diagrams\n",
        "This loop is rather time-intensive. We can alternatively load saved diagrams below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3KmSlPUFXQq",
        "outputId": "3cea3de5-3c1f-4cc4-a095-4b6f2f7f707f"
      },
      "source": [
        "# diagrams = np.empty((0, 200), int) # Use if computing only H_0, H_1\n",
        "diagrams = np.empty((0, 300), int) # Use if computing H_0, H_1, and H_2\n",
        "classes_fold = np.empty((0, 1), str)\n",
        "classes_superfamily = np.empty((0, 1), str)\n",
        "classes_family = np.empty((0, 1), str)\n",
        "\n",
        "for file in os.listdir(\"./SCOP40mini\"):\n",
        "    structure_id = os.path.splitext(file)[0]\n",
        "    structure = parser.get_structure(structure_id, \"./SCOP40mini/\" + file)\n",
        "    \n",
        "    # We grab the SCOP sccs to build the classes\n",
        "    sccs = parser.get_header()['astral']['SCOP-sccs']\n",
        "    fold = sccs.rsplit('.', 2)[0]\n",
        "    superfamily = sccs.rsplit('.', 1)[0]\n",
        "    family = sccs\n",
        "    \n",
        "    # Generate a list of its atoms' coordinates in R^3\n",
        "    coords = []\n",
        "    for atom in structure.get_atoms():\n",
        "        coords.append(list(atom.get_vector()))\n",
        "    coords = np.array(coords)\n",
        "    \n",
        "    # Compute persistent homology\n",
        "    # We roughly use the median number of atoms to set the subsampling threshold \n",
        "    if len(coords) > 1300:\n",
        "        diagram = ripser(coords, maxdim=2, thresh=10, do_cocycles=False, n_perm=1300)['dgms']\n",
        "    else:\n",
        "        diagram = ripser(coords, maxdim=2, thresh=10, do_cocycles=False)['dgms']\n",
        "\n",
        "    # Generate persistence curves from diagrams\n",
        "    # TODO: does remove vs replace make big impact?\n",
        "    d_h0 = pc.Diagram(Dgm=diagram[0], globalmaxdeath=10, inf_policy='remove')\n",
        "    d_h1 = pc.Diagram(Dgm=diagram[1], globalmaxdeath=10, inf_policy='remove')\n",
        "    d_h2 = pc.Diagram(Dgm=diagram[2], globalmaxdeath=10, inf_policy='remove')\n",
        "\n",
        "    # Generate life curves\n",
        "    # TODO: investigate different types of curves, different resolutions\n",
        "    # trying fewer in mesh\n",
        "    lc_h0 = d_h0.lifecurve(meshstart=0, meshstop=10, num_in_mesh=100)\n",
        "    lc_h1 = d_h1.lifecurve(meshstart=0, meshstop=10, num_in_mesh=100)\n",
        "    lc_h2 = d_h2.lifecurve(meshstart=0, meshstop=10, num_in_mesh=100)\n",
        "\n",
        "    # Join life curves together\n",
        "    lc_all = np.concatenate((lc_h0, lc_h1, lc_h2))\n",
        "    \n",
        "    diagrams = np.vstack((diagrams, lc_all))\n",
        "    classes_fold = np.vstack((classes_fold, fold))\n",
        "    classes_superfamily = np.vstack((classes_superfamily, superfamily))\n",
        "    classes_family = np.vstack((classes_family, family))\n",
        "\n",
        "    print(diagrams.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 300)\n",
            "(2, 300)\n",
            "(3, 300)\n",
            "(4, 300)\n",
            "(5, 300)\n",
            "(6, 300)\n",
            "(7, 300)\n",
            "(8, 300)\n",
            "(9, 300)\n",
            "(10, 300)\n",
            "(11, 300)\n",
            "(12, 300)\n",
            "(13, 300)\n",
            "(14, 300)\n",
            "(15, 300)\n",
            "(16, 300)\n",
            "(17, 300)\n",
            "(18, 300)\n",
            "(19, 300)\n",
            "(20, 300)\n",
            "(21, 300)\n",
            "(22, 300)\n",
            "(23, 300)\n",
            "(24, 300)\n",
            "(25, 300)\n",
            "(26, 300)\n",
            "(27, 300)\n",
            "(28, 300)\n",
            "(29, 300)\n",
            "(30, 300)\n",
            "(31, 300)\n",
            "(32, 300)\n",
            "(33, 300)\n",
            "(34, 300)\n",
            "(35, 300)\n",
            "(36, 300)\n",
            "(37, 300)\n",
            "(38, 300)\n",
            "(39, 300)\n",
            "(40, 300)\n",
            "(41, 300)\n",
            "(42, 300)\n",
            "(43, 300)\n",
            "(44, 300)\n",
            "(45, 300)\n",
            "(46, 300)\n",
            "(47, 300)\n",
            "(48, 300)\n",
            "(49, 300)\n",
            "(50, 300)\n",
            "(51, 300)\n",
            "(52, 300)\n",
            "(53, 300)\n",
            "(54, 300)\n",
            "(55, 300)\n",
            "(56, 300)\n",
            "(57, 300)\n",
            "(58, 300)\n",
            "(59, 300)\n",
            "(60, 300)\n",
            "(61, 300)\n",
            "(62, 300)\n",
            "(63, 300)\n",
            "(64, 300)\n",
            "(65, 300)\n",
            "(66, 300)\n",
            "(67, 300)\n",
            "(68, 300)\n",
            "(69, 300)\n",
            "(70, 300)\n",
            "(71, 300)\n",
            "(72, 300)\n",
            "(73, 300)\n",
            "(74, 300)\n",
            "(75, 300)\n",
            "(76, 300)\n",
            "(77, 300)\n",
            "(78, 300)\n",
            "(79, 300)\n",
            "(80, 300)\n",
            "(81, 300)\n",
            "(82, 300)\n",
            "(83, 300)\n",
            "(84, 300)\n",
            "(85, 300)\n",
            "(86, 300)\n",
            "(87, 300)\n",
            "(88, 300)\n",
            "(89, 300)\n",
            "(90, 300)\n",
            "(91, 300)\n",
            "(92, 300)\n",
            "(93, 300)\n",
            "(94, 300)\n",
            "(95, 300)\n",
            "(96, 300)\n",
            "(97, 300)\n",
            "(98, 300)\n",
            "(99, 300)\n",
            "(100, 300)\n",
            "(101, 300)\n",
            "(102, 300)\n",
            "(103, 300)\n",
            "(104, 300)\n",
            "(105, 300)\n",
            "(106, 300)\n",
            "(107, 300)\n",
            "(108, 300)\n",
            "(109, 300)\n",
            "(110, 300)\n",
            "(111, 300)\n",
            "(112, 300)\n",
            "(113, 300)\n",
            "(114, 300)\n",
            "(115, 300)\n",
            "(116, 300)\n",
            "(117, 300)\n",
            "(118, 300)\n",
            "(119, 300)\n",
            "(120, 300)\n",
            "(121, 300)\n",
            "(122, 300)\n",
            "(123, 300)\n",
            "(124, 300)\n",
            "(125, 300)\n",
            "(126, 300)\n",
            "(127, 300)\n",
            "(128, 300)\n",
            "(129, 300)\n",
            "(130, 300)\n",
            "(131, 300)\n",
            "(132, 300)\n",
            "(133, 300)\n",
            "(134, 300)\n",
            "(135, 300)\n",
            "(136, 300)\n",
            "(137, 300)\n",
            "(138, 300)\n",
            "(139, 300)\n",
            "(140, 300)\n",
            "(141, 300)\n",
            "(142, 300)\n",
            "(143, 300)\n",
            "(144, 300)\n",
            "(145, 300)\n",
            "(146, 300)\n",
            "(147, 300)\n",
            "(148, 300)\n",
            "(149, 300)\n",
            "(150, 300)\n",
            "(151, 300)\n",
            "(152, 300)\n",
            "(153, 300)\n",
            "(154, 300)\n",
            "(155, 300)\n",
            "(156, 300)\n",
            "(157, 300)\n",
            "(158, 300)\n",
            "(159, 300)\n",
            "(160, 300)\n",
            "(161, 300)\n",
            "(162, 300)\n",
            "(163, 300)\n",
            "(164, 300)\n",
            "(165, 300)\n",
            "(166, 300)\n",
            "(167, 300)\n",
            "(168, 300)\n",
            "(169, 300)\n",
            "(170, 300)\n",
            "(171, 300)\n",
            "(172, 300)\n",
            "(173, 300)\n",
            "(174, 300)\n",
            "(175, 300)\n",
            "(176, 300)\n",
            "(177, 300)\n",
            "(178, 300)\n",
            "(179, 300)\n",
            "(180, 300)\n",
            "(181, 300)\n",
            "(182, 300)\n",
            "(183, 300)\n",
            "(184, 300)\n",
            "(185, 300)\n",
            "(186, 300)\n",
            "(187, 300)\n",
            "(188, 300)\n",
            "(189, 300)\n",
            "(190, 300)\n",
            "(191, 300)\n",
            "(192, 300)\n",
            "(193, 300)\n",
            "(194, 300)\n",
            "(195, 300)\n",
            "(196, 300)\n",
            "(197, 300)\n",
            "(198, 300)\n",
            "(199, 300)\n",
            "(200, 300)\n",
            "(201, 300)\n",
            "(202, 300)\n",
            "(203, 300)\n",
            "(204, 300)\n",
            "(205, 300)\n",
            "(206, 300)\n",
            "(207, 300)\n",
            "(208, 300)\n",
            "(209, 300)\n",
            "(210, 300)\n",
            "(211, 300)\n",
            "(212, 300)\n",
            "(213, 300)\n",
            "(214, 300)\n",
            "(215, 300)\n",
            "(216, 300)\n",
            "(217, 300)\n",
            "(218, 300)\n",
            "(219, 300)\n",
            "(220, 300)\n",
            "(221, 300)\n",
            "(222, 300)\n",
            "(223, 300)\n",
            "(224, 300)\n",
            "(225, 300)\n",
            "(226, 300)\n",
            "(227, 300)\n",
            "(228, 300)\n",
            "(229, 300)\n",
            "(230, 300)\n",
            "(231, 300)\n",
            "(232, 300)\n",
            "(233, 300)\n",
            "(234, 300)\n",
            "(235, 300)\n",
            "(236, 300)\n",
            "(237, 300)\n",
            "(238, 300)\n",
            "(239, 300)\n",
            "(240, 300)\n",
            "(241, 300)\n",
            "(242, 300)\n",
            "(243, 300)\n",
            "(244, 300)\n",
            "(245, 300)\n",
            "(246, 300)\n",
            "(247, 300)\n",
            "(248, 300)\n",
            "(249, 300)\n",
            "(250, 300)\n",
            "(251, 300)\n",
            "(252, 300)\n",
            "(253, 300)\n",
            "(254, 300)\n",
            "(255, 300)\n",
            "(256, 300)\n",
            "(257, 300)\n",
            "(258, 300)\n",
            "(259, 300)\n",
            "(260, 300)\n",
            "(261, 300)\n",
            "(262, 300)\n",
            "(263, 300)\n",
            "(264, 300)\n",
            "(265, 300)\n",
            "(266, 300)\n",
            "(267, 300)\n",
            "(268, 300)\n",
            "(269, 300)\n",
            "(270, 300)\n",
            "(271, 300)\n",
            "(272, 300)\n",
            "(273, 300)\n",
            "(274, 300)\n",
            "(275, 300)\n",
            "(276, 300)\n",
            "(277, 300)\n",
            "(278, 300)\n",
            "(279, 300)\n",
            "(280, 300)\n",
            "(281, 300)\n",
            "(282, 300)\n",
            "(283, 300)\n",
            "(284, 300)\n",
            "(285, 300)\n",
            "(286, 300)\n",
            "(287, 300)\n",
            "(288, 300)\n",
            "(289, 300)\n",
            "(290, 300)\n",
            "(291, 300)\n",
            "(292, 300)\n",
            "(293, 300)\n",
            "(294, 300)\n",
            "(295, 300)\n",
            "(296, 300)\n",
            "(297, 300)\n",
            "(298, 300)\n",
            "(299, 300)\n",
            "(300, 300)\n",
            "(301, 300)\n",
            "(302, 300)\n",
            "(303, 300)\n",
            "(304, 300)\n",
            "(305, 300)\n",
            "(306, 300)\n",
            "(307, 300)\n",
            "(308, 300)\n",
            "(309, 300)\n",
            "(310, 300)\n",
            "(311, 300)\n",
            "(312, 300)\n",
            "(313, 300)\n",
            "(314, 300)\n",
            "(315, 300)\n",
            "(316, 300)\n",
            "(317, 300)\n",
            "(318, 300)\n",
            "(319, 300)\n",
            "(320, 300)\n",
            "(321, 300)\n",
            "(322, 300)\n",
            "(323, 300)\n",
            "(324, 300)\n",
            "(325, 300)\n",
            "(326, 300)\n",
            "(327, 300)\n",
            "(328, 300)\n",
            "(329, 300)\n",
            "(330, 300)\n",
            "(331, 300)\n",
            "(332, 300)\n",
            "(333, 300)\n",
            "(334, 300)\n",
            "(335, 300)\n",
            "(336, 300)\n",
            "(337, 300)\n",
            "(338, 300)\n",
            "(339, 300)\n",
            "(340, 300)\n",
            "(341, 300)\n",
            "(342, 300)\n",
            "(343, 300)\n",
            "(344, 300)\n",
            "(345, 300)\n",
            "(346, 300)\n",
            "(347, 300)\n",
            "(348, 300)\n",
            "(349, 300)\n",
            "(350, 300)\n",
            "(351, 300)\n",
            "(352, 300)\n",
            "(353, 300)\n",
            "(354, 300)\n",
            "(355, 300)\n",
            "(356, 300)\n",
            "(357, 300)\n",
            "(358, 300)\n",
            "(359, 300)\n",
            "(360, 300)\n",
            "(361, 300)\n",
            "(362, 300)\n",
            "(363, 300)\n",
            "(364, 300)\n",
            "(365, 300)\n",
            "(366, 300)\n",
            "(367, 300)\n",
            "(368, 300)\n",
            "(369, 300)\n",
            "(370, 300)\n",
            "(371, 300)\n",
            "(372, 300)\n",
            "(373, 300)\n",
            "(374, 300)\n",
            "(375, 300)\n",
            "(376, 300)\n",
            "(377, 300)\n",
            "(378, 300)\n",
            "(379, 300)\n",
            "(380, 300)\n",
            "(381, 300)\n",
            "(382, 300)\n",
            "(383, 300)\n",
            "(384, 300)\n",
            "(385, 300)\n",
            "(386, 300)\n",
            "(387, 300)\n",
            "(388, 300)\n",
            "(389, 300)\n",
            "(390, 300)\n",
            "(391, 300)\n",
            "(392, 300)\n",
            "(393, 300)\n",
            "(394, 300)\n",
            "(395, 300)\n",
            "(396, 300)\n",
            "(397, 300)\n",
            "(398, 300)\n",
            "(399, 300)\n",
            "(400, 300)\n",
            "(401, 300)\n",
            "(402, 300)\n",
            "(403, 300)\n",
            "(404, 300)\n",
            "(405, 300)\n",
            "(406, 300)\n",
            "(407, 300)\n",
            "(408, 300)\n",
            "(409, 300)\n",
            "(410, 300)\n",
            "(411, 300)\n",
            "(412, 300)\n",
            "(413, 300)\n",
            "(414, 300)\n",
            "(415, 300)\n",
            "(416, 300)\n",
            "(417, 300)\n",
            "(418, 300)\n",
            "(419, 300)\n",
            "(420, 300)\n",
            "(421, 300)\n",
            "(422, 300)\n",
            "(423, 300)\n",
            "(424, 300)\n",
            "(425, 300)\n",
            "(426, 300)\n",
            "(427, 300)\n",
            "(428, 300)\n",
            "(429, 300)\n",
            "(430, 300)\n",
            "(431, 300)\n",
            "(432, 300)\n",
            "(433, 300)\n",
            "(434, 300)\n",
            "(435, 300)\n",
            "(436, 300)\n",
            "(437, 300)\n",
            "(438, 300)\n",
            "(439, 300)\n",
            "(440, 300)\n",
            "(441, 300)\n",
            "(442, 300)\n",
            "(443, 300)\n",
            "(444, 300)\n",
            "(445, 300)\n",
            "(446, 300)\n",
            "(447, 300)\n",
            "(448, 300)\n",
            "(449, 300)\n",
            "(450, 300)\n",
            "(451, 300)\n",
            "(452, 300)\n",
            "(453, 300)\n",
            "(454, 300)\n",
            "(455, 300)\n",
            "(456, 300)\n",
            "(457, 300)\n",
            "(458, 300)\n",
            "(459, 300)\n",
            "(460, 300)\n",
            "(461, 300)\n",
            "(462, 300)\n",
            "(463, 300)\n",
            "(464, 300)\n",
            "(465, 300)\n",
            "(466, 300)\n",
            "(467, 300)\n",
            "(468, 300)\n",
            "(469, 300)\n",
            "(470, 300)\n",
            "(471, 300)\n",
            "(472, 300)\n",
            "(473, 300)\n",
            "(474, 300)\n",
            "(475, 300)\n",
            "(476, 300)\n",
            "(477, 300)\n",
            "(478, 300)\n",
            "(479, 300)\n",
            "(480, 300)\n",
            "(481, 300)\n",
            "(482, 300)\n",
            "(483, 300)\n",
            "(484, 300)\n",
            "(485, 300)\n",
            "(486, 300)\n",
            "(487, 300)\n",
            "(488, 300)\n",
            "(489, 300)\n",
            "(490, 300)\n",
            "(491, 300)\n",
            "(492, 300)\n",
            "(493, 300)\n",
            "(494, 300)\n",
            "(495, 300)\n",
            "(496, 300)\n",
            "(497, 300)\n",
            "(498, 300)\n",
            "(499, 300)\n",
            "(500, 300)\n",
            "(501, 300)\n",
            "(502, 300)\n",
            "(503, 300)\n",
            "(504, 300)\n",
            "(505, 300)\n",
            "(506, 300)\n",
            "(507, 300)\n",
            "(508, 300)\n",
            "(509, 300)\n",
            "(510, 300)\n",
            "(511, 300)\n",
            "(512, 300)\n",
            "(513, 300)\n",
            "(514, 300)\n",
            "(515, 300)\n",
            "(516, 300)\n",
            "(517, 300)\n",
            "(518, 300)\n",
            "(519, 300)\n",
            "(520, 300)\n",
            "(521, 300)\n",
            "(522, 300)\n",
            "(523, 300)\n",
            "(524, 300)\n",
            "(525, 300)\n",
            "(526, 300)\n",
            "(527, 300)\n",
            "(528, 300)\n",
            "(529, 300)\n",
            "(530, 300)\n",
            "(531, 300)\n",
            "(532, 300)\n",
            "(533, 300)\n",
            "(534, 300)\n",
            "(535, 300)\n",
            "(536, 300)\n",
            "(537, 300)\n",
            "(538, 300)\n",
            "(539, 300)\n",
            "(540, 300)\n",
            "(541, 300)\n",
            "(542, 300)\n",
            "(543, 300)\n",
            "(544, 300)\n",
            "(545, 300)\n",
            "(546, 300)\n",
            "(547, 300)\n",
            "(548, 300)\n",
            "(549, 300)\n",
            "(550, 300)\n",
            "(551, 300)\n",
            "(552, 300)\n",
            "(553, 300)\n",
            "(554, 300)\n",
            "(555, 300)\n",
            "(556, 300)\n",
            "(557, 300)\n",
            "(558, 300)\n",
            "(559, 300)\n",
            "(560, 300)\n",
            "(561, 300)\n",
            "(562, 300)\n",
            "(563, 300)\n",
            "(564, 300)\n",
            "(565, 300)\n",
            "(566, 300)\n",
            "(567, 300)\n",
            "(568, 300)\n",
            "(569, 300)\n",
            "(570, 300)\n",
            "(571, 300)\n",
            "(572, 300)\n",
            "(573, 300)\n",
            "(574, 300)\n",
            "(575, 300)\n",
            "(576, 300)\n",
            "(577, 300)\n",
            "(578, 300)\n",
            "(579, 300)\n",
            "(580, 300)\n",
            "(581, 300)\n",
            "(582, 300)\n",
            "(583, 300)\n",
            "(584, 300)\n",
            "(585, 300)\n",
            "(586, 300)\n",
            "(587, 300)\n",
            "(588, 300)\n",
            "(589, 300)\n",
            "(590, 300)\n",
            "(591, 300)\n",
            "(592, 300)\n",
            "(593, 300)\n",
            "(594, 300)\n",
            "(595, 300)\n",
            "(596, 300)\n",
            "(597, 300)\n",
            "(598, 300)\n",
            "(599, 300)\n",
            "(600, 300)\n",
            "(601, 300)\n",
            "(602, 300)\n",
            "(603, 300)\n",
            "(604, 300)\n",
            "(605, 300)\n",
            "(606, 300)\n",
            "(607, 300)\n",
            "(608, 300)\n",
            "(609, 300)\n",
            "(610, 300)\n",
            "(611, 300)\n",
            "(612, 300)\n",
            "(613, 300)\n",
            "(614, 300)\n",
            "(615, 300)\n",
            "(616, 300)\n",
            "(617, 300)\n",
            "(618, 300)\n",
            "(619, 300)\n",
            "(620, 300)\n",
            "(621, 300)\n",
            "(622, 300)\n",
            "(623, 300)\n",
            "(624, 300)\n",
            "(625, 300)\n",
            "(626, 300)\n",
            "(627, 300)\n",
            "(628, 300)\n",
            "(629, 300)\n",
            "(630, 300)\n",
            "(631, 300)\n",
            "(632, 300)\n",
            "(633, 300)\n",
            "(634, 300)\n",
            "(635, 300)\n",
            "(636, 300)\n",
            "(637, 300)\n",
            "(638, 300)\n",
            "(639, 300)\n",
            "(640, 300)\n",
            "(641, 300)\n",
            "(642, 300)\n",
            "(643, 300)\n",
            "(644, 300)\n",
            "(645, 300)\n",
            "(646, 300)\n",
            "(647, 300)\n",
            "(648, 300)\n",
            "(649, 300)\n",
            "(650, 300)\n",
            "(651, 300)\n",
            "(652, 300)\n",
            "(653, 300)\n",
            "(654, 300)\n",
            "(655, 300)\n",
            "(656, 300)\n",
            "(657, 300)\n",
            "(658, 300)\n",
            "(659, 300)\n",
            "(660, 300)\n",
            "(661, 300)\n",
            "(662, 300)\n",
            "(663, 300)\n",
            "(664, 300)\n",
            "(665, 300)\n",
            "(666, 300)\n",
            "(667, 300)\n",
            "(668, 300)\n",
            "(669, 300)\n",
            "(670, 300)\n",
            "(671, 300)\n",
            "(672, 300)\n",
            "(673, 300)\n",
            "(674, 300)\n",
            "(675, 300)\n",
            "(676, 300)\n",
            "(677, 300)\n",
            "(678, 300)\n",
            "(679, 300)\n",
            "(680, 300)\n",
            "(681, 300)\n",
            "(682, 300)\n",
            "(683, 300)\n",
            "(684, 300)\n",
            "(685, 300)\n",
            "(686, 300)\n",
            "(687, 300)\n",
            "(688, 300)\n",
            "(689, 300)\n",
            "(690, 300)\n",
            "(691, 300)\n",
            "(692, 300)\n",
            "(693, 300)\n",
            "(694, 300)\n",
            "(695, 300)\n",
            "(696, 300)\n",
            "(697, 300)\n",
            "(698, 300)\n",
            "(699, 300)\n",
            "(700, 300)\n",
            "(701, 300)\n",
            "(702, 300)\n",
            "(703, 300)\n",
            "(704, 300)\n",
            "(705, 300)\n",
            "(706, 300)\n",
            "(707, 300)\n",
            "(708, 300)\n",
            "(709, 300)\n",
            "(710, 300)\n",
            "(711, 300)\n",
            "(712, 300)\n",
            "(713, 300)\n",
            "(714, 300)\n",
            "(715, 300)\n",
            "(716, 300)\n",
            "(717, 300)\n",
            "(718, 300)\n",
            "(719, 300)\n",
            "(720, 300)\n",
            "(721, 300)\n",
            "(722, 300)\n",
            "(723, 300)\n",
            "(724, 300)\n",
            "(725, 300)\n",
            "(726, 300)\n",
            "(727, 300)\n",
            "(728, 300)\n",
            "(729, 300)\n",
            "(730, 300)\n",
            "(731, 300)\n",
            "(732, 300)\n",
            "(733, 300)\n",
            "(734, 300)\n",
            "(735, 300)\n",
            "(736, 300)\n",
            "(737, 300)\n",
            "(738, 300)\n",
            "(739, 300)\n",
            "(740, 300)\n",
            "(741, 300)\n",
            "(742, 300)\n",
            "(743, 300)\n",
            "(744, 300)\n",
            "(745, 300)\n",
            "(746, 300)\n",
            "(747, 300)\n",
            "(748, 300)\n",
            "(749, 300)\n",
            "(750, 300)\n",
            "(751, 300)\n",
            "(752, 300)\n",
            "(753, 300)\n",
            "(754, 300)\n",
            "(755, 300)\n",
            "(756, 300)\n",
            "(757, 300)\n",
            "(758, 300)\n",
            "(759, 300)\n",
            "(760, 300)\n",
            "(761, 300)\n",
            "(762, 300)\n",
            "(763, 300)\n",
            "(764, 300)\n",
            "(765, 300)\n",
            "(766, 300)\n",
            "(767, 300)\n",
            "(768, 300)\n",
            "(769, 300)\n",
            "(770, 300)\n",
            "(771, 300)\n",
            "(772, 300)\n",
            "(773, 300)\n",
            "(774, 300)\n",
            "(775, 300)\n",
            "(776, 300)\n",
            "(777, 300)\n",
            "(778, 300)\n",
            "(779, 300)\n",
            "(780, 300)\n",
            "(781, 300)\n",
            "(782, 300)\n",
            "(783, 300)\n",
            "(784, 300)\n",
            "(785, 300)\n",
            "(786, 300)\n",
            "(787, 300)\n",
            "(788, 300)\n",
            "(789, 300)\n",
            "(790, 300)\n",
            "(791, 300)\n",
            "(792, 300)\n",
            "(793, 300)\n",
            "(794, 300)\n",
            "(795, 300)\n",
            "(796, 300)\n",
            "(797, 300)\n",
            "(798, 300)\n",
            "(799, 300)\n",
            "(800, 300)\n",
            "(801, 300)\n",
            "(802, 300)\n",
            "(803, 300)\n",
            "(804, 300)\n",
            "(805, 300)\n",
            "(806, 300)\n",
            "(807, 300)\n",
            "(808, 300)\n",
            "(809, 300)\n",
            "(810, 300)\n",
            "(811, 300)\n",
            "(812, 300)\n",
            "(813, 300)\n",
            "(814, 300)\n",
            "(815, 300)\n",
            "(816, 300)\n",
            "(817, 300)\n",
            "(818, 300)\n",
            "(819, 300)\n",
            "(820, 300)\n",
            "(821, 300)\n",
            "(822, 300)\n",
            "(823, 300)\n",
            "(824, 300)\n",
            "(825, 300)\n",
            "(826, 300)\n",
            "(827, 300)\n",
            "(828, 300)\n",
            "(829, 300)\n",
            "(830, 300)\n",
            "(831, 300)\n",
            "(832, 300)\n",
            "(833, 300)\n",
            "(834, 300)\n",
            "(835, 300)\n",
            "(836, 300)\n",
            "(837, 300)\n",
            "(838, 300)\n",
            "(839, 300)\n",
            "(840, 300)\n",
            "(841, 300)\n",
            "(842, 300)\n",
            "(843, 300)\n",
            "(844, 300)\n",
            "(845, 300)\n",
            "(846, 300)\n",
            "(847, 300)\n",
            "(848, 300)\n",
            "(849, 300)\n",
            "(850, 300)\n",
            "(851, 300)\n",
            "(852, 300)\n",
            "(853, 300)\n",
            "(854, 300)\n",
            "(855, 300)\n",
            "(856, 300)\n",
            "(857, 300)\n",
            "(858, 300)\n",
            "(859, 300)\n",
            "(860, 300)\n",
            "(861, 300)\n",
            "(862, 300)\n",
            "(863, 300)\n",
            "(864, 300)\n",
            "(865, 300)\n",
            "(866, 300)\n",
            "(867, 300)\n",
            "(868, 300)\n",
            "(869, 300)\n",
            "(870, 300)\n",
            "(871, 300)\n",
            "(872, 300)\n",
            "(873, 300)\n",
            "(874, 300)\n",
            "(875, 300)\n",
            "(876, 300)\n",
            "(877, 300)\n",
            "(878, 300)\n",
            "(879, 300)\n",
            "(880, 300)\n",
            "(881, 300)\n",
            "(882, 300)\n",
            "(883, 300)\n",
            "(884, 300)\n",
            "(885, 300)\n",
            "(886, 300)\n",
            "(887, 300)\n",
            "(888, 300)\n",
            "(889, 300)\n",
            "(890, 300)\n",
            "(891, 300)\n",
            "(892, 300)\n",
            "(893, 300)\n",
            "(894, 300)\n",
            "(895, 300)\n",
            "(896, 300)\n",
            "(897, 300)\n",
            "(898, 300)\n",
            "(899, 300)\n",
            "(900, 300)\n",
            "(901, 300)\n",
            "(902, 300)\n",
            "(903, 300)\n",
            "(904, 300)\n",
            "(905, 300)\n",
            "(906, 300)\n",
            "(907, 300)\n",
            "(908, 300)\n",
            "(909, 300)\n",
            "(910, 300)\n",
            "(911, 300)\n",
            "(912, 300)\n",
            "(913, 300)\n",
            "(914, 300)\n",
            "(915, 300)\n",
            "(916, 300)\n",
            "(917, 300)\n",
            "(918, 300)\n",
            "(919, 300)\n",
            "(920, 300)\n",
            "(921, 300)\n",
            "(922, 300)\n",
            "(923, 300)\n",
            "(924, 300)\n",
            "(925, 300)\n",
            "(926, 300)\n",
            "(927, 300)\n",
            "(928, 300)\n",
            "(929, 300)\n",
            "(930, 300)\n",
            "(931, 300)\n",
            "(932, 300)\n",
            "(933, 300)\n",
            "(934, 300)\n",
            "(935, 300)\n",
            "(936, 300)\n",
            "(937, 300)\n",
            "(938, 300)\n",
            "(939, 300)\n",
            "(940, 300)\n",
            "(941, 300)\n",
            "(942, 300)\n",
            "(943, 300)\n",
            "(944, 300)\n",
            "(945, 300)\n",
            "(946, 300)\n",
            "(947, 300)\n",
            "(948, 300)\n",
            "(949, 300)\n",
            "(950, 300)\n",
            "(951, 300)\n",
            "(952, 300)\n",
            "(953, 300)\n",
            "(954, 300)\n",
            "(955, 300)\n",
            "(956, 300)\n",
            "(957, 300)\n",
            "(958, 300)\n",
            "(959, 300)\n",
            "(960, 300)\n",
            "(961, 300)\n",
            "(962, 300)\n",
            "(963, 300)\n",
            "(964, 300)\n",
            "(965, 300)\n",
            "(966, 300)\n",
            "(967, 300)\n",
            "(968, 300)\n",
            "(969, 300)\n",
            "(970, 300)\n",
            "(971, 300)\n",
            "(972, 300)\n",
            "(973, 300)\n",
            "(974, 300)\n",
            "(975, 300)\n",
            "(976, 300)\n",
            "(977, 300)\n",
            "(978, 300)\n",
            "(979, 300)\n",
            "(980, 300)\n",
            "(981, 300)\n",
            "(982, 300)\n",
            "(983, 300)\n",
            "(984, 300)\n",
            "(985, 300)\n",
            "(986, 300)\n",
            "(987, 300)\n",
            "(988, 300)\n",
            "(989, 300)\n",
            "(990, 300)\n",
            "(991, 300)\n",
            "(992, 300)\n",
            "(993, 300)\n",
            "(994, 300)\n",
            "(995, 300)\n",
            "(996, 300)\n",
            "(997, 300)\n",
            "(998, 300)\n",
            "(999, 300)\n",
            "(1000, 300)\n",
            "(1001, 300)\n",
            "(1002, 300)\n",
            "(1003, 300)\n",
            "(1004, 300)\n",
            "(1005, 300)\n",
            "(1006, 300)\n",
            "(1007, 300)\n",
            "(1008, 300)\n",
            "(1009, 300)\n",
            "(1010, 300)\n",
            "(1011, 300)\n",
            "(1012, 300)\n",
            "(1013, 300)\n",
            "(1014, 300)\n",
            "(1015, 300)\n",
            "(1016, 300)\n",
            "(1017, 300)\n",
            "(1018, 300)\n",
            "(1019, 300)\n",
            "(1020, 300)\n",
            "(1021, 300)\n",
            "(1022, 300)\n",
            "(1023, 300)\n",
            "(1024, 300)\n",
            "(1025, 300)\n",
            "(1026, 300)\n",
            "(1027, 300)\n",
            "(1028, 300)\n",
            "(1029, 300)\n",
            "(1030, 300)\n",
            "(1031, 300)\n",
            "(1032, 300)\n",
            "(1033, 300)\n",
            "(1034, 300)\n",
            "(1035, 300)\n",
            "(1036, 300)\n",
            "(1037, 300)\n",
            "(1038, 300)\n",
            "(1039, 300)\n",
            "(1040, 300)\n",
            "(1041, 300)\n",
            "(1042, 300)\n",
            "(1043, 300)\n",
            "(1044, 300)\n",
            "(1045, 300)\n",
            "(1046, 300)\n",
            "(1047, 300)\n",
            "(1048, 300)\n",
            "(1049, 300)\n",
            "(1050, 300)\n",
            "(1051, 300)\n",
            "(1052, 300)\n",
            "(1053, 300)\n",
            "(1054, 300)\n",
            "(1055, 300)\n",
            "(1056, 300)\n",
            "(1057, 300)\n",
            "(1058, 300)\n",
            "(1059, 300)\n",
            "(1060, 300)\n",
            "(1061, 300)\n",
            "(1062, 300)\n",
            "(1063, 300)\n",
            "(1064, 300)\n",
            "(1065, 300)\n",
            "(1066, 300)\n",
            "(1067, 300)\n",
            "(1068, 300)\n",
            "(1069, 300)\n",
            "(1070, 300)\n",
            "(1071, 300)\n",
            "(1072, 300)\n",
            "(1073, 300)\n",
            "(1074, 300)\n",
            "(1075, 300)\n",
            "(1076, 300)\n",
            "(1077, 300)\n",
            "(1078, 300)\n",
            "(1079, 300)\n",
            "(1080, 300)\n",
            "(1081, 300)\n",
            "(1082, 300)\n",
            "(1083, 300)\n",
            "(1084, 300)\n",
            "(1085, 300)\n",
            "(1086, 300)\n",
            "(1087, 300)\n",
            "(1088, 300)\n",
            "(1089, 300)\n",
            "(1090, 300)\n",
            "(1091, 300)\n",
            "(1092, 300)\n",
            "(1093, 300)\n",
            "(1094, 300)\n",
            "(1095, 300)\n",
            "(1096, 300)\n",
            "(1097, 300)\n",
            "(1098, 300)\n",
            "(1099, 300)\n",
            "(1100, 300)\n",
            "(1101, 300)\n",
            "(1102, 300)\n",
            "(1103, 300)\n",
            "(1104, 300)\n",
            "(1105, 300)\n",
            "(1106, 300)\n",
            "(1107, 300)\n",
            "(1108, 300)\n",
            "(1109, 300)\n",
            "(1110, 300)\n",
            "(1111, 300)\n",
            "(1112, 300)\n",
            "(1113, 300)\n",
            "(1114, 300)\n",
            "(1115, 300)\n",
            "(1116, 300)\n",
            "(1117, 300)\n",
            "(1118, 300)\n",
            "(1119, 300)\n",
            "(1120, 300)\n",
            "(1121, 300)\n",
            "(1122, 300)\n",
            "(1123, 300)\n",
            "(1124, 300)\n",
            "(1125, 300)\n",
            "(1126, 300)\n",
            "(1127, 300)\n",
            "(1128, 300)\n",
            "(1129, 300)\n",
            "(1130, 300)\n",
            "(1131, 300)\n",
            "(1132, 300)\n",
            "(1133, 300)\n",
            "(1134, 300)\n",
            "(1135, 300)\n",
            "(1136, 300)\n",
            "(1137, 300)\n",
            "(1138, 300)\n",
            "(1139, 300)\n",
            "(1140, 300)\n",
            "(1141, 300)\n",
            "(1142, 300)\n",
            "(1143, 300)\n",
            "(1144, 300)\n",
            "(1145, 300)\n",
            "(1146, 300)\n",
            "(1147, 300)\n",
            "(1148, 300)\n",
            "(1149, 300)\n",
            "(1150, 300)\n",
            "(1151, 300)\n",
            "(1152, 300)\n",
            "(1153, 300)\n",
            "(1154, 300)\n",
            "(1155, 300)\n",
            "(1156, 300)\n",
            "(1157, 300)\n",
            "(1158, 300)\n",
            "(1159, 300)\n",
            "(1160, 300)\n",
            "(1161, 300)\n",
            "(1162, 300)\n",
            "(1163, 300)\n",
            "(1164, 300)\n",
            "(1165, 300)\n",
            "(1166, 300)\n",
            "(1167, 300)\n",
            "(1168, 300)\n",
            "(1169, 300)\n",
            "(1170, 300)\n",
            "(1171, 300)\n",
            "(1172, 300)\n",
            "(1173, 300)\n",
            "(1174, 300)\n",
            "(1175, 300)\n",
            "(1176, 300)\n",
            "(1177, 300)\n",
            "(1178, 300)\n",
            "(1179, 300)\n",
            "(1180, 300)\n",
            "(1181, 300)\n",
            "(1182, 300)\n",
            "(1183, 300)\n",
            "(1184, 300)\n",
            "(1185, 300)\n",
            "(1186, 300)\n",
            "(1187, 300)\n",
            "(1188, 300)\n",
            "(1189, 300)\n",
            "(1190, 300)\n",
            "(1191, 300)\n",
            "(1192, 300)\n",
            "(1193, 300)\n",
            "(1194, 300)\n",
            "(1195, 300)\n",
            "(1196, 300)\n",
            "(1197, 300)\n",
            "(1198, 300)\n",
            "(1199, 300)\n",
            "(1200, 300)\n",
            "(1201, 300)\n",
            "(1202, 300)\n",
            "(1203, 300)\n",
            "(1204, 300)\n",
            "(1205, 300)\n",
            "(1206, 300)\n",
            "(1207, 300)\n",
            "(1208, 300)\n",
            "(1209, 300)\n",
            "(1210, 300)\n",
            "(1211, 300)\n",
            "(1212, 300)\n",
            "(1213, 300)\n",
            "(1214, 300)\n",
            "(1215, 300)\n",
            "(1216, 300)\n",
            "(1217, 300)\n",
            "(1218, 300)\n",
            "(1219, 300)\n",
            "(1220, 300)\n",
            "(1221, 300)\n",
            "(1222, 300)\n",
            "(1223, 300)\n",
            "(1224, 300)\n",
            "(1225, 300)\n",
            "(1226, 300)\n",
            "(1227, 300)\n",
            "(1228, 300)\n",
            "(1229, 300)\n",
            "(1230, 300)\n",
            "(1231, 300)\n",
            "(1232, 300)\n",
            "(1233, 300)\n",
            "(1234, 300)\n",
            "(1235, 300)\n",
            "(1236, 300)\n",
            "(1237, 300)\n",
            "(1238, 300)\n",
            "(1239, 300)\n",
            "(1240, 300)\n",
            "(1241, 300)\n",
            "(1242, 300)\n",
            "(1243, 300)\n",
            "(1244, 300)\n",
            "(1245, 300)\n",
            "(1246, 300)\n",
            "(1247, 300)\n",
            "(1248, 300)\n",
            "(1249, 300)\n",
            "(1250, 300)\n",
            "(1251, 300)\n",
            "(1252, 300)\n",
            "(1253, 300)\n",
            "(1254, 300)\n",
            "(1255, 300)\n",
            "(1256, 300)\n",
            "(1257, 300)\n",
            "(1258, 300)\n",
            "(1259, 300)\n",
            "(1260, 300)\n",
            "(1261, 300)\n",
            "(1262, 300)\n",
            "(1263, 300)\n",
            "(1264, 300)\n",
            "(1265, 300)\n",
            "(1266, 300)\n",
            "(1267, 300)\n",
            "(1268, 300)\n",
            "(1269, 300)\n",
            "(1270, 300)\n",
            "(1271, 300)\n",
            "(1272, 300)\n",
            "(1273, 300)\n",
            "(1274, 300)\n",
            "(1275, 300)\n",
            "(1276, 300)\n",
            "(1277, 300)\n",
            "(1278, 300)\n",
            "(1279, 300)\n",
            "(1280, 300)\n",
            "(1281, 300)\n",
            "(1282, 300)\n",
            "(1283, 300)\n",
            "(1284, 300)\n",
            "(1285, 300)\n",
            "(1286, 300)\n",
            "(1287, 300)\n",
            "(1288, 300)\n",
            "(1289, 300)\n",
            "(1290, 300)\n",
            "(1291, 300)\n",
            "(1292, 300)\n",
            "(1293, 300)\n",
            "(1294, 300)\n",
            "(1295, 300)\n",
            "(1296, 300)\n",
            "(1297, 300)\n",
            "(1298, 300)\n",
            "(1299, 300)\n",
            "(1300, 300)\n",
            "(1301, 300)\n",
            "(1302, 300)\n",
            "(1303, 300)\n",
            "(1304, 300)\n",
            "(1305, 300)\n",
            "(1306, 300)\n",
            "(1307, 300)\n",
            "(1308, 300)\n",
            "(1309, 300)\n",
            "(1310, 300)\n",
            "(1311, 300)\n",
            "(1312, 300)\n",
            "(1313, 300)\n",
            "(1314, 300)\n",
            "(1315, 300)\n",
            "(1316, 300)\n",
            "(1317, 300)\n",
            "(1318, 300)\n",
            "(1319, 300)\n",
            "(1320, 300)\n",
            "(1321, 300)\n",
            "(1322, 300)\n",
            "(1323, 300)\n",
            "(1324, 300)\n",
            "(1325, 300)\n",
            "(1326, 300)\n",
            "(1327, 300)\n",
            "(1328, 300)\n",
            "(1329, 300)\n",
            "(1330, 300)\n",
            "(1331, 300)\n",
            "(1332, 300)\n",
            "(1333, 300)\n",
            "(1334, 300)\n",
            "(1335, 300)\n",
            "(1336, 300)\n",
            "(1337, 300)\n",
            "(1338, 300)\n",
            "(1339, 300)\n",
            "(1340, 300)\n",
            "(1341, 300)\n",
            "(1342, 300)\n",
            "(1343, 300)\n",
            "(1344, 300)\n",
            "(1345, 300)\n",
            "(1346, 300)\n",
            "(1347, 300)\n",
            "(1348, 300)\n",
            "(1349, 300)\n",
            "(1350, 300)\n",
            "(1351, 300)\n",
            "(1352, 300)\n",
            "(1353, 300)\n",
            "(1354, 300)\n",
            "(1355, 300)\n",
            "(1356, 300)\n",
            "(1357, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9ITusnyL1uT"
      },
      "source": [
        "np.save('./diagrams', diagrams)\n",
        "np.save('./classes_fold', classes_fold)\n",
        "np.save('./classes_superfamily', classes_superfamily)\n",
        "np.save('./classes_family', classes_family)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHpCf2JUBDp9"
      },
      "source": [
        "Set desired SCOP domain classification (e.g., superfamily)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjJ3MKKcAr9C"
      },
      "source": [
        "classes = classes_superfamily"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-hhGWtZMAP7"
      },
      "source": [
        "## Load diagrams and classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlFzcLpqMDp8"
      },
      "source": [
        "diagrams = np.load('./diagrams.npy')\n",
        "classes = np.load('./classes_superfamily.npy')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjxwIn6Gcvgz"
      },
      "source": [
        "## Data preprocessing\n",
        "Run either **A** or **B**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjzhEF0OdGYI"
      },
      "source": [
        "**A**: Prep data for SVM and gradient boosting models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7LJ_BFdMecD"
      },
      "source": [
        "# Generate binary targets for an arbitrary class \n",
        "# targets = np.ravel(label_binarize(classes, classes=['a.3.1'])) # If binary\n",
        "targets = np.ravel(classes) # If multiclass\n",
        "data = diagrams\n",
        "\n",
        "train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzZ-9wgsdA8x"
      },
      "source": [
        "**B**: Prep data for TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_YcaTB8Fmeq",
        "outputId": "36d3fdf6-65e3-49a1-c4fe-072b97b5d18a"
      },
      "source": [
        "# Count the number of unique classes\n",
        "num_classes = len(np.unique(classes))\n",
        "print(num_classes)\n",
        "\n",
        "# Prepare targets and data for TensorFlow\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "one_hot_encoder.fit(classes)\n",
        "targets = one_hot_encoder.transform(classes)\n",
        "data = diagrams\n",
        "\n",
        "train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=0.2)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy99oWv2fMjb"
      },
      "source": [
        "## Build SVM and gradient boosting models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkab5K5KTX2Q",
        "outputId": "8307aaee-8f8e-49f3-87a5-02acc8d31e10"
      },
      "source": [
        "clf = SVC(kernel='rbf', C=20, random_state=42)\n",
        "\n",
        "# Perform 5-fold cross validation\n",
        "scores = cross_val_score(clf, data, targets, cv=5)\n",
        "print('%0.3f accuracy with a standard deviation of %0.2f' % (scores.mean(), scores.std()))\n",
        "\n",
        "# Test accuracy using testing data\n",
        "# clf = SVC(kernel='rbf', C=20).fit(train_data, train_targets)\n",
        "#print('Train Accuracy: {acc:0.3f}'.format(acc=clf.score(train_data, train_targets)))\n",
        "#print('Test Accuracy: {acc:0.3f}'.format(acc=clf.score(test_data, test_targets)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.127 accuracy with a standard deviation of 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YUCFzgV9n8s",
        "outputId": "a1406060-8a39-4436-fbca-3366b2a9db2f"
      },
      "source": [
        "clf = XGBClassifier()\n",
        "\n",
        "# Perform 5-fold cross validation\n",
        "scores = cross_val_score(clf, data, targets, cv=5)\n",
        "print('%0.3f accuracy with a standard deviation of %0.2f' % (scores.mean(), scores.std()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.208 accuracy with a standard deviation of 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9dWPGpN9pTv"
      },
      "source": [
        "clf = LGBMClassifier()\n",
        "\n",
        "# Perform 5-fold cross validation\n",
        "scores = cross_val_score(clf, data, targets, cv=5)\n",
        "print('%0.3f accuracy with a standard deviation of %0.2f' % (scores.mean(), scores.std()))\n",
        "\n",
        "# Test accuracy using testing data\n",
        "# clf = LGBMClassifier().fit(train_data, train_targets)\n",
        "# print('Train Accuracy: {acc:0.3f}'.format(acc=clf.score(train_data, train_targets)))\n",
        "# print('Test Accuracy: {acc:0.3f}'.format(acc=clf.score(test_data, test_targets)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTPhY6zLf3b5"
      },
      "source": [
        "## Build MLP models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaPMK61GhUQk"
      },
      "source": [
        "def get_test_accuracy(model, test_data, test_targets):\n",
        "    \"\"\"Test model classification accuracy\"\"\"\n",
        "    test_loss, test_acc = model.evaluate(x=test_data, y=test_targets, verbose=0)\n",
        "    print('Test Accuracy: {acc:0.3f}'.format(acc=test_acc))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDqrH9z-PEBJ"
      },
      "source": [
        "# Delete model if it exists\n",
        "if 'model' in globals():\n",
        "    del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-B0lv1hg6hJ"
      },
      "source": [
        "### Binary classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDd9ak2wRxhR"
      },
      "source": [
        "# Build binary sequential model for superfamily\n",
        "k_initializer = tf.keras.initializers.he_uniform()\n",
        "b_initializer = tf.keras.initializers.Ones()\n",
        "\n",
        "dropout_rate = 0.10\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(200, activation = 'relu', \n",
        "            input_shape = train_data[0].shape, \n",
        "            kernel_initializer=k_initializer,\n",
        "            bias_initializer=b_initializer),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(200, activation = 'relu'),\n",
        "    Dense(200, activation = 'relu'),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(128, activation = 'relu'),\n",
        "    Dense(128, activation = 'relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "# Compile model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(train_data, train_targets, \n",
        "                    epochs=200, validation_split=0.15, batch_size=50, \n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAIosICWjlbC"
      },
      "source": [
        "\n",
        "### Multiclass classifier (experimental)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W_SQVCiRo7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746d68ce-98ab-43cb-f11a-5e34c5d1dc7b"
      },
      "source": [
        "# Build sequential model for superfamily\n",
        "k_initializer = tf.keras.initializers.he_uniform()\n",
        "b_initializer = tf.keras.initializers.Ones()\n",
        "\n",
        "dropout_rate = 0.10\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(200, activation = 'relu', \n",
        "            input_shape = train_data[0].shape, \n",
        "            kernel_initializer=k_initializer,\n",
        "            bias_initializer=b_initializer),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(200, activation = 'relu'),\n",
        "    Dense(200, activation = 'relu'),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(128, activation = 'relu'),\n",
        "    Dense(128, activation = 'relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(train_data, train_targets, \n",
        "                    epochs=1000, validation_split=0.15, batch_size=500, \n",
        "                    verbose=1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 3s 223ms/step - loss: 355.3275 - acc: 0.0575 - val_loss: 174.8669 - val_acc: 0.0552\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 180.2624 - acc: 0.0597 - val_loss: 94.2198 - val_acc: 0.1166\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 123.8030 - acc: 0.0618 - val_loss: 53.8152 - val_acc: 0.1288\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 79.2529 - acc: 0.0933 - val_loss: 40.3505 - val_acc: 0.1656\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 61.5974 - acc: 0.0889 - val_loss: 33.7996 - val_acc: 0.1718\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 47.9694 - acc: 0.1030 - val_loss: 26.9310 - val_acc: 0.1350\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 40.5816 - acc: 0.0879 - val_loss: 20.6824 - val_acc: 0.0552\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 33.9522 - acc: 0.0759 - val_loss: 16.1953 - val_acc: 0.0675\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 27.9310 - acc: 0.0868 - val_loss: 13.0860 - val_acc: 0.0429\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 25.2631 - acc: 0.0857 - val_loss: 11.5153 - val_acc: 0.0429\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 21.0909 - acc: 0.0944 - val_loss: 10.2099 - val_acc: 0.0307\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 18.4185 - acc: 0.0900 - val_loss: 9.3307 - val_acc: 0.0429\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 16.8398 - acc: 0.0868 - val_loss: 8.2740 - val_acc: 0.0552\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 15.2239 - acc: 0.0879 - val_loss: 7.2664 - val_acc: 0.0613\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 13.2555 - acc: 0.0803 - val_loss: 6.4686 - val_acc: 0.0920\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12.4633 - acc: 0.0911 - val_loss: 5.6731 - val_acc: 0.1779\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11.1304 - acc: 0.0998 - val_loss: 5.3287 - val_acc: 0.1534\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10.8926 - acc: 0.0987 - val_loss: 5.2017 - val_acc: 0.1779\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 9.1771 - acc: 0.1095 - val_loss: 4.9608 - val_acc: 0.1779\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.4485 - acc: 0.1193 - val_loss: 4.6654 - val_acc: 0.1840\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.1021 - acc: 0.1269 - val_loss: 4.4069 - val_acc: 0.1656\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 7.7426 - acc: 0.1063 - val_loss: 4.1186 - val_acc: 0.1411\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 7.1280 - acc: 0.0889 - val_loss: 3.8288 - val_acc: 0.1227\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 7.0750 - acc: 0.0813 - val_loss: 3.6856 - val_acc: 0.0982\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 6.3251 - acc: 0.0965 - val_loss: 3.6489 - val_acc: 0.0982\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 6.0661 - acc: 0.1150 - val_loss: 3.6615 - val_acc: 0.1104\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 5.8334 - acc: 0.0933 - val_loss: 3.6433 - val_acc: 0.1288\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 5.5204 - acc: 0.1117 - val_loss: 3.5351 - val_acc: 0.1350\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 5.5674 - acc: 0.1009 - val_loss: 3.4490 - val_acc: 0.1166\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 5.3261 - acc: 0.0922 - val_loss: 3.3863 - val_acc: 0.1166\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.8493 - acc: 0.1128 - val_loss: 3.2850 - val_acc: 0.1104\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.7674 - acc: 0.0944 - val_loss: 3.2310 - val_acc: 0.1288\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.7022 - acc: 0.0889 - val_loss: 3.1844 - val_acc: 0.0920\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.2793 - acc: 0.0965 - val_loss: 3.1344 - val_acc: 0.1104\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.2837 - acc: 0.0889 - val_loss: 3.1706 - val_acc: 0.0859\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 4.1078 - acc: 0.0954 - val_loss: 3.1842 - val_acc: 0.0552\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.8911 - acc: 0.0748 - val_loss: 3.1818 - val_acc: 0.0368\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.7688 - acc: 0.0889 - val_loss: 3.1717 - val_acc: 0.0368\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.7900 - acc: 0.0727 - val_loss: 3.1694 - val_acc: 0.0429\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.5751 - acc: 0.0586 - val_loss: 3.1561 - val_acc: 0.0429\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4656 - acc: 0.0716 - val_loss: 3.1541 - val_acc: 0.0429\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.4825 - acc: 0.0716 - val_loss: 3.1600 - val_acc: 0.0491\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.4369 - acc: 0.0803 - val_loss: 3.1655 - val_acc: 0.0736\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.2914 - acc: 0.0683 - val_loss: 3.1687 - val_acc: 0.0920\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.3520 - acc: 0.0705 - val_loss: 3.1731 - val_acc: 0.0982\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.2573 - acc: 0.0770 - val_loss: 3.1684 - val_acc: 0.0982\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.2911 - acc: 0.0803 - val_loss: 3.1611 - val_acc: 0.0982\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.2396 - acc: 0.0857 - val_loss: 3.1566 - val_acc: 0.0982\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.1863 - acc: 0.0911 - val_loss: 3.1507 - val_acc: 0.1043\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.2611 - acc: 0.0846 - val_loss: 3.1463 - val_acc: 0.1104\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.2207 - acc: 0.0965 - val_loss: 3.1446 - val_acc: 0.1043\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.1998 - acc: 0.0998 - val_loss: 3.1416 - val_acc: 0.1166\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.1834 - acc: 0.0922 - val_loss: 3.1401 - val_acc: 0.1227\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.1860 - acc: 0.1074 - val_loss: 3.1411 - val_acc: 0.1166\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.1664 - acc: 0.1095 - val_loss: 3.1416 - val_acc: 0.1288\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.1382 - acc: 0.0976 - val_loss: 3.1378 - val_acc: 0.1227\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.1535 - acc: 0.1106 - val_loss: 3.1328 - val_acc: 0.1288\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.1513 - acc: 0.0922 - val_loss: 3.1284 - val_acc: 0.1411\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.1843 - acc: 0.1052 - val_loss: 3.1238 - val_acc: 0.1411\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.1652 - acc: 0.1052 - val_loss: 3.1203 - val_acc: 0.1411\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.1509 - acc: 0.0965 - val_loss: 3.1186 - val_acc: 0.1350\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.1644 - acc: 0.1030 - val_loss: 3.1177 - val_acc: 0.1472\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.1444 - acc: 0.1030 - val_loss: 3.1136 - val_acc: 0.1288\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.1435 - acc: 0.1085 - val_loss: 3.1076 - val_acc: 0.1043\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.1502 - acc: 0.0976 - val_loss: 3.1032 - val_acc: 0.1227\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0971 - acc: 0.0868 - val_loss: 3.0981 - val_acc: 0.1043\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.1309 - acc: 0.0976 - val_loss: 3.0966 - val_acc: 0.1043\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.1170 - acc: 0.1052 - val_loss: 3.0938 - val_acc: 0.0982\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.1159 - acc: 0.1074 - val_loss: 3.0923 - val_acc: 0.1043\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.1558 - acc: 0.0998 - val_loss: 3.0926 - val_acc: 0.1043\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.0942 - acc: 0.0998 - val_loss: 3.0966 - val_acc: 0.1288\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0922 - acc: 0.1009 - val_loss: 3.0958 - val_acc: 0.1227\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.1027 - acc: 0.0933 - val_loss: 3.0995 - val_acc: 0.1104\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.0952 - acc: 0.1074 - val_loss: 3.1104 - val_acc: 0.1227\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.0861 - acc: 0.1063 - val_loss: 3.1147 - val_acc: 0.1227\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.1144 - acc: 0.1128 - val_loss: 3.1023 - val_acc: 0.1104\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0809 - acc: 0.1150 - val_loss: 3.0911 - val_acc: 0.1104\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0747 - acc: 0.1074 - val_loss: 3.0809 - val_acc: 0.1043\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.0860 - acc: 0.1009 - val_loss: 3.0707 - val_acc: 0.1166\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.0812 - acc: 0.1095 - val_loss: 3.0636 - val_acc: 0.0982\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.0543 - acc: 0.0922 - val_loss: 3.0626 - val_acc: 0.0982\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.0486 - acc: 0.1139 - val_loss: 3.0604 - val_acc: 0.1043\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.1088 - acc: 0.0944 - val_loss: 3.0720 - val_acc: 0.1104\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.0825 - acc: 0.1074 - val_loss: 3.0896 - val_acc: 0.1043\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.0490 - acc: 0.1074 - val_loss: 3.0959 - val_acc: 0.1227\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.0964 - acc: 0.1085 - val_loss: 3.0876 - val_acc: 0.1350\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0625 - acc: 0.1215 - val_loss: 3.0732 - val_acc: 0.1534\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0609 - acc: 0.1128 - val_loss: 3.0732 - val_acc: 0.1472\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.0939 - acc: 0.1085 - val_loss: 3.0708 - val_acc: 0.1472\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.0792 - acc: 0.1074 - val_loss: 3.0690 - val_acc: 0.1534\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0832 - acc: 0.1258 - val_loss: 3.0732 - val_acc: 0.1411\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0529 - acc: 0.1117 - val_loss: 3.0768 - val_acc: 0.1227\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.0462 - acc: 0.1063 - val_loss: 3.0786 - val_acc: 0.1166\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.0797 - acc: 0.1139 - val_loss: 3.0689 - val_acc: 0.0982\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.0685 - acc: 0.1193 - val_loss: 3.0654 - val_acc: 0.1104\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.0238 - acc: 0.1106 - val_loss: 3.0585 - val_acc: 0.1166\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.0437 - acc: 0.1009 - val_loss: 3.0456 - val_acc: 0.1166\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0263 - acc: 0.1117 - val_loss: 3.0362 - val_acc: 0.1227\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.0333 - acc: 0.1128 - val_loss: 3.0249 - val_acc: 0.1227\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0599 - acc: 0.1150 - val_loss: 3.0152 - val_acc: 0.1227\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.0554 - acc: 0.1106 - val_loss: 3.0070 - val_acc: 0.1166\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0405 - acc: 0.1074 - val_loss: 3.0057 - val_acc: 0.1227\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0317 - acc: 0.1171 - val_loss: 3.0152 - val_acc: 0.1227\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.0333 - acc: 0.1171 - val_loss: 3.0258 - val_acc: 0.1166\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.0189 - acc: 0.1182 - val_loss: 3.0407 - val_acc: 0.1227\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.0269 - acc: 0.1128 - val_loss: 3.0471 - val_acc: 0.1288\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.0212 - acc: 0.1204 - val_loss: 3.0421 - val_acc: 0.1166\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.0148 - acc: 0.1204 - val_loss: 3.0339 - val_acc: 0.1166\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.9887 - acc: 0.1269 - val_loss: 3.0230 - val_acc: 0.1288\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.0056 - acc: 0.1215 - val_loss: 3.0184 - val_acc: 0.1227\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.0156 - acc: 0.1226 - val_loss: 3.0207 - val_acc: 0.1166\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.0081 - acc: 0.1182 - val_loss: 3.0329 - val_acc: 0.1227\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.9836 - acc: 0.1236 - val_loss: 3.0506 - val_acc: 0.1166\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.0131 - acc: 0.1150 - val_loss: 3.0637 - val_acc: 0.1227\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.0428 - acc: 0.1204 - val_loss: 3.0635 - val_acc: 0.1288\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.0010 - acc: 0.1247 - val_loss: 3.0336 - val_acc: 0.1227\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.0049 - acc: 0.1204 - val_loss: 3.0066 - val_acc: 0.1288\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.9993 - acc: 0.1236 - val_loss: 2.9867 - val_acc: 0.1288\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.9836 - acc: 0.1236 - val_loss: 2.9815 - val_acc: 0.1288\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0266 - acc: 0.1171 - val_loss: 2.9872 - val_acc: 0.1288\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.9918 - acc: 0.1258 - val_loss: 2.9958 - val_acc: 0.1288\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.9709 - acc: 0.1236 - val_loss: 2.9984 - val_acc: 0.1288\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0058 - acc: 0.1226 - val_loss: 2.9911 - val_acc: 0.1288\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9996 - acc: 0.1258 - val_loss: 2.9827 - val_acc: 0.1288\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.9809 - acc: 0.1095 - val_loss: 2.9739 - val_acc: 0.1288\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.9645 - acc: 0.1334 - val_loss: 2.9692 - val_acc: 0.1350\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9954 - acc: 0.1106 - val_loss: 2.9722 - val_acc: 0.1350\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.0078 - acc: 0.1334 - val_loss: 2.9744 - val_acc: 0.1350\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.9658 - acc: 0.1323 - val_loss: 2.9809 - val_acc: 0.1350\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9798 - acc: 0.1399 - val_loss: 2.9876 - val_acc: 0.1350\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9703 - acc: 0.1280 - val_loss: 2.9808 - val_acc: 0.1350\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.9901 - acc: 0.1302 - val_loss: 2.9724 - val_acc: 0.1350\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9589 - acc: 0.1334 - val_loss: 2.9666 - val_acc: 0.1411\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9758 - acc: 0.1215 - val_loss: 2.9618 - val_acc: 0.1411\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.0003 - acc: 0.1258 - val_loss: 2.9529 - val_acc: 0.1350\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9790 - acc: 0.1193 - val_loss: 2.9495 - val_acc: 0.1411\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9725 - acc: 0.1258 - val_loss: 2.9486 - val_acc: 0.1411\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9624 - acc: 0.1280 - val_loss: 2.9552 - val_acc: 0.1411\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.9637 - acc: 0.1323 - val_loss: 2.9659 - val_acc: 0.1350\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9783 - acc: 0.1334 - val_loss: 2.9704 - val_acc: 0.1350\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9595 - acc: 0.1226 - val_loss: 2.9690 - val_acc: 0.1350\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9483 - acc: 0.1367 - val_loss: 2.9669 - val_acc: 0.1288\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9679 - acc: 0.1388 - val_loss: 2.9519 - val_acc: 0.1411\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9531 - acc: 0.1258 - val_loss: 2.9389 - val_acc: 0.1472\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.9756 - acc: 0.1291 - val_loss: 2.9326 - val_acc: 0.1534\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9422 - acc: 0.1345 - val_loss: 2.9362 - val_acc: 0.1411\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9354 - acc: 0.1443 - val_loss: 2.9456 - val_acc: 0.1350\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9452 - acc: 0.1236 - val_loss: 2.9548 - val_acc: 0.1288\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9419 - acc: 0.1280 - val_loss: 2.9532 - val_acc: 0.1288\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9301 - acc: 0.1323 - val_loss: 2.9294 - val_acc: 0.1350\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.9342 - acc: 0.1312 - val_loss: 2.9198 - val_acc: 0.1411\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.9223 - acc: 0.1486 - val_loss: 2.9279 - val_acc: 0.1350\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.9282 - acc: 0.1334 - val_loss: 2.9339 - val_acc: 0.1350\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9365 - acc: 0.1497 - val_loss: 2.9310 - val_acc: 0.1350\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9159 - acc: 0.1323 - val_loss: 2.9244 - val_acc: 0.1411\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.9013 - acc: 0.1670 - val_loss: 2.9232 - val_acc: 0.1411\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.9335 - acc: 0.1410 - val_loss: 2.9173 - val_acc: 0.1411\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9653 - acc: 0.1334 - val_loss: 2.9097 - val_acc: 0.1472\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.8948 - acc: 0.1443 - val_loss: 2.9128 - val_acc: 0.1411\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9344 - acc: 0.1432 - val_loss: 2.9158 - val_acc: 0.1411\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.9058 - acc: 0.1529 - val_loss: 2.9153 - val_acc: 0.1350\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.9191 - acc: 0.1518 - val_loss: 2.9090 - val_acc: 0.1411\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9074 - acc: 0.1334 - val_loss: 2.9025 - val_acc: 0.1411\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.8891 - acc: 0.1453 - val_loss: 2.8954 - val_acc: 0.1534\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.9168 - acc: 0.1518 - val_loss: 2.8852 - val_acc: 0.1595\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9121 - acc: 0.1356 - val_loss: 2.8828 - val_acc: 0.1656\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9602 - acc: 0.1323 - val_loss: 2.8889 - val_acc: 0.1595\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.9051 - acc: 0.1312 - val_loss: 2.8964 - val_acc: 0.1472\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.8869 - acc: 0.1497 - val_loss: 2.9127 - val_acc: 0.1411\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.9127 - acc: 0.1486 - val_loss: 2.9117 - val_acc: 0.1472\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.9309 - acc: 0.1421 - val_loss: 2.8941 - val_acc: 0.1472\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.8911 - acc: 0.1464 - val_loss: 2.8838 - val_acc: 0.1595\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.9037 - acc: 0.1367 - val_loss: 2.8800 - val_acc: 0.1718\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.8612 - acc: 0.1443 - val_loss: 2.8805 - val_acc: 0.1718\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.8868 - acc: 0.1497 - val_loss: 2.8919 - val_acc: 0.1595\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.8603 - acc: 0.1540 - val_loss: 2.9026 - val_acc: 0.1472\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.8718 - acc: 0.1551 - val_loss: 2.9018 - val_acc: 0.1534\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.8837 - acc: 0.1562 - val_loss: 2.8935 - val_acc: 0.1595\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.8636 - acc: 0.1703 - val_loss: 2.8863 - val_acc: 0.1718\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.8930 - acc: 0.1464 - val_loss: 2.8771 - val_acc: 0.1595\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.8893 - acc: 0.1475 - val_loss: 2.8715 - val_acc: 0.1656\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.9057 - acc: 0.1443 - val_loss: 2.8703 - val_acc: 0.1656\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.8691 - acc: 0.1540 - val_loss: 2.8797 - val_acc: 0.1595\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.8724 - acc: 0.1616 - val_loss: 2.8920 - val_acc: 0.1656\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.8474 - acc: 0.1638 - val_loss: 2.9034 - val_acc: 0.1595\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.8758 - acc: 0.1605 - val_loss: 2.8967 - val_acc: 0.1595\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.8738 - acc: 0.1768 - val_loss: 2.8774 - val_acc: 0.1656\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.8427 - acc: 0.1616 - val_loss: 2.8584 - val_acc: 0.1595\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.8980 - acc: 0.1584 - val_loss: 2.8503 - val_acc: 0.1534\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.8556 - acc: 0.1649 - val_loss: 2.8515 - val_acc: 0.1411\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.8753 - acc: 0.1518 - val_loss: 2.8633 - val_acc: 0.1411\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.8553 - acc: 0.1649 - val_loss: 2.8684 - val_acc: 0.1227\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.8590 - acc: 0.1692 - val_loss: 2.8528 - val_acc: 0.1350\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.8600 - acc: 0.1627 - val_loss: 2.8406 - val_acc: 0.1472\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.8465 - acc: 0.1649 - val_loss: 2.8357 - val_acc: 0.1534\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.8510 - acc: 0.1670 - val_loss: 2.8434 - val_acc: 0.1656\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.8648 - acc: 0.1725 - val_loss: 2.8465 - val_acc: 0.2025\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.8557 - acc: 0.1551 - val_loss: 2.8398 - val_acc: 0.1963\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.8481 - acc: 0.1562 - val_loss: 2.8272 - val_acc: 0.2025\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.8486 - acc: 0.1735 - val_loss: 2.8204 - val_acc: 0.2025\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.8488 - acc: 0.1757 - val_loss: 2.8249 - val_acc: 0.2025\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.8339 - acc: 0.1649 - val_loss: 2.8370 - val_acc: 0.1963\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.8264 - acc: 0.1725 - val_loss: 2.8391 - val_acc: 0.1963\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.8529 - acc: 0.1562 - val_loss: 2.8281 - val_acc: 0.2086\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 2.8576 - acc: 0.1692 - val_loss: 2.8204 - val_acc: 0.2086\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.8368 - acc: 0.1649 - val_loss: 2.8207 - val_acc: 0.1779\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.8204 - acc: 0.1594 - val_loss: 2.8292 - val_acc: 0.1718\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.8205 - acc: 0.1735 - val_loss: 2.8432 - val_acc: 0.1656\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.8232 - acc: 0.1594 - val_loss: 2.8453 - val_acc: 0.1718\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.8334 - acc: 0.1779 - val_loss: 2.8347 - val_acc: 0.2086\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.8145 - acc: 0.1746 - val_loss: 2.8152 - val_acc: 0.2025\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.8101 - acc: 0.1746 - val_loss: 2.8038 - val_acc: 0.1963\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.7867 - acc: 0.1963 - val_loss: 2.8003 - val_acc: 0.1963\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.7970 - acc: 0.1931 - val_loss: 2.8013 - val_acc: 0.1963\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.8022 - acc: 0.1725 - val_loss: 2.7998 - val_acc: 0.1902\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.7864 - acc: 0.1790 - val_loss: 2.8004 - val_acc: 0.1963\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.7934 - acc: 0.1779 - val_loss: 2.8009 - val_acc: 0.1963\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.8154 - acc: 0.1855 - val_loss: 2.8025 - val_acc: 0.1963\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.7746 - acc: 0.1887 - val_loss: 2.8041 - val_acc: 0.1963\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.8056 - acc: 0.1844 - val_loss: 2.8012 - val_acc: 0.1902\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.8047 - acc: 0.1952 - val_loss: 2.7921 - val_acc: 0.1902\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.7985 - acc: 0.1985 - val_loss: 2.7877 - val_acc: 0.1902\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.7702 - acc: 0.1963 - val_loss: 2.7852 - val_acc: 0.1902\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.7746 - acc: 0.1952 - val_loss: 2.7880 - val_acc: 0.1963\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.7694 - acc: 0.1909 - val_loss: 2.7937 - val_acc: 0.1963\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.7679 - acc: 0.1876 - val_loss: 2.7992 - val_acc: 0.1963\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.7620 - acc: 0.2061 - val_loss: 2.7948 - val_acc: 0.1963\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.7702 - acc: 0.1876 - val_loss: 2.7854 - val_acc: 0.1963\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.7829 - acc: 0.1898 - val_loss: 2.7821 - val_acc: 0.1902\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.7670 - acc: 0.1996 - val_loss: 2.7841 - val_acc: 0.1902\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.7509 - acc: 0.2017 - val_loss: 2.7922 - val_acc: 0.1963\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.7526 - acc: 0.2039 - val_loss: 2.7902 - val_acc: 0.1963\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.7446 - acc: 0.1887 - val_loss: 2.7752 - val_acc: 0.1963\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.7534 - acc: 0.1800 - val_loss: 2.7636 - val_acc: 0.1902\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.7358 - acc: 0.2039 - val_loss: 2.7614 - val_acc: 0.1902\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.7290 - acc: 0.1974 - val_loss: 2.7676 - val_acc: 0.1963\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.7360 - acc: 0.2007 - val_loss: 2.7794 - val_acc: 0.1963\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.7367 - acc: 0.1996 - val_loss: 2.7862 - val_acc: 0.1963\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.7529 - acc: 0.2050 - val_loss: 2.7675 - val_acc: 0.1963\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.7310 - acc: 0.1963 - val_loss: 2.7538 - val_acc: 0.1902\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.7363 - acc: 0.2007 - val_loss: 2.7478 - val_acc: 0.1902\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.7158 - acc: 0.1931 - val_loss: 2.7478 - val_acc: 0.1902\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.7225 - acc: 0.2017 - val_loss: 2.7579 - val_acc: 0.1963\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.7431 - acc: 0.2082 - val_loss: 2.7638 - val_acc: 0.1963\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.7298 - acc: 0.2007 - val_loss: 2.7603 - val_acc: 0.1963\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.7197 - acc: 0.2007 - val_loss: 2.7535 - val_acc: 0.1902\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.7311 - acc: 0.1931 - val_loss: 2.7472 - val_acc: 0.1902\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.7077 - acc: 0.1952 - val_loss: 2.7497 - val_acc: 0.1902\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6948 - acc: 0.1887 - val_loss: 2.7531 - val_acc: 0.1963\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.7121 - acc: 0.2039 - val_loss: 2.7608 - val_acc: 0.1963\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.7057 - acc: 0.1985 - val_loss: 2.7599 - val_acc: 0.1963\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.6611 - acc: 0.2082 - val_loss: 2.7580 - val_acc: 0.1963\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6893 - acc: 0.2050 - val_loss: 2.7497 - val_acc: 0.1902\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.6816 - acc: 0.2050 - val_loss: 2.7443 - val_acc: 0.1902\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.7128 - acc: 0.1866 - val_loss: 2.7423 - val_acc: 0.1902\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.6857 - acc: 0.2017 - val_loss: 2.7515 - val_acc: 0.2025\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.7289 - acc: 0.1844 - val_loss: 2.7531 - val_acc: 0.2025\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6900 - acc: 0.2039 - val_loss: 2.7465 - val_acc: 0.1902\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.6831 - acc: 0.1887 - val_loss: 2.7417 - val_acc: 0.1902\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6969 - acc: 0.1996 - val_loss: 2.7357 - val_acc: 0.1902\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.6941 - acc: 0.2007 - val_loss: 2.7396 - val_acc: 0.1902\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.6775 - acc: 0.2104 - val_loss: 2.7471 - val_acc: 0.1963\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.6690 - acc: 0.2050 - val_loss: 2.7535 - val_acc: 0.1963\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.6809 - acc: 0.2126 - val_loss: 2.7549 - val_acc: 0.1902\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.6743 - acc: 0.2028 - val_loss: 2.7554 - val_acc: 0.1902\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.6624 - acc: 0.2050 - val_loss: 2.7487 - val_acc: 0.1963\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.6977 - acc: 0.2007 - val_loss: 2.7425 - val_acc: 0.2025\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.6706 - acc: 0.2082 - val_loss: 2.7395 - val_acc: 0.2025\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.6658 - acc: 0.2169 - val_loss: 2.7397 - val_acc: 0.1963\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.6610 - acc: 0.2072 - val_loss: 2.7452 - val_acc: 0.1902\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.6734 - acc: 0.2050 - val_loss: 2.7538 - val_acc: 0.1963\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.6847 - acc: 0.2050 - val_loss: 2.7512 - val_acc: 0.1902\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.6609 - acc: 0.1985 - val_loss: 2.7405 - val_acc: 0.1902\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.6589 - acc: 0.2126 - val_loss: 2.7358 - val_acc: 0.1902\n",
            "Epoch 275/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.6614 - acc: 0.2050 - val_loss: 2.7386 - val_acc: 0.1963\n",
            "Epoch 276/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.6417 - acc: 0.2039 - val_loss: 2.7416 - val_acc: 0.1963\n",
            "Epoch 277/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.6531 - acc: 0.2158 - val_loss: 2.7388 - val_acc: 0.1902\n",
            "Epoch 278/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.6498 - acc: 0.2169 - val_loss: 2.7323 - val_acc: 0.1963\n",
            "Epoch 279/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.6671 - acc: 0.2061 - val_loss: 2.7259 - val_acc: 0.1902\n",
            "Epoch 280/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.6576 - acc: 0.2017 - val_loss: 2.7283 - val_acc: 0.1902\n",
            "Epoch 281/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.6658 - acc: 0.1996 - val_loss: 2.7291 - val_acc: 0.1963\n",
            "Epoch 282/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.6331 - acc: 0.2202 - val_loss: 2.7264 - val_acc: 0.1963\n",
            "Epoch 283/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.6552 - acc: 0.2028 - val_loss: 2.7238 - val_acc: 0.1902\n",
            "Epoch 284/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.6297 - acc: 0.2072 - val_loss: 2.7255 - val_acc: 0.1963\n",
            "Epoch 285/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.6453 - acc: 0.2115 - val_loss: 2.7316 - val_acc: 0.1963\n",
            "Epoch 286/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.6597 - acc: 0.2061 - val_loss: 2.7354 - val_acc: 0.2025\n",
            "Epoch 287/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.6456 - acc: 0.2104 - val_loss: 2.7350 - val_acc: 0.2025\n",
            "Epoch 288/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.6514 - acc: 0.2115 - val_loss: 2.7304 - val_acc: 0.2025\n",
            "Epoch 289/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.6477 - acc: 0.2072 - val_loss: 2.7252 - val_acc: 0.1963\n",
            "Epoch 290/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6480 - acc: 0.2104 - val_loss: 2.7242 - val_acc: 0.1963\n",
            "Epoch 291/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.6561 - acc: 0.2223 - val_loss: 2.7237 - val_acc: 0.1963\n",
            "Epoch 292/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.6280 - acc: 0.2158 - val_loss: 2.7187 - val_acc: 0.1963\n",
            "Epoch 293/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.6564 - acc: 0.2169 - val_loss: 2.7127 - val_acc: 0.1963\n",
            "Epoch 294/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.6355 - acc: 0.2115 - val_loss: 2.7121 - val_acc: 0.1963\n",
            "Epoch 295/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.6345 - acc: 0.2158 - val_loss: 2.7117 - val_acc: 0.1963\n",
            "Epoch 296/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.6359 - acc: 0.2017 - val_loss: 2.7164 - val_acc: 0.1963\n",
            "Epoch 297/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.6147 - acc: 0.2104 - val_loss: 2.7155 - val_acc: 0.1963\n",
            "Epoch 298/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6195 - acc: 0.2039 - val_loss: 2.7190 - val_acc: 0.2025\n",
            "Epoch 299/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.6027 - acc: 0.2158 - val_loss: 2.7309 - val_acc: 0.2025\n",
            "Epoch 300/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6393 - acc: 0.2082 - val_loss: 2.7210 - val_acc: 0.1963\n",
            "Epoch 301/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.6293 - acc: 0.1974 - val_loss: 2.7180 - val_acc: 0.1963\n",
            "Epoch 302/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.6245 - acc: 0.2093 - val_loss: 2.7153 - val_acc: 0.2025\n",
            "Epoch 303/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.6240 - acc: 0.2039 - val_loss: 2.7141 - val_acc: 0.1963\n",
            "Epoch 304/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.5935 - acc: 0.2148 - val_loss: 2.7129 - val_acc: 0.1963\n",
            "Epoch 305/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.6025 - acc: 0.2072 - val_loss: 2.7121 - val_acc: 0.2025\n",
            "Epoch 306/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.6168 - acc: 0.2039 - val_loss: 2.7146 - val_acc: 0.2025\n",
            "Epoch 307/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.5982 - acc: 0.2169 - val_loss: 2.7169 - val_acc: 0.2025\n",
            "Epoch 308/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5854 - acc: 0.2191 - val_loss: 2.7080 - val_acc: 0.2025\n",
            "Epoch 309/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.6290 - acc: 0.1941 - val_loss: 2.6997 - val_acc: 0.2025\n",
            "Epoch 310/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.5786 - acc: 0.2256 - val_loss: 2.6987 - val_acc: 0.2025\n",
            "Epoch 311/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.6395 - acc: 0.2039 - val_loss: 2.7002 - val_acc: 0.2025\n",
            "Epoch 312/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5715 - acc: 0.2104 - val_loss: 2.7077 - val_acc: 0.2025\n",
            "Epoch 313/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.6022 - acc: 0.2126 - val_loss: 2.7073 - val_acc: 0.2025\n",
            "Epoch 314/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.6273 - acc: 0.2061 - val_loss: 2.7191 - val_acc: 0.2025\n",
            "Epoch 315/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.6223 - acc: 0.2158 - val_loss: 2.7328 - val_acc: 0.2025\n",
            "Epoch 316/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.6041 - acc: 0.2256 - val_loss: 2.7316 - val_acc: 0.2086\n",
            "Epoch 317/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5987 - acc: 0.2180 - val_loss: 2.7175 - val_acc: 0.2086\n",
            "Epoch 318/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.5747 - acc: 0.2148 - val_loss: 2.7047 - val_acc: 0.2086\n",
            "Epoch 319/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.5901 - acc: 0.2180 - val_loss: 2.6995 - val_acc: 0.2025\n",
            "Epoch 320/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5773 - acc: 0.2223 - val_loss: 2.7067 - val_acc: 0.1963\n",
            "Epoch 321/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6138 - acc: 0.2213 - val_loss: 2.7071 - val_acc: 0.1963\n",
            "Epoch 322/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5838 - acc: 0.2191 - val_loss: 2.6908 - val_acc: 0.2025\n",
            "Epoch 323/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5773 - acc: 0.2115 - val_loss: 2.6917 - val_acc: 0.2086\n",
            "Epoch 324/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.5711 - acc: 0.2158 - val_loss: 2.6910 - val_acc: 0.2025\n",
            "Epoch 325/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.5862 - acc: 0.2202 - val_loss: 2.6967 - val_acc: 0.2025\n",
            "Epoch 326/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5696 - acc: 0.2223 - val_loss: 2.6994 - val_acc: 0.2025\n",
            "Epoch 327/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5899 - acc: 0.2234 - val_loss: 2.6961 - val_acc: 0.2025\n",
            "Epoch 328/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5839 - acc: 0.2158 - val_loss: 2.6907 - val_acc: 0.2025\n",
            "Epoch 329/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.5850 - acc: 0.2191 - val_loss: 2.6887 - val_acc: 0.2086\n",
            "Epoch 330/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5952 - acc: 0.2180 - val_loss: 2.6846 - val_acc: 0.2086\n",
            "Epoch 331/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5727 - acc: 0.2093 - val_loss: 2.6819 - val_acc: 0.2086\n",
            "Epoch 332/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.5981 - acc: 0.2191 - val_loss: 2.6801 - val_acc: 0.2086\n",
            "Epoch 333/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.5833 - acc: 0.2158 - val_loss: 2.6821 - val_acc: 0.1963\n",
            "Epoch 334/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5719 - acc: 0.2093 - val_loss: 2.6845 - val_acc: 0.1963\n",
            "Epoch 335/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5804 - acc: 0.2191 - val_loss: 2.6886 - val_acc: 0.2086\n",
            "Epoch 336/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.5623 - acc: 0.2202 - val_loss: 2.6883 - val_acc: 0.2086\n",
            "Epoch 337/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5457 - acc: 0.2245 - val_loss: 2.6910 - val_acc: 0.2147\n",
            "Epoch 338/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.5858 - acc: 0.2050 - val_loss: 2.6961 - val_acc: 0.2147\n",
            "Epoch 339/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.5683 - acc: 0.2191 - val_loss: 2.6884 - val_acc: 0.2086\n",
            "Epoch 340/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.5853 - acc: 0.2245 - val_loss: 2.6973 - val_acc: 0.2025\n",
            "Epoch 341/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5626 - acc: 0.2245 - val_loss: 2.6971 - val_acc: 0.2025\n",
            "Epoch 342/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5632 - acc: 0.2234 - val_loss: 2.6930 - val_acc: 0.2025\n",
            "Epoch 343/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.5489 - acc: 0.2213 - val_loss: 2.6901 - val_acc: 0.2086\n",
            "Epoch 344/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.5474 - acc: 0.2234 - val_loss: 2.6907 - val_acc: 0.2086\n",
            "Epoch 345/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5486 - acc: 0.2278 - val_loss: 2.6974 - val_acc: 0.2086\n",
            "Epoch 346/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5688 - acc: 0.2245 - val_loss: 2.6987 - val_acc: 0.2086\n",
            "Epoch 347/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5499 - acc: 0.2234 - val_loss: 2.7042 - val_acc: 0.2025\n",
            "Epoch 348/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.5544 - acc: 0.2289 - val_loss: 2.7016 - val_acc: 0.2025\n",
            "Epoch 349/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.5609 - acc: 0.2180 - val_loss: 2.6919 - val_acc: 0.2147\n",
            "Epoch 350/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.5582 - acc: 0.2126 - val_loss: 2.6951 - val_acc: 0.2147\n",
            "Epoch 351/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.5749 - acc: 0.2191 - val_loss: 2.6958 - val_acc: 0.2147\n",
            "Epoch 352/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5597 - acc: 0.2375 - val_loss: 2.7013 - val_acc: 0.2086\n",
            "Epoch 353/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5507 - acc: 0.2332 - val_loss: 2.7081 - val_acc: 0.2025\n",
            "Epoch 354/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.5458 - acc: 0.2386 - val_loss: 2.7092 - val_acc: 0.2025\n",
            "Epoch 355/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5429 - acc: 0.2321 - val_loss: 2.7021 - val_acc: 0.2086\n",
            "Epoch 356/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.5422 - acc: 0.2375 - val_loss: 2.6899 - val_acc: 0.2025\n",
            "Epoch 357/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5477 - acc: 0.2354 - val_loss: 2.6803 - val_acc: 0.2086\n",
            "Epoch 358/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.5631 - acc: 0.2191 - val_loss: 2.6760 - val_acc: 0.2086\n",
            "Epoch 359/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.5437 - acc: 0.2354 - val_loss: 2.6743 - val_acc: 0.2147\n",
            "Epoch 360/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.5629 - acc: 0.2245 - val_loss: 2.6777 - val_acc: 0.2086\n",
            "Epoch 361/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5424 - acc: 0.2202 - val_loss: 2.6834 - val_acc: 0.2025\n",
            "Epoch 362/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5284 - acc: 0.2223 - val_loss: 2.6860 - val_acc: 0.2147\n",
            "Epoch 363/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5425 - acc: 0.2223 - val_loss: 2.6859 - val_acc: 0.2147\n",
            "Epoch 364/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5347 - acc: 0.2375 - val_loss: 2.6831 - val_acc: 0.2147\n",
            "Epoch 365/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5430 - acc: 0.2321 - val_loss: 2.6817 - val_acc: 0.2147\n",
            "Epoch 366/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5481 - acc: 0.2191 - val_loss: 2.6817 - val_acc: 0.2086\n",
            "Epoch 367/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 2.5193 - acc: 0.2364 - val_loss: 2.6926 - val_acc: 0.2086\n",
            "Epoch 368/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.5499 - acc: 0.2267 - val_loss: 2.6959 - val_acc: 0.2025\n",
            "Epoch 369/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5212 - acc: 0.2462 - val_loss: 2.6865 - val_acc: 0.2086\n",
            "Epoch 370/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.5522 - acc: 0.2223 - val_loss: 2.6863 - val_acc: 0.2270\n",
            "Epoch 371/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5340 - acc: 0.2223 - val_loss: 2.6822 - val_acc: 0.2147\n",
            "Epoch 372/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.5369 - acc: 0.2202 - val_loss: 2.6896 - val_acc: 0.1963\n",
            "Epoch 373/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.5395 - acc: 0.2278 - val_loss: 2.6933 - val_acc: 0.1963\n",
            "Epoch 374/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5356 - acc: 0.2375 - val_loss: 2.6730 - val_acc: 0.2147\n",
            "Epoch 375/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.5309 - acc: 0.2202 - val_loss: 2.6771 - val_acc: 0.2331\n",
            "Epoch 376/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5262 - acc: 0.2408 - val_loss: 2.6812 - val_acc: 0.2086\n",
            "Epoch 377/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5338 - acc: 0.2256 - val_loss: 2.6951 - val_acc: 0.1963\n",
            "Epoch 378/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5235 - acc: 0.2299 - val_loss: 2.6933 - val_acc: 0.1963\n",
            "Epoch 379/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.5625 - acc: 0.2299 - val_loss: 2.6696 - val_acc: 0.2086\n",
            "Epoch 380/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.5300 - acc: 0.2191 - val_loss: 2.6642 - val_acc: 0.2209\n",
            "Epoch 381/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5446 - acc: 0.2332 - val_loss: 2.6615 - val_acc: 0.2147\n",
            "Epoch 382/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.5279 - acc: 0.2343 - val_loss: 2.6678 - val_acc: 0.2086\n",
            "Epoch 383/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.5336 - acc: 0.2256 - val_loss: 2.6771 - val_acc: 0.2086\n",
            "Epoch 384/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.5397 - acc: 0.2289 - val_loss: 2.6728 - val_acc: 0.2086\n",
            "Epoch 385/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5235 - acc: 0.2256 - val_loss: 2.6712 - val_acc: 0.2147\n",
            "Epoch 386/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5103 - acc: 0.2451 - val_loss: 2.6749 - val_acc: 0.2025\n",
            "Epoch 387/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.5193 - acc: 0.2440 - val_loss: 2.6788 - val_acc: 0.1963\n",
            "Epoch 388/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5168 - acc: 0.2451 - val_loss: 2.6720 - val_acc: 0.2025\n",
            "Epoch 389/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5242 - acc: 0.2375 - val_loss: 2.6697 - val_acc: 0.2025\n",
            "Epoch 390/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5290 - acc: 0.2223 - val_loss: 2.6852 - val_acc: 0.2025\n",
            "Epoch 391/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.5205 - acc: 0.2364 - val_loss: 2.6929 - val_acc: 0.2025\n",
            "Epoch 392/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5232 - acc: 0.2256 - val_loss: 2.6776 - val_acc: 0.2025\n",
            "Epoch 393/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5113 - acc: 0.2299 - val_loss: 2.6726 - val_acc: 0.2209\n",
            "Epoch 394/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.5392 - acc: 0.2321 - val_loss: 2.6738 - val_acc: 0.2086\n",
            "Epoch 395/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5153 - acc: 0.2332 - val_loss: 2.6861 - val_acc: 0.1963\n",
            "Epoch 396/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5147 - acc: 0.2354 - val_loss: 2.6956 - val_acc: 0.1963\n",
            "Epoch 397/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.5273 - acc: 0.2386 - val_loss: 2.6800 - val_acc: 0.1963\n",
            "Epoch 398/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.5136 - acc: 0.2386 - val_loss: 2.6628 - val_acc: 0.2086\n",
            "Epoch 399/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4996 - acc: 0.2386 - val_loss: 2.6635 - val_acc: 0.2086\n",
            "Epoch 400/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5177 - acc: 0.2245 - val_loss: 2.6755 - val_acc: 0.2025\n",
            "Epoch 401/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5008 - acc: 0.2495 - val_loss: 2.6929 - val_acc: 0.2147\n",
            "Epoch 402/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5218 - acc: 0.2364 - val_loss: 2.6880 - val_acc: 0.2147\n",
            "Epoch 403/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 2.5105 - acc: 0.2516 - val_loss: 2.6828 - val_acc: 0.2209\n",
            "Epoch 404/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.5153 - acc: 0.2364 - val_loss: 2.6835 - val_acc: 0.2025\n",
            "Epoch 405/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.5013 - acc: 0.2462 - val_loss: 2.6870 - val_acc: 0.2025\n",
            "Epoch 406/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5004 - acc: 0.2527 - val_loss: 2.6811 - val_acc: 0.2025\n",
            "Epoch 407/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4917 - acc: 0.2462 - val_loss: 2.6751 - val_acc: 0.2086\n",
            "Epoch 408/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4989 - acc: 0.2310 - val_loss: 2.6798 - val_acc: 0.2147\n",
            "Epoch 409/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.5048 - acc: 0.2538 - val_loss: 2.6920 - val_acc: 0.2086\n",
            "Epoch 410/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.4950 - acc: 0.2397 - val_loss: 2.6958 - val_acc: 0.2147\n",
            "Epoch 411/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.5332 - acc: 0.2440 - val_loss: 2.6800 - val_acc: 0.2147\n",
            "Epoch 412/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.5209 - acc: 0.2343 - val_loss: 2.6684 - val_acc: 0.2209\n",
            "Epoch 413/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4967 - acc: 0.2603 - val_loss: 2.6757 - val_acc: 0.2025\n",
            "Epoch 414/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.5126 - acc: 0.2430 - val_loss: 2.6923 - val_acc: 0.1963\n",
            "Epoch 415/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5241 - acc: 0.2375 - val_loss: 2.6774 - val_acc: 0.2025\n",
            "Epoch 416/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.5041 - acc: 0.2408 - val_loss: 2.6644 - val_acc: 0.2270\n",
            "Epoch 417/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5108 - acc: 0.2451 - val_loss: 2.6607 - val_acc: 0.2331\n",
            "Epoch 418/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4991 - acc: 0.2375 - val_loss: 2.6666 - val_acc: 0.2086\n",
            "Epoch 419/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5039 - acc: 0.2462 - val_loss: 2.6823 - val_acc: 0.2147\n",
            "Epoch 420/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5078 - acc: 0.2440 - val_loss: 2.6703 - val_acc: 0.2209\n",
            "Epoch 421/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.5097 - acc: 0.2332 - val_loss: 2.6609 - val_acc: 0.2393\n",
            "Epoch 422/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.4983 - acc: 0.2343 - val_loss: 2.6562 - val_acc: 0.2209\n",
            "Epoch 423/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4937 - acc: 0.2343 - val_loss: 2.6552 - val_acc: 0.2086\n",
            "Epoch 424/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4933 - acc: 0.2375 - val_loss: 2.6560 - val_acc: 0.2086\n",
            "Epoch 425/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5081 - acc: 0.2440 - val_loss: 2.6512 - val_acc: 0.2086\n",
            "Epoch 426/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5053 - acc: 0.2397 - val_loss: 2.6494 - val_acc: 0.2270\n",
            "Epoch 427/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4842 - acc: 0.2419 - val_loss: 2.6560 - val_acc: 0.2209\n",
            "Epoch 428/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4908 - acc: 0.2354 - val_loss: 2.6598 - val_acc: 0.2209\n",
            "Epoch 429/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.4966 - acc: 0.2397 - val_loss: 2.6530 - val_acc: 0.2147\n",
            "Epoch 430/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4871 - acc: 0.2592 - val_loss: 2.6503 - val_acc: 0.2025\n",
            "Epoch 431/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4729 - acc: 0.2462 - val_loss: 2.6506 - val_acc: 0.2086\n",
            "Epoch 432/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4783 - acc: 0.2451 - val_loss: 2.6490 - val_acc: 0.2086\n",
            "Epoch 433/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4836 - acc: 0.2343 - val_loss: 2.6455 - val_acc: 0.2147\n",
            "Epoch 434/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4866 - acc: 0.2603 - val_loss: 2.6463 - val_acc: 0.2086\n",
            "Epoch 435/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.4768 - acc: 0.2549 - val_loss: 2.6541 - val_acc: 0.2086\n",
            "Epoch 436/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4744 - acc: 0.2527 - val_loss: 2.6513 - val_acc: 0.2147\n",
            "Epoch 437/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.4780 - acc: 0.2451 - val_loss: 2.6449 - val_acc: 0.2270\n",
            "Epoch 438/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4803 - acc: 0.2430 - val_loss: 2.6441 - val_acc: 0.2147\n",
            "Epoch 439/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4908 - acc: 0.2440 - val_loss: 2.6465 - val_acc: 0.2147\n",
            "Epoch 440/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.4878 - acc: 0.2495 - val_loss: 2.6415 - val_acc: 0.2209\n",
            "Epoch 441/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4389 - acc: 0.2516 - val_loss: 2.6441 - val_acc: 0.2209\n",
            "Epoch 442/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4839 - acc: 0.2408 - val_loss: 2.6466 - val_acc: 0.2147\n",
            "Epoch 443/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.4671 - acc: 0.2440 - val_loss: 2.6424 - val_acc: 0.2147\n",
            "Epoch 444/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.4945 - acc: 0.2408 - val_loss: 2.6384 - val_acc: 0.2515\n",
            "Epoch 445/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.4772 - acc: 0.2690 - val_loss: 2.6402 - val_acc: 0.2209\n",
            "Epoch 446/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4815 - acc: 0.2495 - val_loss: 2.6463 - val_acc: 0.2086\n",
            "Epoch 447/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4834 - acc: 0.2484 - val_loss: 2.6528 - val_acc: 0.2086\n",
            "Epoch 448/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.4856 - acc: 0.2516 - val_loss: 2.6382 - val_acc: 0.2147\n",
            "Epoch 449/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4712 - acc: 0.2560 - val_loss: 2.6329 - val_acc: 0.2515\n",
            "Epoch 450/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.4867 - acc: 0.2440 - val_loss: 2.6361 - val_acc: 0.2209\n",
            "Epoch 451/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4744 - acc: 0.2538 - val_loss: 2.6438 - val_acc: 0.2086\n",
            "Epoch 452/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4856 - acc: 0.2581 - val_loss: 2.6343 - val_acc: 0.2147\n",
            "Epoch 453/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4796 - acc: 0.2430 - val_loss: 2.6295 - val_acc: 0.2209\n",
            "Epoch 454/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4661 - acc: 0.2538 - val_loss: 2.6314 - val_acc: 0.2270\n",
            "Epoch 455/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 2.4781 - acc: 0.2581 - val_loss: 2.6429 - val_acc: 0.2147\n",
            "Epoch 456/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.4828 - acc: 0.2560 - val_loss: 2.6385 - val_acc: 0.2147\n",
            "Epoch 457/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4613 - acc: 0.2636 - val_loss: 2.6350 - val_acc: 0.2147\n",
            "Epoch 458/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4545 - acc: 0.2538 - val_loss: 2.6321 - val_acc: 0.2209\n",
            "Epoch 459/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4753 - acc: 0.2560 - val_loss: 2.6298 - val_acc: 0.2209\n",
            "Epoch 460/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.5042 - acc: 0.2440 - val_loss: 2.6336 - val_acc: 0.2147\n",
            "Epoch 461/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.4528 - acc: 0.2516 - val_loss: 2.6323 - val_acc: 0.2147\n",
            "Epoch 462/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.4695 - acc: 0.2636 - val_loss: 2.6270 - val_acc: 0.2209\n",
            "Epoch 463/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4781 - acc: 0.2603 - val_loss: 2.6301 - val_acc: 0.2147\n",
            "Epoch 464/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.4777 - acc: 0.2614 - val_loss: 2.6276 - val_acc: 0.2147\n",
            "Epoch 465/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4735 - acc: 0.2581 - val_loss: 2.6234 - val_acc: 0.2147\n",
            "Epoch 466/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.4593 - acc: 0.2690 - val_loss: 2.6279 - val_acc: 0.2147\n",
            "Epoch 467/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.4556 - acc: 0.2603 - val_loss: 2.6339 - val_acc: 0.2147\n",
            "Epoch 468/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.4642 - acc: 0.2614 - val_loss: 2.6320 - val_acc: 0.2209\n",
            "Epoch 469/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.4736 - acc: 0.2516 - val_loss: 2.6301 - val_acc: 0.2515\n",
            "Epoch 470/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4771 - acc: 0.2560 - val_loss: 2.6375 - val_acc: 0.2147\n",
            "Epoch 471/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4680 - acc: 0.2549 - val_loss: 2.6521 - val_acc: 0.2086\n",
            "Epoch 472/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.4879 - acc: 0.2484 - val_loss: 2.6406 - val_acc: 0.2147\n",
            "Epoch 473/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4740 - acc: 0.2581 - val_loss: 2.6233 - val_acc: 0.2638\n",
            "Epoch 474/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4698 - acc: 0.2679 - val_loss: 2.6229 - val_acc: 0.2454\n",
            "Epoch 475/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.4511 - acc: 0.2592 - val_loss: 2.6229 - val_acc: 0.2209\n",
            "Epoch 476/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.4578 - acc: 0.2549 - val_loss: 2.6270 - val_acc: 0.2147\n",
            "Epoch 477/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4600 - acc: 0.2516 - val_loss: 2.6178 - val_acc: 0.2147\n",
            "Epoch 478/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4544 - acc: 0.2636 - val_loss: 2.6081 - val_acc: 0.2454\n",
            "Epoch 479/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4571 - acc: 0.2560 - val_loss: 2.6040 - val_acc: 0.2331\n",
            "Epoch 480/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4556 - acc: 0.2505 - val_loss: 2.6073 - val_acc: 0.2209\n",
            "Epoch 481/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.4429 - acc: 0.2516 - val_loss: 2.6156 - val_acc: 0.2147\n",
            "Epoch 482/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4482 - acc: 0.2516 - val_loss: 2.6081 - val_acc: 0.2454\n",
            "Epoch 483/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.4564 - acc: 0.2570 - val_loss: 2.6086 - val_acc: 0.2577\n",
            "Epoch 484/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4547 - acc: 0.2560 - val_loss: 2.6138 - val_acc: 0.2515\n",
            "Epoch 485/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4457 - acc: 0.2603 - val_loss: 2.6288 - val_acc: 0.2147\n",
            "Epoch 486/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.4454 - acc: 0.2722 - val_loss: 2.6107 - val_acc: 0.2331\n",
            "Epoch 487/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.4476 - acc: 0.2701 - val_loss: 2.6039 - val_acc: 0.2515\n",
            "Epoch 488/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4365 - acc: 0.2495 - val_loss: 2.6028 - val_acc: 0.2454\n",
            "Epoch 489/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.4356 - acc: 0.2722 - val_loss: 2.6060 - val_acc: 0.2270\n",
            "Epoch 490/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4383 - acc: 0.2570 - val_loss: 2.6116 - val_acc: 0.2147\n",
            "Epoch 491/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4518 - acc: 0.2798 - val_loss: 2.6037 - val_acc: 0.2209\n",
            "Epoch 492/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4534 - acc: 0.2549 - val_loss: 2.5959 - val_acc: 0.2515\n",
            "Epoch 493/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4287 - acc: 0.2679 - val_loss: 2.5998 - val_acc: 0.2393\n",
            "Epoch 494/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4581 - acc: 0.2733 - val_loss: 2.6016 - val_acc: 0.2331\n",
            "Epoch 495/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.4392 - acc: 0.2722 - val_loss: 2.5996 - val_acc: 0.2331\n",
            "Epoch 496/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4314 - acc: 0.2722 - val_loss: 2.5896 - val_acc: 0.2638\n",
            "Epoch 497/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.4469 - acc: 0.2766 - val_loss: 2.5993 - val_acc: 0.2331\n",
            "Epoch 498/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.4445 - acc: 0.2668 - val_loss: 2.6037 - val_acc: 0.2147\n",
            "Epoch 499/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.4252 - acc: 0.2657 - val_loss: 2.5813 - val_acc: 0.2761\n",
            "Epoch 500/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4337 - acc: 0.2614 - val_loss: 2.5842 - val_acc: 0.2515\n",
            "Epoch 501/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.4482 - acc: 0.2505 - val_loss: 2.6066 - val_acc: 0.2209\n",
            "Epoch 502/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4516 - acc: 0.2679 - val_loss: 2.6017 - val_acc: 0.2270\n",
            "Epoch 503/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4360 - acc: 0.2766 - val_loss: 2.5937 - val_acc: 0.2515\n",
            "Epoch 504/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4298 - acc: 0.2690 - val_loss: 2.5970 - val_acc: 0.2393\n",
            "Epoch 505/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4489 - acc: 0.2625 - val_loss: 2.6072 - val_acc: 0.2209\n",
            "Epoch 506/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.4333 - acc: 0.2625 - val_loss: 2.5953 - val_acc: 0.2331\n",
            "Epoch 507/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.4506 - acc: 0.2625 - val_loss: 2.5801 - val_acc: 0.2515\n",
            "Epoch 508/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4343 - acc: 0.2560 - val_loss: 2.5844 - val_acc: 0.2393\n",
            "Epoch 509/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4267 - acc: 0.2722 - val_loss: 2.5803 - val_acc: 0.2454\n",
            "Epoch 510/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4295 - acc: 0.2690 - val_loss: 2.5778 - val_acc: 0.2638\n",
            "Epoch 511/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4357 - acc: 0.2636 - val_loss: 2.5906 - val_acc: 0.2393\n",
            "Epoch 512/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4421 - acc: 0.2722 - val_loss: 2.5889 - val_acc: 0.2393\n",
            "Epoch 513/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.4273 - acc: 0.2755 - val_loss: 2.5970 - val_acc: 0.2454\n",
            "Epoch 514/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4160 - acc: 0.2679 - val_loss: 2.5974 - val_acc: 0.2577\n",
            "Epoch 515/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4201 - acc: 0.2744 - val_loss: 2.6018 - val_acc: 0.2515\n",
            "Epoch 516/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.4170 - acc: 0.2668 - val_loss: 2.6024 - val_acc: 0.2515\n",
            "Epoch 517/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4331 - acc: 0.2766 - val_loss: 2.6019 - val_acc: 0.2515\n",
            "Epoch 518/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.4360 - acc: 0.2646 - val_loss: 2.5891 - val_acc: 0.2761\n",
            "Epoch 519/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4345 - acc: 0.2657 - val_loss: 2.5957 - val_acc: 0.2454\n",
            "Epoch 520/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4269 - acc: 0.2744 - val_loss: 2.6025 - val_acc: 0.2331\n",
            "Epoch 521/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.4233 - acc: 0.2679 - val_loss: 2.5768 - val_acc: 0.2761\n",
            "Epoch 522/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.4323 - acc: 0.2679 - val_loss: 2.5768 - val_acc: 0.2577\n",
            "Epoch 523/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.4268 - acc: 0.2711 - val_loss: 2.6034 - val_acc: 0.2331\n",
            "Epoch 524/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.4097 - acc: 0.2701 - val_loss: 2.5914 - val_acc: 0.2331\n",
            "Epoch 525/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.4125 - acc: 0.2798 - val_loss: 2.5719 - val_acc: 0.2761\n",
            "Epoch 526/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4190 - acc: 0.2516 - val_loss: 2.5878 - val_acc: 0.2393\n",
            "Epoch 527/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4184 - acc: 0.2809 - val_loss: 2.5815 - val_acc: 0.2454\n",
            "Epoch 528/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3924 - acc: 0.2798 - val_loss: 2.5745 - val_acc: 0.2515\n",
            "Epoch 529/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.4147 - acc: 0.2798 - val_loss: 2.5754 - val_acc: 0.2515\n",
            "Epoch 530/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.4067 - acc: 0.2831 - val_loss: 2.5779 - val_acc: 0.2515\n",
            "Epoch 531/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4109 - acc: 0.2777 - val_loss: 2.5837 - val_acc: 0.2454\n",
            "Epoch 532/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4044 - acc: 0.2733 - val_loss: 2.5594 - val_acc: 0.2761\n",
            "Epoch 533/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4073 - acc: 0.2603 - val_loss: 2.5714 - val_acc: 0.2577\n",
            "Epoch 534/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4200 - acc: 0.2755 - val_loss: 2.5776 - val_acc: 0.2454\n",
            "Epoch 535/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4270 - acc: 0.2711 - val_loss: 2.5674 - val_acc: 0.2638\n",
            "Epoch 536/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3920 - acc: 0.2852 - val_loss: 2.5700 - val_acc: 0.2699\n",
            "Epoch 537/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 2.4269 - acc: 0.2798 - val_loss: 2.6056 - val_acc: 0.2331\n",
            "Epoch 538/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.4201 - acc: 0.2722 - val_loss: 2.5540 - val_acc: 0.2761\n",
            "Epoch 539/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4194 - acc: 0.2733 - val_loss: 2.5564 - val_acc: 0.2699\n",
            "Epoch 540/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4126 - acc: 0.2809 - val_loss: 2.5931 - val_acc: 0.2331\n",
            "Epoch 541/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4139 - acc: 0.2722 - val_loss: 2.5540 - val_acc: 0.2761\n",
            "Epoch 542/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4047 - acc: 0.2809 - val_loss: 2.5622 - val_acc: 0.2699\n",
            "Epoch 543/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3924 - acc: 0.2831 - val_loss: 2.6067 - val_acc: 0.2270\n",
            "Epoch 544/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4072 - acc: 0.2787 - val_loss: 2.5543 - val_acc: 0.2761\n",
            "Epoch 545/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.4121 - acc: 0.2668 - val_loss: 2.5475 - val_acc: 0.2761\n",
            "Epoch 546/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.4010 - acc: 0.2722 - val_loss: 2.6100 - val_acc: 0.2147\n",
            "Epoch 547/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4332 - acc: 0.2744 - val_loss: 2.5576 - val_acc: 0.2577\n",
            "Epoch 548/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4078 - acc: 0.2527 - val_loss: 2.5488 - val_acc: 0.2699\n",
            "Epoch 549/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4021 - acc: 0.2842 - val_loss: 2.5811 - val_acc: 0.2331\n",
            "Epoch 550/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.4024 - acc: 0.2809 - val_loss: 2.5585 - val_acc: 0.2515\n",
            "Epoch 551/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3996 - acc: 0.2777 - val_loss: 2.5383 - val_acc: 0.2699\n",
            "Epoch 552/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.3969 - acc: 0.2744 - val_loss: 2.5674 - val_acc: 0.2331\n",
            "Epoch 553/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4175 - acc: 0.2744 - val_loss: 2.5885 - val_acc: 0.2270\n",
            "Epoch 554/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3912 - acc: 0.2863 - val_loss: 2.5467 - val_acc: 0.2638\n",
            "Epoch 555/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.3865 - acc: 0.2831 - val_loss: 2.5400 - val_acc: 0.2699\n",
            "Epoch 556/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4045 - acc: 0.2755 - val_loss: 2.5806 - val_acc: 0.2270\n",
            "Epoch 557/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4008 - acc: 0.2787 - val_loss: 2.5414 - val_acc: 0.2638\n",
            "Epoch 558/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.3818 - acc: 0.2787 - val_loss: 2.5476 - val_acc: 0.2761\n",
            "Epoch 559/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.4032 - acc: 0.2733 - val_loss: 2.5977 - val_acc: 0.2270\n",
            "Epoch 560/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3902 - acc: 0.2842 - val_loss: 2.5575 - val_acc: 0.2638\n",
            "Epoch 561/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3769 - acc: 0.2798 - val_loss: 2.5504 - val_acc: 0.2761\n",
            "Epoch 562/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3766 - acc: 0.2787 - val_loss: 2.5645 - val_acc: 0.2577\n",
            "Epoch 563/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3871 - acc: 0.2842 - val_loss: 2.5877 - val_acc: 0.2270\n",
            "Epoch 564/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.4006 - acc: 0.2733 - val_loss: 2.5529 - val_acc: 0.2699\n",
            "Epoch 565/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4253 - acc: 0.2495 - val_loss: 2.5475 - val_acc: 0.2699\n",
            "Epoch 566/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.3932 - acc: 0.2636 - val_loss: 2.5802 - val_acc: 0.2270\n",
            "Epoch 567/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3980 - acc: 0.2690 - val_loss: 2.5522 - val_acc: 0.2577\n",
            "Epoch 568/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.4061 - acc: 0.2657 - val_loss: 2.5412 - val_acc: 0.2822\n",
            "Epoch 569/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3984 - acc: 0.2744 - val_loss: 2.5607 - val_acc: 0.2393\n",
            "Epoch 570/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3950 - acc: 0.2787 - val_loss: 2.5656 - val_acc: 0.2393\n",
            "Epoch 571/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.3682 - acc: 0.2733 - val_loss: 2.5348 - val_acc: 0.2638\n",
            "Epoch 572/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3661 - acc: 0.2918 - val_loss: 2.5522 - val_acc: 0.2515\n",
            "Epoch 573/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3874 - acc: 0.2885 - val_loss: 2.5593 - val_acc: 0.2577\n",
            "Epoch 574/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3932 - acc: 0.2939 - val_loss: 2.5349 - val_acc: 0.2699\n",
            "Epoch 575/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.3928 - acc: 0.2766 - val_loss: 2.5404 - val_acc: 0.2761\n",
            "Epoch 576/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3655 - acc: 0.2787 - val_loss: 2.5404 - val_acc: 0.2638\n",
            "Epoch 577/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3617 - acc: 0.2972 - val_loss: 2.5421 - val_acc: 0.2699\n",
            "Epoch 578/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3642 - acc: 0.2983 - val_loss: 2.5379 - val_acc: 0.2638\n",
            "Epoch 579/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.3812 - acc: 0.2744 - val_loss: 2.5358 - val_acc: 0.2577\n",
            "Epoch 580/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3680 - acc: 0.2918 - val_loss: 2.5498 - val_acc: 0.2761\n",
            "Epoch 581/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3570 - acc: 0.2939 - val_loss: 2.5371 - val_acc: 0.2699\n",
            "Epoch 582/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.3511 - acc: 0.2928 - val_loss: 2.5476 - val_acc: 0.2577\n",
            "Epoch 583/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.3775 - acc: 0.2907 - val_loss: 2.5590 - val_acc: 0.2577\n",
            "Epoch 584/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3849 - acc: 0.2831 - val_loss: 2.5342 - val_acc: 0.2577\n",
            "Epoch 585/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.3773 - acc: 0.2874 - val_loss: 2.5259 - val_acc: 0.2699\n",
            "Epoch 586/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3631 - acc: 0.2831 - val_loss: 2.5613 - val_acc: 0.2454\n",
            "Epoch 587/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3710 - acc: 0.2852 - val_loss: 2.5447 - val_acc: 0.2577\n",
            "Epoch 588/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.3795 - acc: 0.2852 - val_loss: 2.5491 - val_acc: 0.2577\n",
            "Epoch 589/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.3719 - acc: 0.3037 - val_loss: 2.5485 - val_acc: 0.2515\n",
            "Epoch 590/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3783 - acc: 0.2820 - val_loss: 2.5342 - val_acc: 0.2638\n",
            "Epoch 591/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 2.3598 - acc: 0.2907 - val_loss: 2.5380 - val_acc: 0.2577\n",
            "Epoch 592/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.3527 - acc: 0.2896 - val_loss: 2.5542 - val_acc: 0.2638\n",
            "Epoch 593/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.3777 - acc: 0.2907 - val_loss: 2.5372 - val_acc: 0.2638\n",
            "Epoch 594/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3570 - acc: 0.2820 - val_loss: 2.5362 - val_acc: 0.2638\n",
            "Epoch 595/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.3719 - acc: 0.2831 - val_loss: 2.5597 - val_acc: 0.2577\n",
            "Epoch 596/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3515 - acc: 0.3037 - val_loss: 2.5405 - val_acc: 0.2638\n",
            "Epoch 597/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.3472 - acc: 0.2983 - val_loss: 2.5333 - val_acc: 0.2577\n",
            "Epoch 598/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3532 - acc: 0.2972 - val_loss: 2.5458 - val_acc: 0.2515\n",
            "Epoch 599/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3506 - acc: 0.2983 - val_loss: 2.5381 - val_acc: 0.2638\n",
            "Epoch 600/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3610 - acc: 0.2939 - val_loss: 2.5287 - val_acc: 0.2638\n",
            "Epoch 601/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3402 - acc: 0.2993 - val_loss: 2.5347 - val_acc: 0.2638\n",
            "Epoch 602/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3464 - acc: 0.3048 - val_loss: 2.5302 - val_acc: 0.2638\n",
            "Epoch 603/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.3567 - acc: 0.2961 - val_loss: 2.5299 - val_acc: 0.2638\n",
            "Epoch 604/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.3595 - acc: 0.2993 - val_loss: 2.5326 - val_acc: 0.2699\n",
            "Epoch 605/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3558 - acc: 0.3069 - val_loss: 2.5285 - val_acc: 0.2699\n",
            "Epoch 606/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 2.3433 - acc: 0.2961 - val_loss: 2.5530 - val_acc: 0.2638\n",
            "Epoch 607/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.3541 - acc: 0.2961 - val_loss: 2.5347 - val_acc: 0.2577\n",
            "Epoch 608/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3594 - acc: 0.2918 - val_loss: 2.5359 - val_acc: 0.2638\n",
            "Epoch 609/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.3538 - acc: 0.2744 - val_loss: 2.5467 - val_acc: 0.2515\n",
            "Epoch 610/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3462 - acc: 0.3004 - val_loss: 2.5228 - val_acc: 0.2638\n",
            "Epoch 611/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.3453 - acc: 0.2766 - val_loss: 2.5364 - val_acc: 0.2638\n",
            "Epoch 612/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3595 - acc: 0.2918 - val_loss: 2.5457 - val_acc: 0.2577\n",
            "Epoch 613/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3343 - acc: 0.3037 - val_loss: 2.5314 - val_acc: 0.2577\n",
            "Epoch 614/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3415 - acc: 0.2928 - val_loss: 2.5520 - val_acc: 0.2638\n",
            "Epoch 615/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3405 - acc: 0.3015 - val_loss: 2.5304 - val_acc: 0.2761\n",
            "Epoch 616/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3454 - acc: 0.2928 - val_loss: 2.5388 - val_acc: 0.2577\n",
            "Epoch 617/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3202 - acc: 0.3026 - val_loss: 2.5507 - val_acc: 0.2515\n",
            "Epoch 618/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.3491 - acc: 0.2983 - val_loss: 2.5511 - val_acc: 0.2515\n",
            "Epoch 619/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3535 - acc: 0.2939 - val_loss: 2.5437 - val_acc: 0.2638\n",
            "Epoch 620/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3448 - acc: 0.2972 - val_loss: 2.5522 - val_acc: 0.2454\n",
            "Epoch 621/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3476 - acc: 0.2972 - val_loss: 2.5248 - val_acc: 0.2638\n",
            "Epoch 622/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3541 - acc: 0.2755 - val_loss: 2.5341 - val_acc: 0.2577\n",
            "Epoch 623/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.3551 - acc: 0.2928 - val_loss: 2.5561 - val_acc: 0.2638\n",
            "Epoch 624/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3314 - acc: 0.2918 - val_loss: 2.5558 - val_acc: 0.2638\n",
            "Epoch 625/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.3356 - acc: 0.2907 - val_loss: 2.5545 - val_acc: 0.2638\n",
            "Epoch 626/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3329 - acc: 0.3069 - val_loss: 2.5361 - val_acc: 0.2577\n",
            "Epoch 627/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3312 - acc: 0.3026 - val_loss: 2.5313 - val_acc: 0.2638\n",
            "Epoch 628/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.3355 - acc: 0.2918 - val_loss: 2.5379 - val_acc: 0.2699\n",
            "Epoch 629/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.3449 - acc: 0.3048 - val_loss: 2.5395 - val_acc: 0.2638\n",
            "Epoch 630/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3413 - acc: 0.2928 - val_loss: 2.5638 - val_acc: 0.2761\n",
            "Epoch 631/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.3497 - acc: 0.2972 - val_loss: 2.5464 - val_acc: 0.2822\n",
            "Epoch 632/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3425 - acc: 0.2950 - val_loss: 2.5396 - val_acc: 0.2699\n",
            "Epoch 633/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.3455 - acc: 0.2928 - val_loss: 2.5550 - val_acc: 0.2638\n",
            "Epoch 634/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3306 - acc: 0.3004 - val_loss: 2.5644 - val_acc: 0.2515\n",
            "Epoch 635/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.3574 - acc: 0.2831 - val_loss: 2.5823 - val_acc: 0.2515\n",
            "Epoch 636/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3576 - acc: 0.2928 - val_loss: 2.5374 - val_acc: 0.2699\n",
            "Epoch 637/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3593 - acc: 0.2896 - val_loss: 2.5355 - val_acc: 0.2638\n",
            "Epoch 638/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3248 - acc: 0.2896 - val_loss: 2.5702 - val_acc: 0.2393\n",
            "Epoch 639/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.3376 - acc: 0.2983 - val_loss: 2.5717 - val_acc: 0.2393\n",
            "Epoch 640/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3545 - acc: 0.2744 - val_loss: 2.5651 - val_acc: 0.2577\n",
            "Epoch 641/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3479 - acc: 0.2918 - val_loss: 2.5438 - val_acc: 0.2761\n",
            "Epoch 642/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3373 - acc: 0.2907 - val_loss: 2.5294 - val_acc: 0.2883\n",
            "Epoch 643/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3507 - acc: 0.2852 - val_loss: 2.5780 - val_acc: 0.2515\n",
            "Epoch 644/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.3318 - acc: 0.2896 - val_loss: 2.5378 - val_acc: 0.2699\n",
            "Epoch 645/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.3341 - acc: 0.2950 - val_loss: 2.5560 - val_acc: 0.2577\n",
            "Epoch 646/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3315 - acc: 0.2993 - val_loss: 2.5544 - val_acc: 0.2577\n",
            "Epoch 647/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.3391 - acc: 0.2972 - val_loss: 2.5311 - val_acc: 0.2761\n",
            "Epoch 648/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3406 - acc: 0.2907 - val_loss: 2.5532 - val_acc: 0.2454\n",
            "Epoch 649/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.3318 - acc: 0.2972 - val_loss: 2.5338 - val_acc: 0.2577\n",
            "Epoch 650/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3190 - acc: 0.2972 - val_loss: 2.5349 - val_acc: 0.2577\n",
            "Epoch 651/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3252 - acc: 0.2961 - val_loss: 2.5334 - val_acc: 0.2577\n",
            "Epoch 652/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3238 - acc: 0.3026 - val_loss: 2.5361 - val_acc: 0.2638\n",
            "Epoch 653/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3146 - acc: 0.2972 - val_loss: 2.5282 - val_acc: 0.2638\n",
            "Epoch 654/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.3197 - acc: 0.2928 - val_loss: 2.5382 - val_acc: 0.2638\n",
            "Epoch 655/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3276 - acc: 0.3026 - val_loss: 2.5244 - val_acc: 0.2638\n",
            "Epoch 656/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3091 - acc: 0.3015 - val_loss: 2.5277 - val_acc: 0.2577\n",
            "Epoch 657/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.3133 - acc: 0.3015 - val_loss: 2.5271 - val_acc: 0.2638\n",
            "Epoch 658/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3207 - acc: 0.3015 - val_loss: 2.5327 - val_acc: 0.2699\n",
            "Epoch 659/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3210 - acc: 0.3026 - val_loss: 2.5320 - val_acc: 0.2638\n",
            "Epoch 660/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.3514 - acc: 0.2896 - val_loss: 2.5222 - val_acc: 0.2638\n",
            "Epoch 661/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3277 - acc: 0.3156 - val_loss: 2.5379 - val_acc: 0.2577\n",
            "Epoch 662/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3129 - acc: 0.3048 - val_loss: 2.5363 - val_acc: 0.2638\n",
            "Epoch 663/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3262 - acc: 0.2972 - val_loss: 2.5465 - val_acc: 0.2454\n",
            "Epoch 664/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3161 - acc: 0.3091 - val_loss: 2.5242 - val_acc: 0.2577\n",
            "Epoch 665/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.3308 - acc: 0.2907 - val_loss: 2.5324 - val_acc: 0.2761\n",
            "Epoch 666/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2900 - acc: 0.3091 - val_loss: 2.5364 - val_acc: 0.2577\n",
            "Epoch 667/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.2999 - acc: 0.3080 - val_loss: 2.5440 - val_acc: 0.2638\n",
            "Epoch 668/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3261 - acc: 0.3015 - val_loss: 2.5447 - val_acc: 0.2638\n",
            "Epoch 669/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 2.3207 - acc: 0.3080 - val_loss: 2.5497 - val_acc: 0.2638\n",
            "Epoch 670/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3125 - acc: 0.3015 - val_loss: 2.5519 - val_acc: 0.2699\n",
            "Epoch 671/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3043 - acc: 0.3059 - val_loss: 2.5526 - val_acc: 0.2699\n",
            "Epoch 672/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3081 - acc: 0.3134 - val_loss: 2.5444 - val_acc: 0.2761\n",
            "Epoch 673/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.3209 - acc: 0.2983 - val_loss: 2.5678 - val_acc: 0.2331\n",
            "Epoch 674/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3018 - acc: 0.3102 - val_loss: 2.5571 - val_acc: 0.2577\n",
            "Epoch 675/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3115 - acc: 0.3059 - val_loss: 2.5506 - val_acc: 0.2515\n",
            "Epoch 676/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2973 - acc: 0.3124 - val_loss: 2.5677 - val_acc: 0.2393\n",
            "Epoch 677/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3025 - acc: 0.3004 - val_loss: 2.5534 - val_acc: 0.2638\n",
            "Epoch 678/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3179 - acc: 0.2983 - val_loss: 2.5523 - val_acc: 0.2638\n",
            "Epoch 679/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3210 - acc: 0.3015 - val_loss: 2.5438 - val_acc: 0.2577\n",
            "Epoch 680/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3076 - acc: 0.2950 - val_loss: 2.5515 - val_acc: 0.2577\n",
            "Epoch 681/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2923 - acc: 0.3015 - val_loss: 2.5602 - val_acc: 0.2699\n",
            "Epoch 682/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.3016 - acc: 0.3059 - val_loss: 2.5576 - val_acc: 0.2638\n",
            "Epoch 683/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.2868 - acc: 0.3091 - val_loss: 2.5603 - val_acc: 0.2638\n",
            "Epoch 684/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3398 - acc: 0.3059 - val_loss: 2.5562 - val_acc: 0.2577\n",
            "Epoch 685/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.2995 - acc: 0.3048 - val_loss: 2.5547 - val_acc: 0.2638\n",
            "Epoch 686/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2880 - acc: 0.3048 - val_loss: 2.5498 - val_acc: 0.2638\n",
            "Epoch 687/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2882 - acc: 0.3059 - val_loss: 2.5529 - val_acc: 0.2638\n",
            "Epoch 688/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2866 - acc: 0.3069 - val_loss: 2.5520 - val_acc: 0.2638\n",
            "Epoch 689/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3027 - acc: 0.2993 - val_loss: 2.5511 - val_acc: 0.2638\n",
            "Epoch 690/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2935 - acc: 0.3048 - val_loss: 2.5370 - val_acc: 0.2638\n",
            "Epoch 691/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2852 - acc: 0.3059 - val_loss: 2.5295 - val_acc: 0.2699\n",
            "Epoch 692/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3019 - acc: 0.3145 - val_loss: 2.5211 - val_acc: 0.2699\n",
            "Epoch 693/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.2992 - acc: 0.3059 - val_loss: 2.5225 - val_acc: 0.2761\n",
            "Epoch 694/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.2980 - acc: 0.3004 - val_loss: 2.5604 - val_acc: 0.2761\n",
            "Epoch 695/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3180 - acc: 0.3113 - val_loss: 2.5622 - val_acc: 0.2515\n",
            "Epoch 696/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3054 - acc: 0.2983 - val_loss: 2.5412 - val_acc: 0.2638\n",
            "Epoch 697/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3113 - acc: 0.3080 - val_loss: 2.5351 - val_acc: 0.2761\n",
            "Epoch 698/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.3030 - acc: 0.3048 - val_loss: 2.5339 - val_acc: 0.2883\n",
            "Epoch 699/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.2865 - acc: 0.3124 - val_loss: 2.5855 - val_acc: 0.2393\n",
            "Epoch 700/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3129 - acc: 0.3080 - val_loss: 2.5666 - val_acc: 0.2638\n",
            "Epoch 701/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.3106 - acc: 0.2972 - val_loss: 2.5626 - val_acc: 0.2699\n",
            "Epoch 702/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3019 - acc: 0.3080 - val_loss: 2.5495 - val_acc: 0.2577\n",
            "Epoch 703/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3067 - acc: 0.2961 - val_loss: 2.5430 - val_acc: 0.2699\n",
            "Epoch 704/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2961 - acc: 0.3124 - val_loss: 2.5736 - val_acc: 0.2515\n",
            "Epoch 705/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3167 - acc: 0.3102 - val_loss: 2.5522 - val_acc: 0.2577\n",
            "Epoch 706/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3012 - acc: 0.2993 - val_loss: 2.5629 - val_acc: 0.2761\n",
            "Epoch 707/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3040 - acc: 0.3069 - val_loss: 2.5413 - val_acc: 0.2638\n",
            "Epoch 708/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3028 - acc: 0.2983 - val_loss: 2.5263 - val_acc: 0.2699\n",
            "Epoch 709/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.3020 - acc: 0.2972 - val_loss: 2.5484 - val_acc: 0.2638\n",
            "Epoch 710/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2913 - acc: 0.3037 - val_loss: 2.5323 - val_acc: 0.2822\n",
            "Epoch 711/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2860 - acc: 0.3080 - val_loss: 2.5428 - val_acc: 0.2699\n",
            "Epoch 712/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3039 - acc: 0.3102 - val_loss: 2.5470 - val_acc: 0.2761\n",
            "Epoch 713/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.2972 - acc: 0.3059 - val_loss: 2.5528 - val_acc: 0.2638\n",
            "Epoch 714/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3043 - acc: 0.2983 - val_loss: 2.5733 - val_acc: 0.2515\n",
            "Epoch 715/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3233 - acc: 0.3059 - val_loss: 2.5274 - val_acc: 0.2761\n",
            "Epoch 716/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2931 - acc: 0.2983 - val_loss: 2.5401 - val_acc: 0.2638\n",
            "Epoch 717/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.3076 - acc: 0.3037 - val_loss: 2.5811 - val_acc: 0.2454\n",
            "Epoch 718/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.3071 - acc: 0.3080 - val_loss: 2.5948 - val_acc: 0.2515\n",
            "Epoch 719/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3183 - acc: 0.2831 - val_loss: 2.5795 - val_acc: 0.2393\n",
            "Epoch 720/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.3344 - acc: 0.3048 - val_loss: 2.5371 - val_acc: 0.2699\n",
            "Epoch 721/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2835 - acc: 0.3069 - val_loss: 2.5722 - val_acc: 0.2577\n",
            "Epoch 722/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.3051 - acc: 0.2852 - val_loss: 2.5765 - val_acc: 0.2638\n",
            "Epoch 723/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2952 - acc: 0.3145 - val_loss: 2.5509 - val_acc: 0.2577\n",
            "Epoch 724/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.2835 - acc: 0.3091 - val_loss: 2.5537 - val_acc: 0.2761\n",
            "Epoch 725/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3120 - acc: 0.3026 - val_loss: 2.5476 - val_acc: 0.2761\n",
            "Epoch 726/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2841 - acc: 0.3124 - val_loss: 2.5409 - val_acc: 0.2822\n",
            "Epoch 727/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2961 - acc: 0.2983 - val_loss: 2.5399 - val_acc: 0.2638\n",
            "Epoch 728/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2926 - acc: 0.3124 - val_loss: 2.5543 - val_acc: 0.2761\n",
            "Epoch 729/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2888 - acc: 0.3080 - val_loss: 2.5423 - val_acc: 0.2761\n",
            "Epoch 730/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3087 - acc: 0.2972 - val_loss: 2.5341 - val_acc: 0.2761\n",
            "Epoch 731/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2912 - acc: 0.3102 - val_loss: 2.5168 - val_acc: 0.2761\n",
            "Epoch 732/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2862 - acc: 0.3091 - val_loss: 2.5410 - val_acc: 0.2638\n",
            "Epoch 733/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.3067 - acc: 0.2983 - val_loss: 2.5589 - val_acc: 0.2577\n",
            "Epoch 734/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.3051 - acc: 0.3091 - val_loss: 2.5456 - val_acc: 0.2577\n",
            "Epoch 735/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2929 - acc: 0.3037 - val_loss: 2.5159 - val_acc: 0.2699\n",
            "Epoch 736/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2609 - acc: 0.3319 - val_loss: 2.5136 - val_acc: 0.2822\n",
            "Epoch 737/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.2657 - acc: 0.3210 - val_loss: 2.5109 - val_acc: 0.2883\n",
            "Epoch 738/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.2653 - acc: 0.3124 - val_loss: 2.5139 - val_acc: 0.2638\n",
            "Epoch 739/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2777 - acc: 0.3102 - val_loss: 2.5223 - val_acc: 0.2638\n",
            "Epoch 740/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2921 - acc: 0.3200 - val_loss: 2.5272 - val_acc: 0.2638\n",
            "Epoch 741/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.2834 - acc: 0.3069 - val_loss: 2.5319 - val_acc: 0.2638\n",
            "Epoch 742/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2902 - acc: 0.3048 - val_loss: 2.5384 - val_acc: 0.2577\n",
            "Epoch 743/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2570 - acc: 0.3037 - val_loss: 2.5390 - val_acc: 0.2822\n",
            "Epoch 744/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2758 - acc: 0.3200 - val_loss: 2.5454 - val_acc: 0.2822\n",
            "Epoch 745/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2645 - acc: 0.3210 - val_loss: 2.5438 - val_acc: 0.2761\n",
            "Epoch 746/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2646 - acc: 0.3091 - val_loss: 2.5441 - val_acc: 0.2822\n",
            "Epoch 747/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2654 - acc: 0.3145 - val_loss: 2.5413 - val_acc: 0.2638\n",
            "Epoch 748/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2862 - acc: 0.2950 - val_loss: 2.5436 - val_acc: 0.2699\n",
            "Epoch 749/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2651 - acc: 0.3145 - val_loss: 2.5321 - val_acc: 0.2822\n",
            "Epoch 750/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2729 - acc: 0.3113 - val_loss: 2.5259 - val_acc: 0.2761\n",
            "Epoch 751/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2757 - acc: 0.3091 - val_loss: 2.5340 - val_acc: 0.2699\n",
            "Epoch 752/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2670 - acc: 0.3189 - val_loss: 2.5322 - val_acc: 0.2699\n",
            "Epoch 753/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2767 - acc: 0.3069 - val_loss: 2.5318 - val_acc: 0.2577\n",
            "Epoch 754/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2660 - acc: 0.3113 - val_loss: 2.5285 - val_acc: 0.2761\n",
            "Epoch 755/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2544 - acc: 0.3124 - val_loss: 2.5258 - val_acc: 0.2699\n",
            "Epoch 756/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.2758 - acc: 0.3113 - val_loss: 2.5336 - val_acc: 0.2761\n",
            "Epoch 757/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2694 - acc: 0.3200 - val_loss: 2.5440 - val_acc: 0.2761\n",
            "Epoch 758/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2679 - acc: 0.3080 - val_loss: 2.5439 - val_acc: 0.2822\n",
            "Epoch 759/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2718 - acc: 0.3243 - val_loss: 2.5356 - val_acc: 0.2761\n",
            "Epoch 760/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2646 - acc: 0.3243 - val_loss: 2.5412 - val_acc: 0.2822\n",
            "Epoch 761/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2917 - acc: 0.3048 - val_loss: 2.5393 - val_acc: 0.2822\n",
            "Epoch 762/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2582 - acc: 0.3286 - val_loss: 2.5354 - val_acc: 0.2699\n",
            "Epoch 763/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2603 - acc: 0.3200 - val_loss: 2.5466 - val_acc: 0.2822\n",
            "Epoch 764/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2598 - acc: 0.3124 - val_loss: 2.5667 - val_acc: 0.2699\n",
            "Epoch 765/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2697 - acc: 0.3026 - val_loss: 2.5676 - val_acc: 0.2761\n",
            "Epoch 766/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2693 - acc: 0.3167 - val_loss: 2.5427 - val_acc: 0.2699\n",
            "Epoch 767/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2853 - acc: 0.3178 - val_loss: 2.5347 - val_acc: 0.2761\n",
            "Epoch 768/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2887 - acc: 0.3026 - val_loss: 2.5661 - val_acc: 0.2699\n",
            "Epoch 769/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2735 - acc: 0.3102 - val_loss: 2.5622 - val_acc: 0.2699\n",
            "Epoch 770/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2935 - acc: 0.2939 - val_loss: 2.5709 - val_acc: 0.2515\n",
            "Epoch 771/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2785 - acc: 0.3134 - val_loss: 2.5214 - val_acc: 0.2761\n",
            "Epoch 772/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2699 - acc: 0.3026 - val_loss: 2.5228 - val_acc: 0.2699\n",
            "Epoch 773/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2680 - acc: 0.3167 - val_loss: 2.5612 - val_acc: 0.2761\n",
            "Epoch 774/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2647 - acc: 0.3167 - val_loss: 2.5566 - val_acc: 0.2577\n",
            "Epoch 775/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.2900 - acc: 0.3080 - val_loss: 2.5464 - val_acc: 0.2761\n",
            "Epoch 776/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2723 - acc: 0.3200 - val_loss: 2.5311 - val_acc: 0.2822\n",
            "Epoch 777/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2592 - acc: 0.3167 - val_loss: 2.5531 - val_acc: 0.2761\n",
            "Epoch 778/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2692 - acc: 0.3059 - val_loss: 2.5464 - val_acc: 0.2699\n",
            "Epoch 779/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.2618 - acc: 0.3167 - val_loss: 2.5241 - val_acc: 0.2822\n",
            "Epoch 780/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.2724 - acc: 0.3113 - val_loss: 2.5290 - val_acc: 0.2822\n",
            "Epoch 781/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.2628 - acc: 0.3210 - val_loss: 2.5402 - val_acc: 0.2822\n",
            "Epoch 782/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2408 - acc: 0.3080 - val_loss: 2.5438 - val_acc: 0.2761\n",
            "Epoch 783/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2714 - acc: 0.3189 - val_loss: 2.5393 - val_acc: 0.2822\n",
            "Epoch 784/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2527 - acc: 0.3243 - val_loss: 2.5392 - val_acc: 0.2945\n",
            "Epoch 785/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2576 - acc: 0.3221 - val_loss: 2.5291 - val_acc: 0.2822\n",
            "Epoch 786/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2361 - acc: 0.3156 - val_loss: 2.5451 - val_acc: 0.2761\n",
            "Epoch 787/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2459 - acc: 0.3200 - val_loss: 2.5535 - val_acc: 0.2761\n",
            "Epoch 788/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.2560 - acc: 0.3026 - val_loss: 2.5524 - val_acc: 0.2761\n",
            "Epoch 789/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2517 - acc: 0.3167 - val_loss: 2.5463 - val_acc: 0.2822\n",
            "Epoch 790/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2433 - acc: 0.3254 - val_loss: 2.5429 - val_acc: 0.2883\n",
            "Epoch 791/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.2656 - acc: 0.3069 - val_loss: 2.5534 - val_acc: 0.2822\n",
            "Epoch 792/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2355 - acc: 0.3254 - val_loss: 2.5511 - val_acc: 0.2822\n",
            "Epoch 793/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2526 - acc: 0.3145 - val_loss: 2.5539 - val_acc: 0.2699\n",
            "Epoch 794/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2639 - acc: 0.3243 - val_loss: 2.5716 - val_acc: 0.2638\n",
            "Epoch 795/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2655 - acc: 0.3200 - val_loss: 2.5566 - val_acc: 0.2883\n",
            "Epoch 796/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2463 - acc: 0.3178 - val_loss: 2.5700 - val_acc: 0.2761\n",
            "Epoch 797/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2488 - acc: 0.3286 - val_loss: 2.5667 - val_acc: 0.2699\n",
            "Epoch 798/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.2438 - acc: 0.3156 - val_loss: 2.5509 - val_acc: 0.2761\n",
            "Epoch 799/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2375 - acc: 0.3189 - val_loss: 2.5578 - val_acc: 0.2761\n",
            "Epoch 800/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2566 - acc: 0.3124 - val_loss: 2.5562 - val_acc: 0.2699\n",
            "Epoch 801/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2632 - acc: 0.3243 - val_loss: 2.5587 - val_acc: 0.2761\n",
            "Epoch 802/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2383 - acc: 0.3210 - val_loss: 2.5703 - val_acc: 0.2699\n",
            "Epoch 803/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2633 - acc: 0.3156 - val_loss: 2.5867 - val_acc: 0.2761\n",
            "Epoch 804/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2573 - acc: 0.3308 - val_loss: 2.5559 - val_acc: 0.2822\n",
            "Epoch 805/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2673 - acc: 0.3069 - val_loss: 2.5523 - val_acc: 0.2699\n",
            "Epoch 806/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2476 - acc: 0.3286 - val_loss: 2.5626 - val_acc: 0.2699\n",
            "Epoch 807/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.2386 - acc: 0.3189 - val_loss: 2.5742 - val_acc: 0.2761\n",
            "Epoch 808/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2511 - acc: 0.3113 - val_loss: 2.5601 - val_acc: 0.2699\n",
            "Epoch 809/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2723 - acc: 0.3286 - val_loss: 2.5358 - val_acc: 0.2822\n",
            "Epoch 810/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2547 - acc: 0.3102 - val_loss: 2.5280 - val_acc: 0.2761\n",
            "Epoch 811/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.2399 - acc: 0.3232 - val_loss: 2.5320 - val_acc: 0.2699\n",
            "Epoch 812/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2297 - acc: 0.3232 - val_loss: 2.5229 - val_acc: 0.2822\n",
            "Epoch 813/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2354 - acc: 0.3265 - val_loss: 2.5340 - val_acc: 0.2822\n",
            "Epoch 814/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.2337 - acc: 0.3178 - val_loss: 2.5329 - val_acc: 0.2761\n",
            "Epoch 815/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2380 - acc: 0.3156 - val_loss: 2.5390 - val_acc: 0.2822\n",
            "Epoch 816/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2365 - acc: 0.3189 - val_loss: 2.5433 - val_acc: 0.2699\n",
            "Epoch 817/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2274 - acc: 0.3124 - val_loss: 2.5491 - val_acc: 0.2699\n",
            "Epoch 818/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2508 - acc: 0.3232 - val_loss: 2.5375 - val_acc: 0.2822\n",
            "Epoch 819/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2288 - acc: 0.3232 - val_loss: 2.5451 - val_acc: 0.2638\n",
            "Epoch 820/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2535 - acc: 0.3134 - val_loss: 2.5406 - val_acc: 0.2761\n",
            "Epoch 821/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2227 - acc: 0.3275 - val_loss: 2.5475 - val_acc: 0.2761\n",
            "Epoch 822/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.2206 - acc: 0.3254 - val_loss: 2.5576 - val_acc: 0.2761\n",
            "Epoch 823/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2335 - acc: 0.3232 - val_loss: 2.5458 - val_acc: 0.2822\n",
            "Epoch 824/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.2460 - acc: 0.3156 - val_loss: 2.5316 - val_acc: 0.2822\n",
            "Epoch 825/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2252 - acc: 0.3265 - val_loss: 2.5319 - val_acc: 0.2883\n",
            "Epoch 826/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.2248 - acc: 0.3330 - val_loss: 2.5349 - val_acc: 0.2761\n",
            "Epoch 827/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.2179 - acc: 0.3210 - val_loss: 2.5428 - val_acc: 0.2883\n",
            "Epoch 828/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.2297 - acc: 0.3319 - val_loss: 2.5204 - val_acc: 0.2883\n",
            "Epoch 829/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.2373 - acc: 0.3243 - val_loss: 2.5196 - val_acc: 0.2883\n",
            "Epoch 830/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2304 - acc: 0.3286 - val_loss: 2.5494 - val_acc: 0.2822\n",
            "Epoch 831/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2497 - acc: 0.3297 - val_loss: 2.5399 - val_acc: 0.2822\n",
            "Epoch 832/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.2382 - acc: 0.3091 - val_loss: 2.5325 - val_acc: 0.2883\n",
            "Epoch 833/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.2298 - acc: 0.3395 - val_loss: 2.5386 - val_acc: 0.2883\n",
            "Epoch 834/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2259 - acc: 0.3297 - val_loss: 2.5581 - val_acc: 0.2761\n",
            "Epoch 835/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2550 - acc: 0.3134 - val_loss: 2.5647 - val_acc: 0.2699\n",
            "Epoch 836/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.2483 - acc: 0.3275 - val_loss: 2.5351 - val_acc: 0.2761\n",
            "Epoch 837/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2321 - acc: 0.3308 - val_loss: 2.5239 - val_acc: 0.2945\n",
            "Epoch 838/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2240 - acc: 0.3275 - val_loss: 2.5305 - val_acc: 0.2883\n",
            "Epoch 839/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.2229 - acc: 0.3254 - val_loss: 2.5430 - val_acc: 0.2883\n",
            "Epoch 840/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2309 - acc: 0.3124 - val_loss: 2.5564 - val_acc: 0.2761\n",
            "Epoch 841/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2219 - acc: 0.3308 - val_loss: 2.5336 - val_acc: 0.2883\n",
            "Epoch 842/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.2168 - acc: 0.3275 - val_loss: 2.5235 - val_acc: 0.2945\n",
            "Epoch 843/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.2344 - acc: 0.3210 - val_loss: 2.5249 - val_acc: 0.2822\n",
            "Epoch 844/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2178 - acc: 0.3275 - val_loss: 2.5386 - val_acc: 0.2822\n",
            "Epoch 845/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2255 - acc: 0.3254 - val_loss: 2.5291 - val_acc: 0.2761\n",
            "Epoch 846/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.2129 - acc: 0.3254 - val_loss: 2.5271 - val_acc: 0.2883\n",
            "Epoch 847/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2402 - acc: 0.3286 - val_loss: 2.5354 - val_acc: 0.2883\n",
            "Epoch 848/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2208 - acc: 0.3254 - val_loss: 2.5373 - val_acc: 0.2761\n",
            "Epoch 849/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.2322 - acc: 0.3189 - val_loss: 2.5363 - val_acc: 0.2822\n",
            "Epoch 850/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.2100 - acc: 0.3351 - val_loss: 2.5246 - val_acc: 0.2945\n",
            "Epoch 851/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2277 - acc: 0.3286 - val_loss: 2.5262 - val_acc: 0.2883\n",
            "Epoch 852/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2390 - acc: 0.3297 - val_loss: 2.5327 - val_acc: 0.2822\n",
            "Epoch 853/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2127 - acc: 0.3221 - val_loss: 2.5423 - val_acc: 0.2945\n",
            "Epoch 854/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2271 - acc: 0.3243 - val_loss: 2.5378 - val_acc: 0.2822\n",
            "Epoch 855/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2115 - acc: 0.3232 - val_loss: 2.5312 - val_acc: 0.2822\n",
            "Epoch 856/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2100 - acc: 0.3221 - val_loss: 2.5239 - val_acc: 0.2945\n",
            "Epoch 857/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.2081 - acc: 0.3341 - val_loss: 2.5259 - val_acc: 0.2945\n",
            "Epoch 858/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.2329 - acc: 0.3221 - val_loss: 2.5252 - val_acc: 0.2761\n",
            "Epoch 859/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2107 - acc: 0.3373 - val_loss: 2.5222 - val_acc: 0.2945\n",
            "Epoch 860/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2246 - acc: 0.3265 - val_loss: 2.5256 - val_acc: 0.2883\n",
            "Epoch 861/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2119 - acc: 0.3362 - val_loss: 2.5389 - val_acc: 0.2883\n",
            "Epoch 862/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2152 - acc: 0.3286 - val_loss: 2.5335 - val_acc: 0.2945\n",
            "Epoch 863/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2038 - acc: 0.3232 - val_loss: 2.5194 - val_acc: 0.2945\n",
            "Epoch 864/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.2131 - acc: 0.3221 - val_loss: 2.5166 - val_acc: 0.2822\n",
            "Epoch 865/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.1981 - acc: 0.3243 - val_loss: 2.5155 - val_acc: 0.2883\n",
            "Epoch 866/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2041 - acc: 0.3406 - val_loss: 2.5320 - val_acc: 0.2883\n",
            "Epoch 867/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2224 - acc: 0.3265 - val_loss: 2.5464 - val_acc: 0.2822\n",
            "Epoch 868/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2198 - acc: 0.3286 - val_loss: 2.5406 - val_acc: 0.3006\n",
            "Epoch 869/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2115 - acc: 0.3297 - val_loss: 2.5475 - val_acc: 0.2822\n",
            "Epoch 870/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.2157 - acc: 0.3275 - val_loss: 2.5584 - val_acc: 0.2761\n",
            "Epoch 871/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1923 - acc: 0.3330 - val_loss: 2.5514 - val_acc: 0.2822\n",
            "Epoch 872/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 2.2008 - acc: 0.3341 - val_loss: 2.5454 - val_acc: 0.2883\n",
            "Epoch 873/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 2.2105 - acc: 0.3351 - val_loss: 2.5488 - val_acc: 0.2822\n",
            "Epoch 874/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.2224 - acc: 0.3243 - val_loss: 2.5528 - val_acc: 0.2761\n",
            "Epoch 875/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.2183 - acc: 0.3232 - val_loss: 2.5455 - val_acc: 0.2822\n",
            "Epoch 876/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.1975 - acc: 0.3373 - val_loss: 2.5354 - val_acc: 0.2761\n",
            "Epoch 877/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.2337 - acc: 0.3341 - val_loss: 2.5245 - val_acc: 0.2822\n",
            "Epoch 878/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.2040 - acc: 0.3275 - val_loss: 2.5180 - val_acc: 0.3006\n",
            "Epoch 879/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1912 - acc: 0.3384 - val_loss: 2.5385 - val_acc: 0.3006\n",
            "Epoch 880/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.2049 - acc: 0.3341 - val_loss: 2.5236 - val_acc: 0.2945\n",
            "Epoch 881/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2179 - acc: 0.3275 - val_loss: 2.5238 - val_acc: 0.2945\n",
            "Epoch 882/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.2120 - acc: 0.3178 - val_loss: 2.5335 - val_acc: 0.2883\n",
            "Epoch 883/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2169 - acc: 0.3449 - val_loss: 2.5255 - val_acc: 0.3067\n",
            "Epoch 884/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.2083 - acc: 0.3243 - val_loss: 2.5259 - val_acc: 0.2761\n",
            "Epoch 885/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.2034 - acc: 0.3265 - val_loss: 2.5229 - val_acc: 0.2883\n",
            "Epoch 886/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.1970 - acc: 0.3319 - val_loss: 2.5122 - val_acc: 0.2945\n",
            "Epoch 887/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.1949 - acc: 0.3341 - val_loss: 2.5099 - val_acc: 0.2883\n",
            "Epoch 888/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2083 - acc: 0.3351 - val_loss: 2.5129 - val_acc: 0.3006\n",
            "Epoch 889/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.1879 - acc: 0.3254 - val_loss: 2.5273 - val_acc: 0.2883\n",
            "Epoch 890/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2060 - acc: 0.3286 - val_loss: 2.5245 - val_acc: 0.3006\n",
            "Epoch 891/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.1980 - acc: 0.3351 - val_loss: 2.5214 - val_acc: 0.3006\n",
            "Epoch 892/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2051 - acc: 0.3384 - val_loss: 2.5177 - val_acc: 0.2945\n",
            "Epoch 893/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1797 - acc: 0.3362 - val_loss: 2.5278 - val_acc: 0.2883\n",
            "Epoch 894/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1841 - acc: 0.3341 - val_loss: 2.5257 - val_acc: 0.3006\n",
            "Epoch 895/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.1972 - acc: 0.3319 - val_loss: 2.5185 - val_acc: 0.2945\n",
            "Epoch 896/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1979 - acc: 0.3275 - val_loss: 2.5184 - val_acc: 0.3067\n",
            "Epoch 897/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2033 - acc: 0.3297 - val_loss: 2.5379 - val_acc: 0.2761\n",
            "Epoch 898/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2014 - acc: 0.3384 - val_loss: 2.5331 - val_acc: 0.2945\n",
            "Epoch 899/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.1882 - acc: 0.3351 - val_loss: 2.5219 - val_acc: 0.2945\n",
            "Epoch 900/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.1828 - acc: 0.3373 - val_loss: 2.5157 - val_acc: 0.3006\n",
            "Epoch 901/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1973 - acc: 0.3330 - val_loss: 2.5222 - val_acc: 0.3067\n",
            "Epoch 902/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1960 - acc: 0.3319 - val_loss: 2.5116 - val_acc: 0.3129\n",
            "Epoch 903/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1810 - acc: 0.3427 - val_loss: 2.5111 - val_acc: 0.2945\n",
            "Epoch 904/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.1804 - acc: 0.3416 - val_loss: 2.5240 - val_acc: 0.2822\n",
            "Epoch 905/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2049 - acc: 0.3297 - val_loss: 2.5206 - val_acc: 0.2761\n",
            "Epoch 906/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.1696 - acc: 0.3482 - val_loss: 2.5161 - val_acc: 0.2883\n",
            "Epoch 907/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.2210 - acc: 0.3275 - val_loss: 2.5029 - val_acc: 0.3006\n",
            "Epoch 908/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.2125 - acc: 0.3406 - val_loss: 2.5006 - val_acc: 0.3067\n",
            "Epoch 909/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2057 - acc: 0.3254 - val_loss: 2.5157 - val_acc: 0.3006\n",
            "Epoch 910/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.2103 - acc: 0.3319 - val_loss: 2.5141 - val_acc: 0.3006\n",
            "Epoch 911/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2166 - acc: 0.3265 - val_loss: 2.5290 - val_acc: 0.3006\n",
            "Epoch 912/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1888 - acc: 0.3330 - val_loss: 2.5496 - val_acc: 0.2822\n",
            "Epoch 913/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.2166 - acc: 0.3395 - val_loss: 2.5211 - val_acc: 0.2945\n",
            "Epoch 914/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.2020 - acc: 0.3254 - val_loss: 2.4910 - val_acc: 0.3129\n",
            "Epoch 915/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1863 - acc: 0.3438 - val_loss: 2.5223 - val_acc: 0.2699\n",
            "Epoch 916/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.1949 - acc: 0.3406 - val_loss: 2.5254 - val_acc: 0.2945\n",
            "Epoch 917/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.1850 - acc: 0.3362 - val_loss: 2.4914 - val_acc: 0.2945\n",
            "Epoch 918/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.1933 - acc: 0.3449 - val_loss: 2.4805 - val_acc: 0.3006\n",
            "Epoch 919/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.1720 - acc: 0.3471 - val_loss: 2.4852 - val_acc: 0.3067\n",
            "Epoch 920/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.1888 - acc: 0.3503 - val_loss: 2.4787 - val_acc: 0.3067\n",
            "Epoch 921/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1761 - acc: 0.3482 - val_loss: 2.4744 - val_acc: 0.3129\n",
            "Epoch 922/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.1796 - acc: 0.3373 - val_loss: 2.4695 - val_acc: 0.3006\n",
            "Epoch 923/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.1943 - acc: 0.3416 - val_loss: 2.4878 - val_acc: 0.3006\n",
            "Epoch 924/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1599 - acc: 0.3362 - val_loss: 2.4754 - val_acc: 0.3067\n",
            "Epoch 925/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.1606 - acc: 0.3362 - val_loss: 2.4783 - val_acc: 0.3313\n",
            "Epoch 926/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.1806 - acc: 0.3406 - val_loss: 2.4804 - val_acc: 0.3067\n",
            "Epoch 927/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1773 - acc: 0.3351 - val_loss: 2.4810 - val_acc: 0.3006\n",
            "Epoch 928/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1601 - acc: 0.3416 - val_loss: 2.4870 - val_acc: 0.3067\n",
            "Epoch 929/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1604 - acc: 0.3438 - val_loss: 2.4729 - val_acc: 0.3006\n",
            "Epoch 930/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.1675 - acc: 0.3395 - val_loss: 2.4730 - val_acc: 0.3190\n",
            "Epoch 931/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.1741 - acc: 0.3492 - val_loss: 2.4853 - val_acc: 0.3067\n",
            "Epoch 932/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1519 - acc: 0.3525 - val_loss: 2.4824 - val_acc: 0.3129\n",
            "Epoch 933/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.1541 - acc: 0.3482 - val_loss: 2.4865 - val_acc: 0.3129\n",
            "Epoch 934/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.1779 - acc: 0.3362 - val_loss: 2.4979 - val_acc: 0.3067\n",
            "Epoch 935/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.1349 - acc: 0.3536 - val_loss: 2.5028 - val_acc: 0.3067\n",
            "Epoch 936/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.1498 - acc: 0.3492 - val_loss: 2.4900 - val_acc: 0.3067\n",
            "Epoch 937/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 2.1783 - acc: 0.3319 - val_loss: 2.4976 - val_acc: 0.3190\n",
            "Epoch 938/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.1581 - acc: 0.3503 - val_loss: 2.5096 - val_acc: 0.2945\n",
            "Epoch 939/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1548 - acc: 0.3525 - val_loss: 2.4917 - val_acc: 0.3067\n",
            "Epoch 940/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.1619 - acc: 0.3427 - val_loss: 2.4828 - val_acc: 0.3067\n",
            "Epoch 941/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 2.1437 - acc: 0.3579 - val_loss: 2.4805 - val_acc: 0.3190\n",
            "Epoch 942/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.1556 - acc: 0.3482 - val_loss: 2.4913 - val_acc: 0.3129\n",
            "Epoch 943/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.1582 - acc: 0.3525 - val_loss: 2.4761 - val_acc: 0.3313\n",
            "Epoch 944/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.1563 - acc: 0.3438 - val_loss: 2.4692 - val_acc: 0.3313\n",
            "Epoch 945/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.1412 - acc: 0.3568 - val_loss: 2.4746 - val_acc: 0.3190\n",
            "Epoch 946/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.1666 - acc: 0.3471 - val_loss: 2.4861 - val_acc: 0.2883\n",
            "Epoch 947/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1332 - acc: 0.3536 - val_loss: 2.4639 - val_acc: 0.3129\n",
            "Epoch 948/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1456 - acc: 0.3525 - val_loss: 2.4688 - val_acc: 0.3067\n",
            "Epoch 949/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1653 - acc: 0.3384 - val_loss: 2.4683 - val_acc: 0.3190\n",
            "Epoch 950/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.1229 - acc: 0.3633 - val_loss: 2.4678 - val_acc: 0.3067\n",
            "Epoch 951/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1335 - acc: 0.3525 - val_loss: 2.4607 - val_acc: 0.3252\n",
            "Epoch 952/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1506 - acc: 0.3503 - val_loss: 2.4697 - val_acc: 0.3252\n",
            "Epoch 953/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1690 - acc: 0.3330 - val_loss: 2.4646 - val_acc: 0.3129\n",
            "Epoch 954/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1558 - acc: 0.3471 - val_loss: 2.4512 - val_acc: 0.3252\n",
            "Epoch 955/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.1455 - acc: 0.3492 - val_loss: 2.4440 - val_acc: 0.3252\n",
            "Epoch 956/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1401 - acc: 0.3590 - val_loss: 2.4574 - val_acc: 0.3067\n",
            "Epoch 957/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1467 - acc: 0.3351 - val_loss: 2.4810 - val_acc: 0.3190\n",
            "Epoch 958/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1448 - acc: 0.3416 - val_loss: 2.4376 - val_acc: 0.3067\n",
            "Epoch 959/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1390 - acc: 0.3416 - val_loss: 2.4460 - val_acc: 0.3252\n",
            "Epoch 960/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1413 - acc: 0.3525 - val_loss: 2.4540 - val_acc: 0.3129\n",
            "Epoch 961/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1504 - acc: 0.3503 - val_loss: 2.4446 - val_acc: 0.3252\n",
            "Epoch 962/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1416 - acc: 0.3449 - val_loss: 2.4431 - val_acc: 0.3374\n",
            "Epoch 963/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.1478 - acc: 0.3536 - val_loss: 2.4677 - val_acc: 0.3067\n",
            "Epoch 964/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.1284 - acc: 0.3557 - val_loss: 2.4643 - val_acc: 0.3313\n",
            "Epoch 965/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1342 - acc: 0.3406 - val_loss: 2.4639 - val_acc: 0.3129\n",
            "Epoch 966/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.1629 - acc: 0.3427 - val_loss: 2.4743 - val_acc: 0.3190\n",
            "Epoch 967/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.1375 - acc: 0.3416 - val_loss: 2.4425 - val_acc: 0.3313\n",
            "Epoch 968/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.1282 - acc: 0.3557 - val_loss: 2.4280 - val_acc: 0.3190\n",
            "Epoch 969/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1126 - acc: 0.3514 - val_loss: 2.4324 - val_acc: 0.3252\n",
            "Epoch 970/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.1364 - acc: 0.3460 - val_loss: 2.4563 - val_acc: 0.3190\n",
            "Epoch 971/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.1212 - acc: 0.3579 - val_loss: 2.4359 - val_acc: 0.3313\n",
            "Epoch 972/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1126 - acc: 0.3547 - val_loss: 2.4359 - val_acc: 0.3252\n",
            "Epoch 973/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 2.1382 - acc: 0.3395 - val_loss: 2.4559 - val_acc: 0.3252\n",
            "Epoch 974/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1084 - acc: 0.3525 - val_loss: 2.4565 - val_acc: 0.3190\n",
            "Epoch 975/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1141 - acc: 0.3460 - val_loss: 2.4345 - val_acc: 0.3313\n",
            "Epoch 976/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1334 - acc: 0.3514 - val_loss: 2.4498 - val_acc: 0.3252\n",
            "Epoch 977/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.1146 - acc: 0.3612 - val_loss: 2.4477 - val_acc: 0.3374\n",
            "Epoch 978/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.1094 - acc: 0.3579 - val_loss: 2.4369 - val_acc: 0.3313\n",
            "Epoch 979/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1307 - acc: 0.3525 - val_loss: 2.4320 - val_acc: 0.3252\n",
            "Epoch 980/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1139 - acc: 0.3568 - val_loss: 2.4593 - val_acc: 0.3313\n",
            "Epoch 981/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.1097 - acc: 0.3601 - val_loss: 2.4255 - val_acc: 0.3436\n",
            "Epoch 982/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.0954 - acc: 0.3568 - val_loss: 2.4225 - val_acc: 0.3313\n",
            "Epoch 983/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1133 - acc: 0.3612 - val_loss: 2.4474 - val_acc: 0.3190\n",
            "Epoch 984/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.0967 - acc: 0.3536 - val_loss: 2.4239 - val_acc: 0.3313\n",
            "Epoch 985/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1456 - acc: 0.3590 - val_loss: 2.4252 - val_acc: 0.3374\n",
            "Epoch 986/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1050 - acc: 0.3525 - val_loss: 2.4419 - val_acc: 0.3252\n",
            "Epoch 987/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1204 - acc: 0.3601 - val_loss: 2.4331 - val_acc: 0.3129\n",
            "Epoch 988/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.1296 - acc: 0.3525 - val_loss: 2.4604 - val_acc: 0.3252\n",
            "Epoch 989/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.0907 - acc: 0.3590 - val_loss: 2.4746 - val_acc: 0.3006\n",
            "Epoch 990/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.1250 - acc: 0.3547 - val_loss: 2.4437 - val_acc: 0.3252\n",
            "Epoch 991/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.1077 - acc: 0.3514 - val_loss: 2.4179 - val_acc: 0.3313\n",
            "Epoch 992/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 2.1003 - acc: 0.3568 - val_loss: 2.4428 - val_acc: 0.3252\n",
            "Epoch 993/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.1088 - acc: 0.3644 - val_loss: 2.4304 - val_acc: 0.3497\n",
            "Epoch 994/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.1218 - acc: 0.3525 - val_loss: 2.4177 - val_acc: 0.3374\n",
            "Epoch 995/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.0929 - acc: 0.3655 - val_loss: 2.4301 - val_acc: 0.3497\n",
            "Epoch 996/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1041 - acc: 0.3536 - val_loss: 2.4258 - val_acc: 0.3374\n",
            "Epoch 997/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.0798 - acc: 0.3460 - val_loss: 2.4316 - val_acc: 0.3252\n",
            "Epoch 998/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1101 - acc: 0.3612 - val_loss: 2.4468 - val_acc: 0.3313\n",
            "Epoch 999/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.1161 - acc: 0.3492 - val_loss: 2.4381 - val_acc: 0.3313\n",
            "Epoch 1000/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1201 - acc: 0.3547 - val_loss: 2.4334 - val_acc: 0.3252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6loFudL4bEhH"
      },
      "source": [
        "Let's explore what's going wrong in a mistaken classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qCLfVdOWWaM4",
        "outputId": "9218a163-77e5-4001-f85a-84d7d0cd7632"
      },
      "source": [
        "predictions = model.predict(test_data)\n",
        "\n",
        "i = 16\n",
        "\n",
        "true_class = test_targets[i]\n",
        "pred_class = tf.one_hot(tf.argmax(predictions[i]), depth = num_classes).numpy()\n",
        "\n",
        "true_class_profiles = []\n",
        "for j in range(0, len(train_targets)):\n",
        "    if(np.array_equal(train_targets[j], true_class) == True):\n",
        "        true_class_profiles.append(j)\n",
        "\n",
        "pred_class_profiles = []\n",
        "for j in range(0, len(train_targets)):\n",
        "    if(np.array_equal(train_targets[j], pred_class) == True):\n",
        "        pred_class_profiles.append(j)  \n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
        "fig.subplots_adjust(hspace=0.4)\n",
        "ax[0].bar(np.arange(num_classes), test_targets[i], color='orange')\n",
        "ax[0].set_title('True class')\n",
        "ax[1].bar(np.arange(num_classes), predictions[i])\n",
        "ax[1].set_title('Predicted classes')\n",
        "plt.show()\n",
        "\n",
        "homology = range(100, 300)\n",
        "\n",
        "# Plot all the persistence curves for a given class layered onto one another, or maybe the mean?\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "for k in true_class_profiles:\n",
        "    ax.plot(train_data[k, homology])\n",
        "    ax.set_title('Persistence curves, true class')\n",
        "plt.ylim([0, 800])\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "for k in pred_class_profiles:\n",
        "    ax.plot(train_data[k, homology])\n",
        "    ax.set_title('Persistence curves, predicted class')\n",
        "plt.ylim([0, 800])\n",
        "plt.show()\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(test_data[i, homology])\n",
        "ax.set_title('Persistence curve')\n",
        "plt.ylim([0, 800])\n",
        "plt.show()\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAE/CAYAAAB1vdadAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfvElEQVR4nO3dfZRddX3v8ffnhgerPBhMtJpHlPgQahfoGOzSUrpUiHpLaOtDtA/Qq4225La16m1q7wJvvPbS2hZXr1iJNZVrq4Bo6dw2FlGs1atgJkqBhKYMaYCkkQAJgopAyPf+cXb0MJnJHMjszJnh/Vpr1uz9+/32Pt/N5jAf9v6ds1NVSJIkaWL9p8kuQJIkaToyZEmSJLXAkCVJktQCQ5YkSVILDFmSJEktMGRJkiS1wJAlSUCSrUleOdl1SJo+DFmSDrkk3+362Zvkga71X5rs+iRpIhw22QVIeuKpqqP2LSfZCry1qr4wclySw6pqz6GsTZImileyJPWNJKcl2Zbk95J8G/irJOck+eqIcZXkhGb5yCR/kuT2JHcm+UiSHzvAa/x6kpuT3J9kU5IXjTJmSZKvJ7k3yY4kH0pyRNOXJBcm2ZnkviQ3JvmJpu81zT7vT7I9ybsm9B+QpCnFkCWp3/w4cBywAFjRw/gLgOcCJwEnAHOA80YbmOT1wHuBXwWOAc4E7hll6CPAO4BZwE8BrwB+s+k7HTi1ec1jgTd07eNjwNuq6mjgJ4Breqhf0jRlyJLUb/YC51fVg1X1wIEGJgmdIPaOqtpVVfcDfwgsH2OTtwJ/XFXrq2O4qm4bOaiqNlTVtVW1p6q2AhcDP9N0PwwcDTwfSFXdXFU7uvoWJzmmqnZX1Tcf26FLmk4MWZL6zV1V9YMex84GngxsaG7t3Qv8Y9M+mnnArePtNMlzk/x9km8nuY9OcJsFUFXXAB8CLgJ2JlmT5Jhm018EXgPcluTLSX6qx+OQNA0ZsiT1mxqx/j06QQqAJD/e1Xc38ABwYlU9tfk5tnti/Qh3AM/poYa/AP4VWFRVxwDvAfLDAqv+vKpeDCymc9vw3U37+qpaBjwduBK4vIfXkjRNGbIk9bt/AU5MclKSJ9GZUwVAVe0FPgpcmOTpAEnmJDljjH39JfCuJC9uJrCfkGTBKOOOBu4Dvpvk+cBv7OtI8pIkpyQ5nE4A/AGwN8kRSX4pybFV9XCz/d6DPXhJU5chS1Jfq6p/A1YDXwBuAb46YsjvAcPAtc2tvS8AzxtjX58G3g98ErifztWm40YZ+i7gzc2YjwKXdfUd07TtBm6jM+n9A03frwBbmzreDvidX9ITWKpGXpmXJEnSwfJKliRJUgsMWZIkSS0wZEmSJLXAkCVJktQCQ5YkSVILDpvsAkaaNWtWLVy4cLLLkCRJGteGDRvurqpRnzLRdyFr4cKFDA0NTXYZkiRJ40qy3/NP9xn3dmGStUl2JrlpjP4k+fMkw0luSPKirr6zk9zS/Jz9+MqXJEmaenqZk/VxYOkB+l8NLGp+VtB55hdJjgPOB04BlgDnJ5l5MMVKkiRNFeOGrKr6Z2DXAYYsA/5PdVwLPDXJM4EzgKuraldV7Qau5sBhTZIkadqYiDlZc+g82X6fbU3bWO37SbKCzlUw5s+fPwElSZJ0CH0yB7+PN/uYu+mmL77CoarWVNVAVQ3Mnj3qBH1JkqQpZSJC1nZgXtf63KZtrHZJkqRpbyJC1iDwq82nDF8KfKeqdgBXAacnmdlMeD+9aZMkSZr2xp2TleRTwGnArCTb6Hxi8HCAqvoIsA54DTAMfB/4taZvV5L3AeubXa2uqgNNoJckSZo2xg1ZVfWmcfoLOHeMvrXA2sdXmiRJ0tTVFxPfJUmSphtDliRJUgsMWZIkSS0wZEmSJLXAkCVJktQCQ5YkSVILDFmSJEktMGRJkiS1wJAlSZLUAkOWJElSCwxZkiRJLTBkSZIktcCQJUmS1AJDliRJUgsMWZIkSS0wZEmSJLXAkCVJktQCQ5YkSVILegpZSZYm2ZxkOMmqUfovTHJ98/NvSe7t6nukq29wIouXJEnqV4eNNyDJDOAi4FXANmB9ksGq2rRvTFW9o2v8fwVO7trFA1V10sSVLEmS1P96uZK1BBiuqi1V9RBwKbDsAOPfBHxqIoqTJEmaqnoJWXOAO7rWtzVt+0myADgeuKar+UlJhpJcm+SsMbZb0YwZuuuuu3osXZIkqX9N9MT35cAVVfVIV9uCqhoA3gx8MMlzRm5UVWuqaqCqBmbPnj3BJUmSJB16vYSs7cC8rvW5TdtoljPiVmFVbW9+bwH+iUfP15IkSZqWeglZ64FFSY5PcgSdILXfpwSTPB+YCXy9q21mkiOb5VnAy4BNI7eVJEmabsb9dGFV7UmyErgKmAGsraqNSVYDQ1W1L3AtBy6tqura/AXAxUn20gl0F3R/KlGSJGm6GjdkAVTVOmDdiLbzRqy/d5Ttvga88CDqkyRJmpL8xndJkqQWGLIkSZJaYMiSJElqgSFLkiSpBYYsSZKkFhiyJEmSWmDIkiRJaoEhS5IkqQWGLEmSpBYYsiRJklpgyJIkSWqBIUuSJKkFhixJkqQWGLIkSZJaYMiSJElqgSFLkiSpBYYsSZKkFhiyJEmSWtBTyEqyNMnmJMNJVo3Sf06Su5Jc3/y8tavv7CS3ND9nT2TxkiRJ/eqw8QYkmQFcBLwK2AasTzJYVZtGDL2sqlaO2PY44HxgAChgQ7Pt7gmpXpIkqU/1ciVrCTBcVVuq6iHgUmBZj/s/A7i6qnY1wepqYOnjK1WSJGnq6CVkzQHu6Frf1rSN9ItJbkhyRZJ5j2XbJCuSDCUZuuuuu3osXZIkqX9N1MT3/wssrKqfpHO16pLHsnFVramqgaoamD179gSVJEmSNHl6CVnbgXld63Obth+qqnuq6sFm9S+BF/e6rSRJ0nTUS8haDyxKcnySI4DlwGD3gCTP7Fo9E7i5Wb4KOD3JzCQzgdObNkmSpGlt3E8XVtWeJCvphKMZwNqq2phkNTBUVYPAbyU5E9gD7ALOabbdleR9dIIawOqq2tXCcUiSJPWVVNVk1/AoAwMDNTQ0NNllSJLUu0/m4Pfx5v76e6zeJNlQVQOj9fmN75IkSS0wZEmSJLXAkCVJktQCQ5YkSVILDFmSJEktMGRJkiS1wJAlSZLUAkOWJElSCwxZkiRJLTBkSZIktcCQJUmS1AJDliRJUgsMWZIkSS0wZEmSJLXAkCVJktQCQ5YkSVILDFmSJEkt6ClkJVmaZHOS4SSrRun/3SSbktyQ5ItJFnT1PZLk+uZncCKLlyRJ6leHjTcgyQzgIuBVwDZgfZLBqtrUNexbwEBVfT/JbwB/DLyx6Xugqk6a4LolSZL6Wi9XspYAw1W1paoeAi4FlnUPqKovVdX3m9VrgbkTW6YkSdLU0kvImgPc0bW+rWkby1uAz3WtPynJUJJrk5z1OGqUJEmacsa9XfhYJPllYAD4ma7mBVW1PcmzgWuS3FhVt47YbgWwAmD+/PkTWZIkSdKk6OVK1nZgXtf63KbtUZK8EvgD4MyqenBfe1Vtb35vAf4JOHnktlW1pqoGqmpg9uzZj+kAJEmS+lEvIWs9sCjJ8UmOAJYDj/qUYJKTgYvpBKydXe0zkxzZLM8CXgZ0T5iXJEmalsa9XVhVe5KsBK4CZgBrq2pjktXAUFUNAh8AjgI+nQTg9qo6E3gBcHGSvXQC3QUjPpUoSZI0LfU0J6uq1gHrRrSd17X8yjG2+xrwwoMpUJIkaSryG98lSZJaYMiSJElqgSFLkiSpBYYsSZKkFhiyJEmSWmDIkiRJaoEhS5IkqQWGLEmSpBYYsiRJklpgyJIkSWqBIUuSJKkFhixJkqQWGLIkSZJaYMiSJElqgSFLkiSpBYYsSZKkFhiyJEmSWmDIkiRJakFPISvJ0iSbkwwnWTVK/5FJLmv6r0uysKvv95v2zUnOmLjSJUmS+te4ISvJDOAi4NXAYuBNSRaPGPYWYHdVnQBcCPxRs+1iYDlwIrAU+HCzP0mSpGmtlytZS4DhqtpSVQ8BlwLLRoxZBlzSLF8BvCJJmvZLq+rBqvp3YLjZnyRJ0rTWS8iaA9zRtb6taRt1TFXtAb4DPK3HbSVJkqadwya7AIAkK4AVzep3k2yezHoas4C7J7sI9cRzNTV4nqYOz9Vk+KU8nq08V5NvwVgdvYSs7cC8rvW5TdtoY7YlOQw4Frinx22pqjXAmh5qOWSSDFXVwGTXofF5rqYGz9PU4bmaOjxX/a2X24XrgUVJjk9yBJ2J7IMjxgwCZzfLrwOuqapq2pc3nz48HlgEfGNiSpckSepf417Jqqo9SVYCVwEzgLVVtTHJamCoqgaBjwGfSDIM7KITxGjGXQ5sAvYA51bVIy0diyRJUt9I54KTRkqyormNqT7nuZoaPE9Th+dq6vBc9TdDliRJUgt8rI4kSVILDFmjGO8xQuofSbYmuTHJ9UmGJrsedSRZm2Rnkpu62o5LcnWSW5rfMyezRnWMca7em2R78766PslrJrNGQZJ5Sb6UZFOSjUl+u2n3fdXHDFkj9PgYIfWXn62qk/wYc1/5OJ1HaXVbBXyxqhYBX2zWNfk+zv7nCuDC5n11UlWtO8Q1aX97gHdW1WLgpcC5zd8m31d9zJC1v14eIyTpAKrqn+l80rhb9+O3LgHOOqRFaVRjnCv1maraUVXfbJbvB26m8wQV31d9zJC1Px8FNLUU8PkkG5onB6h/PaOqdjTL3waeMZnFaFwrk9zQ3E70FlQfSbIQOBm4Dt9Xfc2Qpanu5VX1Ijq3d89NcupkF6TxNV9W7Eeb+9dfAM8BTgJ2AH86ueVonyRHAZ8Bfqeq7uvu833VfwxZ++vpUUDqD1W1vfm9E/hbOrd71Z/uTPJMgOb3zkmuR2Ooqjur6pGq2gt8FN9XfSHJ4XQC1t9U1WebZt9XfcyQtb9eHiOkPpDkKUmO3rcMnA7cdOCtNIm6H791NvB3k1iLDmDfH+3Gz+P7atIlCZ2nq9xcVX/W1eX7qo/5ZaSjaD6u/EF+9Bih909ySRpFkmfTuXoFnUdEfdJz1R+SfAo4DZgF3AmcD1wJXA7MB24D3lBVTrieZGOcq9Po3CosYCvwtq55P5oESV4OfAW4EdjbNL+Hzrws31d9ypAlSZLUAm8XSpIktcCQJUmS1AJDliRJUgsMWZIkSS0wZEmSJLXAkCVJktQCQ5YkSVILDFmSJEktMGRJkiS1wJAlSZLUAkOWJElSCwxZkiRJLTBkSZIktcCQJUmS1AJDlqRJkeTjSf5ns/zTSTYfotetJCc8xm1OS7KtrZokTU+GLEljSrI1yQNJvpvkziYYHTXRr1NVX6mq5/VQzzlJvjrRry9JbTBkSRrPz1XVUcCLgAHgv48ckOSwQ16VJPU5Q5aknlTVduBzwE/AD2+7nZvkFuCWpu0/J7k+yb1JvpbkJ/dtn+TkJN9Mcn+Sy4AndfU96nZcknlJPpvkriT3JPlQkhcAHwF+qrmydm8z9sgkf5Lk9uZq20eS/FjXvt6dZEeS/0jyXw50jEmOS/JXzdjdSa4cY9yqJLc2x7Ipyc939Z2Q5MtJvpPk7uZYSceFSXYmuS/JjUn2/bMc8xiSzEry980/011JvpLE/3ZLU4BvVEk9STIPeA3wra7ms4BTgMVJTgbWAm8DngZcDAw2AeII4ErgE8BxwKeBXxzjdWYAfw/cBiwE5gCXVtXNwNuBr1fVUVX11GaTC4DnAicBJzTjz2v2tRR4F/AqYBHwynEO8xPAk4ETgacDF44x7lbgp4Fjgf8B/HWSZzZ97wM+D8wE5gL/u2k/HTi1qfVY4A3APeMdA/BOYBswG3gG8B6gxjkOSX3AkCVpPFc2V42+CnwZ+MOuvv9VVbuq6gFgBXBxVV1XVY9U1SXAg8BLm5/DgQ9W1cNVdQWwfozXWwI8C3h3VX2vqn5QVaPOw0qS5nXf0dRxf1Pf8mbIG4C/qqqbqup7wHvHOsgmJL0aeHtV7W7q/PJoY6vq01X1H1W1t6ouo3Mlb0nT/TCwAHjWiNofBo4Gng+kqm6uqh09HMPDwDOBBU1NX6kqQ5Y0BRiyJI3nrKp6alUtqKrfbALVPnd0LS8A3tnc1rq3CWbz6ASmZwHbR4SD28Z4vXnAbVW1p4faZtO58rSh6zX/sWmned3uGsd6zX2vu6uqdo/3okl+teu26L10bqHOarr/GxDgG0k27rtFWVXXAB8CLgJ2JlmT5JgejuEDwDDw+SRbkqwarz5J/cGQJelgdIemO4D3N4Fs38+Tq+pTwA5gTnPVZp/5Y+zzDmD+GJPpR17BuRt4ADix6zWPbSbq07zuvB5ec9/rHpfkqQcYQ5IFwEeBlcDTmtuWN9EJVlTVt6vq16vqWXRunX5431dGVNWfV9WLgcV0bg++e7xjqKr7q+qdVfVs4Ezgd5O84kA1SuoPhixJE+WjwNuTnNJM8n5KktcmORr4OrAH+K0khyf5BX50e22kb9AJRxc0+3hSkpc1fXcCc5s5XlTV3uZ1L0zydIAkc5Kc0Yy/HDgnyeIkTwbOH6v4qtpBZ2L/h5PMbOo8dZShT6ET9u5qXu/XaD4M0Ky/PsncZnV3M3Zvkpc0/2wOB74H/ADYO94xpPNhghOagPod4BFg71jHIal/GLIkTYiqGgJ+nc4tsd10bnGd0/Q9BPxCs74LeCPw2TH28wjwc3QmgN9OZ9L3G5vua4CNwLeT3N20/V7zWtcmuQ/4AvC8Zl+fAz7YbDfc/D6QX6EzB+pfgZ3A74xS3ybgT+kExzuBFwL/r2vIS4DrknwXGAR+u6q2AMfQCVO76dy2vIfOrcADHgOdCftfAL7bvOaHq+pL4xyHpD4Q509KkiRNPK9kSZIktcCQJUmS1AJDliRJUgsMWZIkSS0wZEmSJLVgtC/7m1SzZs2qhQsXTnYZkiRJ49qwYcPdVTV7tL6+C1kLFy5kaGhossuQJEkaV5IxH9fl7UJJkqQWGLIkSZJaYMiSJElqQd/NyZIkCWDhqn846H1sveC1E1CJ9Ph4JUuSJKkFhixJkqQWGLIkSZJaYMiSJElqgSFLkiSpBYYsSZKkFhiyJEmSWmDIkiRJakFPISvJ0iSbkwwnWTVK/+8m2ZTkhiRfTLKgq+/sJLc0P2dPZPGSJEn9atyQlWQGcBHwamAx8KYki0cM+xYwUFU/CVwB/HGz7XHA+cApwBLg/CQzJ658SZKk/tTLlawlwHBVbamqh4BLgWXdA6rqS1X1/Wb1WmBus3wGcHVV7aqq3cDVwNKJKV2SJKl/9RKy5gB3dK1va9rG8hbgc49zW0mSpGlhQh8QneSXgQHgZx7jdiuAFQDz58+fyJIkSZImRS9XsrYD87rW5zZtj5LklcAfAGdW1YOPZduqWlNVA1U1MHv27F5rlyRJ6lu9hKz1wKIkxyc5AlgODHYPSHIycDGdgLWzq+sq4PQkM5sJ76c3bZIkSdPauLcLq2pPkpV0wtEMYG1VbUyyGhiqqkHgA8BRwKeTANxeVWdW1a4k76MT1ABWV9WuVo5EkiSpj/Q0J6uq1gHrRrSd17X8ygNsuxZY+3gLlCRJmor8xndJkqQWGLIkSZJaYMiSJElqgSFLkiSpBYYsSZKkFhiyJEmSWmDIkiRJaoEhS5IkqQWGLEmSpBYYsiRJklpgyJIkSWqBIUuSJKkFhixJkqQWGLIkSZJaYMiSJElqQU8hK8nSJJuTDCdZNUr/qUm+mWRPkteN6HskyfXNz+BEFS5JktTPDhtvQJIZwEXAq4BtwPokg1W1qWvY7cA5wLtG2cUDVXXSBNQqSZI0ZYwbsoAlwHBVbQFIcimwDPhhyKqqrU3f3hZqlCRJmnJ6uV04B7ija31b09arJyUZSnJtkrMeU3WSJElTVC9Xsg7WgqranuTZwDVJbqyqW7sHJFkBrACYP3/+IShJkiSpXb1cydoOzOtan9u09aSqtje/twD/BJw8ypg1VTVQVQOzZ8/uddeSJEl9q5eQtR5YlOT4JEcAy4GePiWYZGaSI5vlWcDL6JrLJUmSNF2NG7Kqag+wErgKuBm4vKo2Jlmd5EyAJC9Jsg14PXBxko3N5i8AhpL8C/Al4IIRn0qUJEmalnqak1VV64B1I9rO61peT+c24sjtvga88CBrlCRJmnIOxcR3SZr2Fq76h4Pex9YLXjsBlUjqFz5WR5IkqQWGLEmSpBYYsiRJklpgyJIkSWqBIUuSJKkFhixJkqQWGLIkSZJaYMiSJElqgSFLkiSpBYYsSZKkFhiyJEmSWmDIkiRJaoEhS5IkqQWGLEmSpBb0FLKSLE2yOclwklWj9J+a5JtJ9iR53Yi+s5Pc0vycPVGFS5Ik9bNxQ1aSGcBFwKuBxcCbkiweMex24BzgkyO2PQ44HzgFWAKcn2TmwZctSZLU33q5krUEGK6qLVX1EHApsKx7QFVtraobgL0jtj0DuLqqdlXVbuBqYOkE1C1JktTXeglZc4A7uta3NW296GnbJCuSDCUZuuuuu3rctSRJUv/qi4nvVbWmqgaqamD27NmTXY4kSdJB6yVkbQfmda3Pbdp6cTDbSpIkTVm9hKz1wKIkxyc5AlgODPa4/6uA05PMbCa8n960SZIkTWvjhqyq2gOspBOObgYur6qNSVYnORMgyUuSbANeD1ycZGOz7S7gfXSC2npgddMmSZI0rR3Wy6CqWgesG9F2Xtfyejq3Akfbdi2w9iBqlCRJmnL6YuK7JEnSdNPTlSxJkqaDhav+YUL2s/WC107IfjS9eSVLkiSpBYYsSZKkFhiyJEmSWmDIkiRJaoEhS5IkqQWGLEmSpBb4FQ6SJB2kifhqCL8WYvoxZElPQP5BkKT2ebtQkiSpBYYsSZKkFhiyJEmSWmDIkiRJakFPISvJ0iSbkwwnWTVK/5FJLmv6r0uysGlfmOSBJNc3Px+Z2PIlSZL607ifLkwyA7gIeBWwDVifZLCqNnUNewuwu6pOSLIc+CPgjU3frVV10gTXLUmS1Nd6uZK1BBiuqi1V9RBwKbBsxJhlwCXN8hXAK5Jk4sqUJEmaWnoJWXOAO7rWtzVto46pqj3Ad4CnNX3HJ/lWki8n+emDrFeSJGlKaPvLSHcA86vqniQvBq5McmJV3dc9KMkKYAXA/PnzWy5pavFLIzVV+O+qJD1aLyFrOzCva31u0zbamG1JDgOOBe6pqgIeBKiqDUluBZ4LDHVvXFVrgDUAAwMD9TiOQ33AP7KSJP1IL7cL1wOLkhyf5AhgOTA4YswgcHaz/DrgmqqqJLObifMkeTawCNgyMaVLkiT1r3GvZFXVniQrgauAGcDaqtqYZDUwVFWDwMeATyQZBnbRCWIApwKrkzwM7AXeXlW72jgQSZKkftLTnKyqWgesG9F2XtfyD4DXj7LdZ4DPHGSNkiRJU07bE98lSU8AzsmU9udjdSRJklrglSxpgrTxf/JeHXhi8/xLU5tXsiRJklpgyJIkSWqBtwsl6QnG25DSoeGVLEmSpBZ4JUuSJB0Ur46OzitZkiRJLTBkSZIktcCQJUmS1ALnZEl6wnH+iKRD4QkbsvyPrCRJatMTNmTpic2QLUlqmyFLkqQnCP8H89DqaeJ7kqVJNicZTrJqlP4jk1zW9F+XZGFX3+837ZuTnDFxpUuSJPWvcUNWkhnARcCrgcXAm5IsHjHsLcDuqjoBuBD4o2bbxcBy4ERgKfDhZn+SJEnTWi9XspYAw1W1paoeAi4Flo0Yswy4pFm+AnhFkjTtl1bVg1X178Bwsz9JkqRprZc5WXOAO7rWtwGnjDWmqvYk+Q7wtKb92hHbznnc1WrCeF9eU4H/nkqaylJVBx6QvA5YWlVvbdZ/BTilqlZ2jbmpGbOtWb+VThB7L3BtVf110/4x4HNVdcWI11gBrGhWnwdsPvhDO2izgLsnuwj1xHM1NXiepg7P1dThuZp8C6pq9mgdvVzJ2g7M61qf27SNNmZbksOAY4F7etyWqloDrOmhlkMmyVBVDUx2HRqf52pq8DxNHZ6rqcNz1d96mZO1HliU5PgkR9CZyD44YswgcHaz/DrgmupcIhsEljefPjweWAR8Y2JKlyRJ6l/jXslq5litBK4CZgBrq2pjktXAUFUNAh8DPpFkGNhFJ4jRjLsc2ATsAc6tqkdaOhZJkqS+Me6crCeqJCua25jqc56rqcHzNHV4rqYOz1V/M2RJkiS1oKdvfJckSdJjY8gaxXiPEVL/SLI1yY1Jrk8yNNn1qCPJ2iQ7m6932dd2XJKrk9zS/J45mTWqY4xz9d4k25v31fVJXjOZNQqSzEvypSSbkmxM8ttNu++rPmbIGqHHxwipv/xsVZ3kx5j7ysfpPEqr2yrgi1W1CPhis67J93H2P1cAFzbvq5Oqat0hrkn72wO8s6oWAy8Fzm3+Nvm+6mOGrP318hghSQdQVf9M55PG3bofv3UJcNYhLUqjGuNcqc9U1Y6q+mazfD9wM50nqPi+6mOGrP2N9hghHwXUvwr4fJINzZMD1L+eUVU7muVvA8+YzGI0rpVJbmhuJ3oLqo8kWQicDFyH76u+ZsjSVPfyqnoRndu75yY5dbIL0viaLyv2o8396y+A5wAnATuAP53ccrRPkqOAzwC/U1X3dff5vuo/hqz99fQoIPWHqtre/N4J/C2d273qT3cmeSZA83vnJNejMVTVnVX1SFXtBT6K76u+kORwOgHrb6rqs02z76s+ZsjaXy+PEVIfSPKUJEfvWwZOB2468FaaRN2P3zob+LtJrEUHsO+PduPn8X016ZKEztNVbq6qP+vq8n3Vx/wy0lE0H1f+ID96jND7J7kkjSLJs+lcvYLOI6I+6bnqD0k+BZwGzALuBM4HrgQuB+YDtwFvqConXE+yMc7VaXRuFRawFXhb17wfTYIkLwe+AtwI7G2a30NnXpbvqz5lyJIkSWqBtwslSZJaYMiSJElqgSFLkiSpBYYsSZKkFhiyJEmSWmDIkiRJaoEhS5IkqQWGLEmSpBb8f15ABMhiGbAVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9usq4WI7eRBn",
        "outputId": "17af3a53-c13f-4c3c-d21f-bd8af5fe9130"
      },
      "source": [
        "# view = py3Dmol.view(query='pdb:'+'1a9x', linked=True, viewergrid=(2,2))\n",
        "# view.setViewStyle({'style':'outline','color':'black','width':0.1})\n",
        "# view.setStyle({'cartoon':{'arrows':True, 'tubes':True, 'style':'oval', 'color':'white'}},viewer=(0,1))\n",
        "# view.setStyle({'stick':{'colorscheme':'greenCarbon'}},viewer=(1,0))\n",
        "# view.setStyle({'cartoon':{'color':'spectrum'}},viewer=(1,1))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHwiZ3UJm1yk"
      },
      "source": [
        "TODO: I don't think there's exactly alignment between the files and the mols\n",
        "Maybe consider adding the mol to the \"diagrams\" file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "MszSyysYjBes",
        "outputId": "3dd7b546-484c-460b-a7db-0e770160f419"
      },
      "source": [
        "# Get a random true class from PDB\n",
        "rand_true_class = random.choice(true_class_profiles)\n",
        "\n",
        "file = os.listdir(\"./SCOP40mini\")[rand_true_class]\n",
        "structure_id = os.path.splitext(file)[0]\n",
        "structure = parser.get_structure(structure_id, \"./SCOP40mini/\" + file)\n",
        "pdb_id_rand_true_class = parser.get_header()['astral']['Source-PDB']\n",
        "\n",
        "rand_true_class_mol = py3Dmol.view(query='pdb:'+pdb_id_rand_true_class)\n",
        "rand_true_class_mol.setStyle({'cartoon':{'color':'spectrum'}})"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_16354699520693216\"  style=\"position: relative; width: 640px; height: 480px\">\n        <p id=\"3dmolwarning_16354699520693216\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n      resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n}\n\nvar viewer_16354699520693216 = null;\nvar warn = document.getElementById(\"3dmolwarning_16354699520693216\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_16354699520693216 = $3Dmol.createViewer($(\"#3dmolviewer_16354699520693216\"),{backgroundColor:\"white\"});\n$3Dmol.download(\"pdb:1hv8\", viewer_16354699520693216, {}, function() {\nviewer_16354699520693216.zoomTo();\n\tviewer_16354699520693216.setStyle({\"cartoon\": {\"color\": \"spectrum\"}});\nviewer_16354699520693216.render();\n})\n});\n</script>",
            "text/html": [
              "<div id=\"3dmolviewer_16354699520693216\"  style=\"position: relative; width: 640px; height: 480px\">\n",
              "        <p id=\"3dmolwarning_16354699520693216\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n",
              "        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n",
              "        </div>\n",
              "<script>\n",
              "\n",
              "var loadScriptAsync = function(uri){\n",
              "  return new Promise((resolve, reject) => {\n",
              "    var tag = document.createElement('script');\n",
              "    tag.src = uri;\n",
              "    tag.async = true;\n",
              "    tag.onload = () => {\n",
              "      resolve();\n",
              "    };\n",
              "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
              "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
              "});\n",
              "};\n",
              "\n",
              "if(typeof $3Dmolpromise === 'undefined') {\n",
              "$3Dmolpromise = null;\n",
              "  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n",
              "}\n",
              "\n",
              "var viewer_16354699520693216 = null;\n",
              "var warn = document.getElementById(\"3dmolwarning_16354699520693216\");\n",
              "if(warn) {\n",
              "    warn.parentNode.removeChild(warn);\n",
              "}\n",
              "$3Dmolpromise.then(function() {\n",
              "viewer_16354699520693216 = $3Dmol.createViewer($(\"#3dmolviewer_16354699520693216\"),{backgroundColor:\"white\"});\n",
              "$3Dmol.download(\"pdb:1hv8\", viewer_16354699520693216, {}, function() {\n",
              "viewer_16354699520693216.zoomTo();\n",
              "\tviewer_16354699520693216.setStyle({\"cartoon\": {\"color\": \"spectrum\"}});\n",
              "viewer_16354699520693216.render();\n",
              "})\n",
              "});\n",
              "</script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<py3Dmol.view at 0x7f2e8a397a90>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "2HBCsaszjCPU",
        "outputId": "d10d700c-d54c-48cd-ef07-875ba064fe8c"
      },
      "source": [
        "# Get a random predicted class from PDB\n",
        "rand_pred_class = random.choice(pred_class_profiles)\n",
        "\n",
        "file = os.listdir(\"./SCOP40mini\")[rand_pred_class]\n",
        "structure_id = os.path.splitext(file)[0]\n",
        "structure = parser.get_structure(structure_id, \"./SCOP40mini/\" + file)\n",
        "pdb_id_rand_pred_class = parser.get_header()['astral']['Source-PDB']\n",
        "\n",
        "rand_pred_class_mol = py3Dmol.view(query='pdb:'+pdb_id_rand_pred_class)\n",
        "rand_pred_class_mol.setStyle({'cartoon':{'color':'spectrum'}})"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_16354699437613018\"  style=\"position: relative; width: 640px; height: 480px\">\n        <p id=\"3dmolwarning_16354699437613018\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n      resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n}\n\nvar viewer_16354699437613018 = null;\nvar warn = document.getElementById(\"3dmolwarning_16354699437613018\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_16354699437613018 = $3Dmol.createViewer($(\"#3dmolviewer_16354699437613018\"),{backgroundColor:\"white\"});\n$3Dmol.download(\"pdb:1u0l\", viewer_16354699437613018, {}, function() {\nviewer_16354699437613018.zoomTo();\n\tviewer_16354699437613018.setStyle({\"cartoon\": {\"color\": \"spectrum\"}});\nviewer_16354699437613018.render();\n})\n});\n</script>",
            "text/html": [
              "<div id=\"3dmolviewer_16354699437613018\"  style=\"position: relative; width: 640px; height: 480px\">\n",
              "        <p id=\"3dmolwarning_16354699437613018\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n",
              "        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n",
              "        </div>\n",
              "<script>\n",
              "\n",
              "var loadScriptAsync = function(uri){\n",
              "  return new Promise((resolve, reject) => {\n",
              "    var tag = document.createElement('script');\n",
              "    tag.src = uri;\n",
              "    tag.async = true;\n",
              "    tag.onload = () => {\n",
              "      resolve();\n",
              "    };\n",
              "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
              "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
              "});\n",
              "};\n",
              "\n",
              "if(typeof $3Dmolpromise === 'undefined') {\n",
              "$3Dmolpromise = null;\n",
              "  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n",
              "}\n",
              "\n",
              "var viewer_16354699437613018 = null;\n",
              "var warn = document.getElementById(\"3dmolwarning_16354699437613018\");\n",
              "if(warn) {\n",
              "    warn.parentNode.removeChild(warn);\n",
              "}\n",
              "$3Dmolpromise.then(function() {\n",
              "viewer_16354699437613018 = $3Dmol.createViewer($(\"#3dmolviewer_16354699437613018\"),{backgroundColor:\"white\"});\n",
              "$3Dmol.download(\"pdb:1u0l\", viewer_16354699437613018, {}, function() {\n",
              "viewer_16354699437613018.zoomTo();\n",
              "\tviewer_16354699437613018.setStyle({\"cartoon\": {\"color\": \"spectrum\"}});\n",
              "viewer_16354699437613018.render();\n",
              "})\n",
              "});\n",
              "</script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<py3Dmol.view at 0x7f2e8af6aa10>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "8P4pcFzkjD8i",
        "outputId": "66d984ce-d035-4054-df8e-8efd4eb56797"
      },
      "source": [
        "# Get the actual file of interest\n",
        "file = os.listdir(\"./SCOP40mini\")[i]\n",
        "structure_id = os.path.splitext(file)[0]\n",
        "structure = parser.get_structure(structure_id, \"./SCOP40mini/\" + file)\n",
        "pdb_id = parser.get_header()['astral']['Source-PDB']\n",
        "\n",
        "selected_mol = py3Dmol.view(query='pdb:'+pdb_id)\n",
        "selected_mol.setStyle({'cartoon':{'color':'spectrum'}})"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_16354699569408987\"  style=\"position: relative; width: 640px; height: 480px\">\n        <p id=\"3dmolwarning_16354699569408987\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n      resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n}\n\nvar viewer_16354699569408987 = null;\nvar warn = document.getElementById(\"3dmolwarning_16354699569408987\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_16354699569408987 = $3Dmol.createViewer($(\"#3dmolviewer_16354699569408987\"),{backgroundColor:\"white\"});\n$3Dmol.download(\"pdb:1gw0\", viewer_16354699569408987, {}, function() {\nviewer_16354699569408987.zoomTo();\n\tviewer_16354699569408987.setStyle({\"cartoon\": {\"color\": \"spectrum\"}});\nviewer_16354699569408987.render();\n})\n});\n</script>",
            "text/html": [
              "<div id=\"3dmolviewer_16354699569408987\"  style=\"position: relative; width: 640px; height: 480px\">\n",
              "        <p id=\"3dmolwarning_16354699569408987\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n",
              "        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n",
              "        </div>\n",
              "<script>\n",
              "\n",
              "var loadScriptAsync = function(uri){\n",
              "  return new Promise((resolve, reject) => {\n",
              "    var tag = document.createElement('script');\n",
              "    tag.src = uri;\n",
              "    tag.async = true;\n",
              "    tag.onload = () => {\n",
              "      resolve();\n",
              "    };\n",
              "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
              "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
              "});\n",
              "};\n",
              "\n",
              "if(typeof $3Dmolpromise === 'undefined') {\n",
              "$3Dmolpromise = null;\n",
              "  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n",
              "}\n",
              "\n",
              "var viewer_16354699569408987 = null;\n",
              "var warn = document.getElementById(\"3dmolwarning_16354699569408987\");\n",
              "if(warn) {\n",
              "    warn.parentNode.removeChild(warn);\n",
              "}\n",
              "$3Dmolpromise.then(function() {\n",
              "viewer_16354699569408987 = $3Dmol.createViewer($(\"#3dmolviewer_16354699569408987\"),{backgroundColor:\"white\"});\n",
              "$3Dmol.download(\"pdb:1gw0\", viewer_16354699569408987, {}, function() {\n",
              "viewer_16354699569408987.zoomTo();\n",
              "\tviewer_16354699569408987.setStyle({\"cartoon\": {\"color\": \"spectrum\"}});\n",
              "viewer_16354699569408987.render();\n",
              "})\n",
              "});\n",
              "</script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<py3Dmol.view at 0x7f2e8b837790>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt-hQsqZuswD"
      },
      "source": [
        "file = os.listdir(\"./SCOP40mini\")[i]\n",
        "structure_id = os.path.splitext(file)[0]\n",
        "structure = parser.get_structure(structure_id, \"./SCOP40mini/\" + file)\n",
        "pdb_id = parser.get_header()['astral']['Source-PDB']\n",
        "\n",
        "view = py3Dmol.view(query='pdb:'+pdb_id)\n",
        "view.setStyle({'cartoon':{'color':'spectrum'}})\n",
        "view"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q66dQnVORsIm"
      },
      "source": [
        "### Multiclass classifier (stable)\n",
        "\n",
        "The following model achieves about 42% acc without overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uO8BBFxFrK-",
        "outputId": "f6c79768-4cb7-4a9c-9b00-21c03a381aae"
      },
      "source": [
        "# Build sequential model for superfamily\n",
        "k_initializer = tf.keras.initializers.he_uniform()\n",
        "b_initializer = tf.keras.initializers.Ones()\n",
        "\n",
        "dropout_rate = 0.10\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(200, activation = 'relu', \n",
        "            input_shape = train_data[0].shape, \n",
        "            kernel_initializer=k_initializer,\n",
        "            bias_initializer=b_initializer),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(200, activation = 'relu'),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(200, activation = 'relu'),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(128, activation = 'relu'),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(128, activation = 'relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(train_data, train_targets, \n",
        "                    epochs=800, validation_split=0.15, batch_size=100, \n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/800\n",
            "10/10 [==============================] - 1s 31ms/step - loss: 204.0123 - acc: 0.0770 - val_loss: 29.4518 - val_acc: 0.0613\n",
            "Epoch 2/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 45.5439 - acc: 0.0781 - val_loss: 15.2686 - val_acc: 0.1472\n",
            "Epoch 3/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 25.2997 - acc: 0.1030 - val_loss: 8.0702 - val_acc: 0.1534\n",
            "Epoch 4/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.8617 - acc: 0.0911 - val_loss: 4.5176 - val_acc: 0.1963\n",
            "Epoch 5/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.8458 - acc: 0.0748 - val_loss: 3.7957 - val_acc: 0.0798\n",
            "Epoch 6/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.7563 - acc: 0.0835 - val_loss: 3.4106 - val_acc: 0.0491\n",
            "Epoch 7/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.5472 - acc: 0.0716 - val_loss: 3.2556 - val_acc: 0.0798\n",
            "Epoch 8/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.5744 - acc: 0.0803 - val_loss: 3.1444 - val_acc: 0.0798\n",
            "Epoch 9/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7597 - acc: 0.0868 - val_loss: 3.1350 - val_acc: 0.1227\n",
            "Epoch 10/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2417 - acc: 0.0965 - val_loss: 3.1336 - val_acc: 0.0920\n",
            "Epoch 11/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9173 - acc: 0.0770 - val_loss: 3.1408 - val_acc: 0.0613\n",
            "Epoch 12/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.6495 - acc: 0.0944 - val_loss: 3.0886 - val_acc: 0.0982\n",
            "Epoch 13/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5309 - acc: 0.0965 - val_loss: 3.0532 - val_acc: 0.0982\n",
            "Epoch 14/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5556 - acc: 0.0976 - val_loss: 3.0521 - val_acc: 0.0982\n",
            "Epoch 15/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.4471 - acc: 0.0900 - val_loss: 3.0716 - val_acc: 0.0920\n",
            "Epoch 16/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3788 - acc: 0.0987 - val_loss: 3.1022 - val_acc: 0.0613\n",
            "Epoch 17/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.2541 - acc: 0.0987 - val_loss: 3.1139 - val_acc: 0.0552\n",
            "Epoch 18/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.3561 - acc: 0.0868 - val_loss: 3.1036 - val_acc: 0.0552\n",
            "Epoch 19/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.3272 - acc: 0.1041 - val_loss: 3.0087 - val_acc: 0.1043\n",
            "Epoch 20/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.3308 - acc: 0.1117 - val_loss: 2.9511 - val_acc: 0.1166\n",
            "Epoch 21/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.1976 - acc: 0.1356 - val_loss: 2.9577 - val_acc: 0.1043\n",
            "Epoch 22/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.2583 - acc: 0.1041 - val_loss: 3.0330 - val_acc: 0.0613\n",
            "Epoch 23/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.1281 - acc: 0.0965 - val_loss: 2.9845 - val_acc: 0.1043\n",
            "Epoch 24/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.1065 - acc: 0.1041 - val_loss: 2.9668 - val_acc: 0.1043\n",
            "Epoch 25/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.0816 - acc: 0.0998 - val_loss: 2.9197 - val_acc: 0.1043\n",
            "Epoch 26/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.0950 - acc: 0.1345 - val_loss: 2.9036 - val_acc: 0.1104\n",
            "Epoch 27/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.0870 - acc: 0.1291 - val_loss: 2.9000 - val_acc: 0.1166\n",
            "Epoch 28/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.0279 - acc: 0.1323 - val_loss: 2.8728 - val_acc: 0.1166\n",
            "Epoch 29/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.0252 - acc: 0.1280 - val_loss: 2.8720 - val_acc: 0.1166\n",
            "Epoch 30/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.0718 - acc: 0.1226 - val_loss: 2.8929 - val_acc: 0.1043\n",
            "Epoch 31/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.0311 - acc: 0.1128 - val_loss: 2.9145 - val_acc: 0.1043\n",
            "Epoch 32/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.0162 - acc: 0.0987 - val_loss: 2.8984 - val_acc: 0.1043\n",
            "Epoch 33/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.0208 - acc: 0.1269 - val_loss: 2.8599 - val_acc: 0.1166\n",
            "Epoch 34/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.9838 - acc: 0.1312 - val_loss: 2.8553 - val_acc: 0.1166\n",
            "Epoch 35/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.9648 - acc: 0.1269 - val_loss: 2.8478 - val_acc: 0.1104\n",
            "Epoch 36/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.9515 - acc: 0.1312 - val_loss: 2.8334 - val_acc: 0.1166\n",
            "Epoch 37/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.9748 - acc: 0.1302 - val_loss: 2.8381 - val_acc: 0.1166\n",
            "Epoch 38/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.9732 - acc: 0.1453 - val_loss: 2.8415 - val_acc: 0.1656\n",
            "Epoch 39/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.9979 - acc: 0.1529 - val_loss: 2.8533 - val_acc: 0.1534\n",
            "Epoch 40/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.9204 - acc: 0.1367 - val_loss: 2.8259 - val_acc: 0.1656\n",
            "Epoch 41/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.9257 - acc: 0.1551 - val_loss: 2.8143 - val_acc: 0.2086\n",
            "Epoch 42/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.9225 - acc: 0.1388 - val_loss: 2.8355 - val_acc: 0.1595\n",
            "Epoch 43/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.9217 - acc: 0.1453 - val_loss: 2.8251 - val_acc: 0.1718\n",
            "Epoch 44/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8920 - acc: 0.1616 - val_loss: 2.8104 - val_acc: 0.1718\n",
            "Epoch 45/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8752 - acc: 0.1616 - val_loss: 2.8057 - val_acc: 0.1779\n",
            "Epoch 46/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.8878 - acc: 0.1627 - val_loss: 2.8042 - val_acc: 0.1840\n",
            "Epoch 47/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.8736 - acc: 0.1649 - val_loss: 2.8088 - val_acc: 0.1902\n",
            "Epoch 48/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.8456 - acc: 0.1670 - val_loss: 2.7910 - val_acc: 0.2025\n",
            "Epoch 49/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.8369 - acc: 0.1703 - val_loss: 2.7908 - val_acc: 0.2086\n",
            "Epoch 50/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.8543 - acc: 0.1659 - val_loss: 2.7871 - val_acc: 0.2086\n",
            "Epoch 51/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.8358 - acc: 0.1790 - val_loss: 2.7888 - val_acc: 0.1902\n",
            "Epoch 52/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8510 - acc: 0.1627 - val_loss: 2.7797 - val_acc: 0.1840\n",
            "Epoch 53/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8293 - acc: 0.1714 - val_loss: 2.7682 - val_acc: 0.2025\n",
            "Epoch 54/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8427 - acc: 0.1703 - val_loss: 2.7885 - val_acc: 0.1595\n",
            "Epoch 55/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8174 - acc: 0.1627 - val_loss: 2.7779 - val_acc: 0.1963\n",
            "Epoch 56/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8476 - acc: 0.1627 - val_loss: 2.7837 - val_acc: 0.1779\n",
            "Epoch 57/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8434 - acc: 0.1638 - val_loss: 2.7921 - val_acc: 0.1779\n",
            "Epoch 58/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.8239 - acc: 0.1638 - val_loss: 2.7724 - val_acc: 0.1963\n",
            "Epoch 59/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.8443 - acc: 0.1627 - val_loss: 2.7769 - val_acc: 0.1779\n",
            "Epoch 60/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.8116 - acc: 0.1518 - val_loss: 2.7661 - val_acc: 0.1963\n",
            "Epoch 61/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8387 - acc: 0.1822 - val_loss: 2.7729 - val_acc: 0.1779\n",
            "Epoch 62/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8223 - acc: 0.1649 - val_loss: 2.7663 - val_acc: 0.1779\n",
            "Epoch 63/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.8597 - acc: 0.1692 - val_loss: 2.7730 - val_acc: 0.1656\n",
            "Epoch 64/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7877 - acc: 0.1616 - val_loss: 2.7469 - val_acc: 0.2086\n",
            "Epoch 65/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8295 - acc: 0.1649 - val_loss: 2.7706 - val_acc: 0.1840\n",
            "Epoch 66/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8144 - acc: 0.1790 - val_loss: 2.7472 - val_acc: 0.2086\n",
            "Epoch 67/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8095 - acc: 0.1573 - val_loss: 2.7532 - val_acc: 0.2025\n",
            "Epoch 68/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7784 - acc: 0.1790 - val_loss: 2.7351 - val_acc: 0.2086\n",
            "Epoch 69/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8184 - acc: 0.1757 - val_loss: 2.7630 - val_acc: 0.2025\n",
            "Epoch 70/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7844 - acc: 0.1822 - val_loss: 2.7419 - val_acc: 0.2147\n",
            "Epoch 71/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.8184 - acc: 0.1779 - val_loss: 2.7343 - val_acc: 0.2025\n",
            "Epoch 72/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8041 - acc: 0.1692 - val_loss: 2.7221 - val_acc: 0.2454\n",
            "Epoch 73/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.7960 - acc: 0.1779 - val_loss: 2.7327 - val_acc: 0.2086\n",
            "Epoch 74/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7594 - acc: 0.1811 - val_loss: 2.7294 - val_acc: 0.2025\n",
            "Epoch 75/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7875 - acc: 0.1681 - val_loss: 2.7276 - val_acc: 0.2025\n",
            "Epoch 76/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7722 - acc: 0.1725 - val_loss: 2.7258 - val_acc: 0.2270\n",
            "Epoch 77/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7451 - acc: 0.1866 - val_loss: 2.7123 - val_acc: 0.2454\n",
            "Epoch 78/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7683 - acc: 0.1735 - val_loss: 2.7223 - val_acc: 0.2270\n",
            "Epoch 79/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7882 - acc: 0.1692 - val_loss: 2.7051 - val_acc: 0.2086\n",
            "Epoch 80/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7414 - acc: 0.1833 - val_loss: 2.7115 - val_acc: 0.2147\n",
            "Epoch 81/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7393 - acc: 0.1800 - val_loss: 2.7003 - val_acc: 0.2147\n",
            "Epoch 82/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7559 - acc: 0.1887 - val_loss: 2.7072 - val_acc: 0.2147\n",
            "Epoch 83/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.7365 - acc: 0.1876 - val_loss: 2.6910 - val_acc: 0.2147\n",
            "Epoch 84/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.7581 - acc: 0.1833 - val_loss: 2.7164 - val_acc: 0.2209\n",
            "Epoch 85/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7460 - acc: 0.1627 - val_loss: 2.6988 - val_acc: 0.2209\n",
            "Epoch 86/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7729 - acc: 0.1876 - val_loss: 2.7111 - val_acc: 0.2270\n",
            "Epoch 87/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7649 - acc: 0.1518 - val_loss: 2.6932 - val_acc: 0.2331\n",
            "Epoch 88/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7397 - acc: 0.1855 - val_loss: 2.6998 - val_acc: 0.2025\n",
            "Epoch 89/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7368 - acc: 0.1822 - val_loss: 2.7001 - val_acc: 0.2147\n",
            "Epoch 90/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7119 - acc: 0.1876 - val_loss: 2.6960 - val_acc: 0.2147\n",
            "Epoch 91/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7546 - acc: 0.1876 - val_loss: 2.6931 - val_acc: 0.2086\n",
            "Epoch 92/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7379 - acc: 0.1833 - val_loss: 2.6873 - val_acc: 0.2209\n",
            "Epoch 93/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7094 - acc: 0.1866 - val_loss: 2.6907 - val_acc: 0.2209\n",
            "Epoch 94/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7203 - acc: 0.1876 - val_loss: 2.6861 - val_acc: 0.2147\n",
            "Epoch 95/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.7307 - acc: 0.1887 - val_loss: 2.6756 - val_acc: 0.2331\n",
            "Epoch 96/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7119 - acc: 0.1746 - val_loss: 2.6782 - val_acc: 0.2270\n",
            "Epoch 97/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7240 - acc: 0.1779 - val_loss: 2.7086 - val_acc: 0.2147\n",
            "Epoch 98/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7558 - acc: 0.1746 - val_loss: 2.6859 - val_acc: 0.2025\n",
            "Epoch 99/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7566 - acc: 0.1757 - val_loss: 2.6834 - val_acc: 0.2209\n",
            "Epoch 100/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7154 - acc: 0.1790 - val_loss: 2.6785 - val_acc: 0.2025\n",
            "Epoch 101/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7135 - acc: 0.1822 - val_loss: 2.6704 - val_acc: 0.2209\n",
            "Epoch 102/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7019 - acc: 0.1627 - val_loss: 2.6657 - val_acc: 0.2147\n",
            "Epoch 103/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6950 - acc: 0.1920 - val_loss: 2.6460 - val_acc: 0.2393\n",
            "Epoch 104/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7210 - acc: 0.1811 - val_loss: 2.6792 - val_acc: 0.2025\n",
            "Epoch 105/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6931 - acc: 0.1844 - val_loss: 2.6656 - val_acc: 0.2209\n",
            "Epoch 106/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.7126 - acc: 0.1876 - val_loss: 2.6619 - val_acc: 0.2147\n",
            "Epoch 107/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6730 - acc: 0.1898 - val_loss: 2.6536 - val_acc: 0.2147\n",
            "Epoch 108/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6764 - acc: 0.1855 - val_loss: 2.6731 - val_acc: 0.2086\n",
            "Epoch 109/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7044 - acc: 0.1844 - val_loss: 2.6586 - val_acc: 0.2086\n",
            "Epoch 110/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6866 - acc: 0.1866 - val_loss: 2.6383 - val_acc: 0.2147\n",
            "Epoch 111/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6767 - acc: 0.1909 - val_loss: 2.6286 - val_acc: 0.2209\n",
            "Epoch 112/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6776 - acc: 0.1963 - val_loss: 2.6466 - val_acc: 0.2270\n",
            "Epoch 113/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7095 - acc: 0.1866 - val_loss: 2.6371 - val_acc: 0.2393\n",
            "Epoch 114/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6889 - acc: 0.1920 - val_loss: 2.6313 - val_acc: 0.2331\n",
            "Epoch 115/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7115 - acc: 0.1833 - val_loss: 2.6444 - val_acc: 0.2270\n",
            "Epoch 116/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6645 - acc: 0.1963 - val_loss: 2.6598 - val_acc: 0.2147\n",
            "Epoch 117/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6568 - acc: 0.1963 - val_loss: 2.6548 - val_acc: 0.2086\n",
            "Epoch 118/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6350 - acc: 0.1952 - val_loss: 2.6425 - val_acc: 0.2270\n",
            "Epoch 119/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6584 - acc: 0.1952 - val_loss: 2.6353 - val_acc: 0.2393\n",
            "Epoch 120/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6886 - acc: 0.1844 - val_loss: 2.6554 - val_acc: 0.2147\n",
            "Epoch 121/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6584 - acc: 0.1887 - val_loss: 2.6436 - val_acc: 0.2393\n",
            "Epoch 122/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6916 - acc: 0.1866 - val_loss: 2.6631 - val_acc: 0.2086\n",
            "Epoch 123/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6636 - acc: 0.1898 - val_loss: 2.6490 - val_acc: 0.2147\n",
            "Epoch 124/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6539 - acc: 0.1963 - val_loss: 2.6307 - val_acc: 0.2331\n",
            "Epoch 125/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6745 - acc: 0.2039 - val_loss: 2.6403 - val_acc: 0.2209\n",
            "Epoch 126/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7115 - acc: 0.1573 - val_loss: 2.6736 - val_acc: 0.2025\n",
            "Epoch 127/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6619 - acc: 0.1866 - val_loss: 2.6411 - val_acc: 0.2147\n",
            "Epoch 128/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6880 - acc: 0.1898 - val_loss: 2.6571 - val_acc: 0.2086\n",
            "Epoch 129/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6428 - acc: 0.1941 - val_loss: 2.6322 - val_acc: 0.2209\n",
            "Epoch 130/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6622 - acc: 0.1866 - val_loss: 2.6523 - val_acc: 0.2086\n",
            "Epoch 131/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6548 - acc: 0.1909 - val_loss: 2.6365 - val_acc: 0.2209\n",
            "Epoch 132/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6857 - acc: 0.1584 - val_loss: 2.6590 - val_acc: 0.2209\n",
            "Epoch 133/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6641 - acc: 0.1866 - val_loss: 2.6438 - val_acc: 0.2147\n",
            "Epoch 134/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6739 - acc: 0.1909 - val_loss: 2.6529 - val_acc: 0.2086\n",
            "Epoch 135/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6595 - acc: 0.1931 - val_loss: 2.6474 - val_acc: 0.2147\n",
            "Epoch 136/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6676 - acc: 0.2039 - val_loss: 2.6682 - val_acc: 0.2209\n",
            "Epoch 137/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6481 - acc: 0.1952 - val_loss: 2.6193 - val_acc: 0.2393\n",
            "Epoch 138/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6607 - acc: 0.1931 - val_loss: 2.6294 - val_acc: 0.2209\n",
            "Epoch 139/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6261 - acc: 0.2007 - val_loss: 2.6540 - val_acc: 0.2147\n",
            "Epoch 140/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6626 - acc: 0.2082 - val_loss: 2.6457 - val_acc: 0.2270\n",
            "Epoch 141/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6534 - acc: 0.1985 - val_loss: 2.6216 - val_acc: 0.2393\n",
            "Epoch 142/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6501 - acc: 0.1887 - val_loss: 2.6349 - val_acc: 0.2147\n",
            "Epoch 143/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6618 - acc: 0.1931 - val_loss: 2.6274 - val_acc: 0.2147\n",
            "Epoch 144/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6183 - acc: 0.2061 - val_loss: 2.6304 - val_acc: 0.2147\n",
            "Epoch 145/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6736 - acc: 0.1974 - val_loss: 2.6498 - val_acc: 0.2209\n",
            "Epoch 146/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6311 - acc: 0.2061 - val_loss: 2.6286 - val_acc: 0.2209\n",
            "Epoch 147/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6257 - acc: 0.2039 - val_loss: 2.6132 - val_acc: 0.2270\n",
            "Epoch 148/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6243 - acc: 0.2017 - val_loss: 2.6354 - val_acc: 0.2209\n",
            "Epoch 149/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6493 - acc: 0.1985 - val_loss: 2.6103 - val_acc: 0.2331\n",
            "Epoch 150/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6361 - acc: 0.2028 - val_loss: 2.6280 - val_acc: 0.2209\n",
            "Epoch 151/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6347 - acc: 0.1920 - val_loss: 2.6337 - val_acc: 0.2270\n",
            "Epoch 152/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6230 - acc: 0.2039 - val_loss: 2.6437 - val_acc: 0.2147\n",
            "Epoch 153/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6337 - acc: 0.1833 - val_loss: 2.6128 - val_acc: 0.2393\n",
            "Epoch 154/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6142 - acc: 0.2028 - val_loss: 2.6288 - val_acc: 0.2147\n",
            "Epoch 155/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6528 - acc: 0.1996 - val_loss: 2.5916 - val_acc: 0.2515\n",
            "Epoch 156/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6464 - acc: 0.1920 - val_loss: 2.6265 - val_acc: 0.2209\n",
            "Epoch 157/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6975 - acc: 0.2017 - val_loss: 2.6363 - val_acc: 0.2147\n",
            "Epoch 158/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6635 - acc: 0.1996 - val_loss: 2.6197 - val_acc: 0.2331\n",
            "Epoch 159/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6395 - acc: 0.1909 - val_loss: 2.6283 - val_acc: 0.2086\n",
            "Epoch 160/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6229 - acc: 0.1920 - val_loss: 2.6059 - val_acc: 0.2209\n",
            "Epoch 161/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6202 - acc: 0.2072 - val_loss: 2.6248 - val_acc: 0.2393\n",
            "Epoch 162/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6386 - acc: 0.1963 - val_loss: 2.6143 - val_acc: 0.2147\n",
            "Epoch 163/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6032 - acc: 0.2104 - val_loss: 2.5833 - val_acc: 0.2515\n",
            "Epoch 164/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6198 - acc: 0.2104 - val_loss: 2.6327 - val_acc: 0.2331\n",
            "Epoch 165/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6294 - acc: 0.2072 - val_loss: 2.6093 - val_acc: 0.2331\n",
            "Epoch 166/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6438 - acc: 0.1909 - val_loss: 2.6211 - val_acc: 0.2270\n",
            "Epoch 167/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6296 - acc: 0.2050 - val_loss: 2.5979 - val_acc: 0.2209\n",
            "Epoch 168/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6151 - acc: 0.1996 - val_loss: 2.6057 - val_acc: 0.2331\n",
            "Epoch 169/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6023 - acc: 0.2072 - val_loss: 2.5940 - val_acc: 0.2270\n",
            "Epoch 170/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6109 - acc: 0.2028 - val_loss: 2.5933 - val_acc: 0.2270\n",
            "Epoch 171/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6163 - acc: 0.1974 - val_loss: 2.5759 - val_acc: 0.2270\n",
            "Epoch 172/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6020 - acc: 0.2093 - val_loss: 2.5808 - val_acc: 0.2209\n",
            "Epoch 173/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6128 - acc: 0.1909 - val_loss: 2.6275 - val_acc: 0.2270\n",
            "Epoch 174/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6774 - acc: 0.1963 - val_loss: 2.5946 - val_acc: 0.2454\n",
            "Epoch 175/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6168 - acc: 0.2007 - val_loss: 2.5864 - val_acc: 0.2270\n",
            "Epoch 176/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6005 - acc: 0.2104 - val_loss: 2.5772 - val_acc: 0.2515\n",
            "Epoch 177/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6043 - acc: 0.2028 - val_loss: 2.5883 - val_acc: 0.2393\n",
            "Epoch 178/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.6114 - acc: 0.1931 - val_loss: 2.5870 - val_acc: 0.2515\n",
            "Epoch 179/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6085 - acc: 0.2093 - val_loss: 2.6045 - val_acc: 0.2331\n",
            "Epoch 180/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6226 - acc: 0.1963 - val_loss: 2.6005 - val_acc: 0.2454\n",
            "Epoch 181/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6170 - acc: 0.2028 - val_loss: 2.5971 - val_acc: 0.2209\n",
            "Epoch 182/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6365 - acc: 0.1952 - val_loss: 2.6207 - val_acc: 0.2147\n",
            "Epoch 183/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6281 - acc: 0.2007 - val_loss: 2.5919 - val_acc: 0.2270\n",
            "Epoch 184/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6719 - acc: 0.1996 - val_loss: 2.5855 - val_acc: 0.2270\n",
            "Epoch 185/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6331 - acc: 0.1931 - val_loss: 2.5919 - val_acc: 0.2270\n",
            "Epoch 186/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6247 - acc: 0.1920 - val_loss: 2.5705 - val_acc: 0.2270\n",
            "Epoch 187/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6015 - acc: 0.1985 - val_loss: 2.5935 - val_acc: 0.2270\n",
            "Epoch 188/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6157 - acc: 0.2061 - val_loss: 2.5826 - val_acc: 0.2270\n",
            "Epoch 189/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5963 - acc: 0.1963 - val_loss: 2.5745 - val_acc: 0.2209\n",
            "Epoch 190/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5889 - acc: 0.2126 - val_loss: 2.5415 - val_acc: 0.2638\n",
            "Epoch 191/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5969 - acc: 0.2180 - val_loss: 2.6073 - val_acc: 0.2331\n",
            "Epoch 192/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6003 - acc: 0.2093 - val_loss: 2.5890 - val_acc: 0.2515\n",
            "Epoch 193/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6180 - acc: 0.1963 - val_loss: 2.5876 - val_acc: 0.2331\n",
            "Epoch 194/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6254 - acc: 0.1941 - val_loss: 2.5774 - val_acc: 0.2454\n",
            "Epoch 195/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6146 - acc: 0.1941 - val_loss: 2.5867 - val_acc: 0.2270\n",
            "Epoch 196/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6017 - acc: 0.2017 - val_loss: 2.5915 - val_acc: 0.2454\n",
            "Epoch 197/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5932 - acc: 0.2169 - val_loss: 2.5628 - val_acc: 0.2393\n",
            "Epoch 198/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5890 - acc: 0.2072 - val_loss: 2.5521 - val_acc: 0.2577\n",
            "Epoch 199/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5959 - acc: 0.1974 - val_loss: 2.5842 - val_acc: 0.2331\n",
            "Epoch 200/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6224 - acc: 0.2007 - val_loss: 2.5655 - val_acc: 0.2577\n",
            "Epoch 201/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5972 - acc: 0.2093 - val_loss: 2.5785 - val_acc: 0.2393\n",
            "Epoch 202/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5826 - acc: 0.2017 - val_loss: 2.5773 - val_acc: 0.2393\n",
            "Epoch 203/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6121 - acc: 0.2028 - val_loss: 2.5722 - val_acc: 0.2393\n",
            "Epoch 204/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5946 - acc: 0.2115 - val_loss: 2.5637 - val_acc: 0.2331\n",
            "Epoch 205/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6104 - acc: 0.2061 - val_loss: 2.5579 - val_acc: 0.2331\n",
            "Epoch 206/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6050 - acc: 0.2007 - val_loss: 2.5578 - val_acc: 0.2331\n",
            "Epoch 207/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6037 - acc: 0.2072 - val_loss: 2.5827 - val_acc: 0.2454\n",
            "Epoch 208/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5834 - acc: 0.2082 - val_loss: 2.5684 - val_acc: 0.2331\n",
            "Epoch 209/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5797 - acc: 0.2072 - val_loss: 2.5565 - val_acc: 0.2515\n",
            "Epoch 210/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6059 - acc: 0.1996 - val_loss: 2.5883 - val_acc: 0.2270\n",
            "Epoch 211/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6400 - acc: 0.1941 - val_loss: 2.5416 - val_acc: 0.2577\n",
            "Epoch 212/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6082 - acc: 0.2017 - val_loss: 2.5950 - val_acc: 0.2331\n",
            "Epoch 213/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5928 - acc: 0.2148 - val_loss: 2.5330 - val_acc: 0.2331\n",
            "Epoch 214/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5655 - acc: 0.2072 - val_loss: 2.5919 - val_acc: 0.2393\n",
            "Epoch 215/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5857 - acc: 0.2115 - val_loss: 2.5382 - val_acc: 0.2515\n",
            "Epoch 216/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6056 - acc: 0.2158 - val_loss: 2.6109 - val_acc: 0.2331\n",
            "Epoch 217/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5902 - acc: 0.2050 - val_loss: 2.5611 - val_acc: 0.2209\n",
            "Epoch 218/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5715 - acc: 0.2061 - val_loss: 2.5566 - val_acc: 0.2331\n",
            "Epoch 219/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5582 - acc: 0.2072 - val_loss: 2.5587 - val_acc: 0.2331\n",
            "Epoch 220/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6032 - acc: 0.1985 - val_loss: 2.5613 - val_acc: 0.2515\n",
            "Epoch 221/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5681 - acc: 0.2072 - val_loss: 2.5568 - val_acc: 0.2393\n",
            "Epoch 222/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5632 - acc: 0.2148 - val_loss: 2.5486 - val_acc: 0.2393\n",
            "Epoch 223/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6002 - acc: 0.2082 - val_loss: 2.5841 - val_acc: 0.2515\n",
            "Epoch 224/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5911 - acc: 0.2061 - val_loss: 2.5380 - val_acc: 0.2515\n",
            "Epoch 225/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5807 - acc: 0.2104 - val_loss: 2.5652 - val_acc: 0.2515\n",
            "Epoch 226/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6356 - acc: 0.1985 - val_loss: 2.5932 - val_acc: 0.2393\n",
            "Epoch 227/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5757 - acc: 0.2137 - val_loss: 2.5511 - val_acc: 0.2454\n",
            "Epoch 228/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6148 - acc: 0.1985 - val_loss: 2.5832 - val_acc: 0.2270\n",
            "Epoch 229/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5877 - acc: 0.1985 - val_loss: 2.5391 - val_acc: 0.2577\n",
            "Epoch 230/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5971 - acc: 0.2050 - val_loss: 2.5044 - val_acc: 0.2454\n",
            "Epoch 231/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5680 - acc: 0.2148 - val_loss: 2.5661 - val_acc: 0.2393\n",
            "Epoch 232/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5834 - acc: 0.2115 - val_loss: 2.5638 - val_acc: 0.2331\n",
            "Epoch 233/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5574 - acc: 0.2072 - val_loss: 2.6721 - val_acc: 0.2331\n",
            "Epoch 234/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6046 - acc: 0.2115 - val_loss: 2.5567 - val_acc: 0.2393\n",
            "Epoch 235/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5612 - acc: 0.2072 - val_loss: 2.5401 - val_acc: 0.2270\n",
            "Epoch 236/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6140 - acc: 0.2039 - val_loss: 2.5640 - val_acc: 0.2393\n",
            "Epoch 237/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6082 - acc: 0.2082 - val_loss: 2.5987 - val_acc: 0.2577\n",
            "Epoch 238/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5603 - acc: 0.2180 - val_loss: 2.5675 - val_acc: 0.2454\n",
            "Epoch 239/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5658 - acc: 0.2017 - val_loss: 2.5050 - val_acc: 0.2577\n",
            "Epoch 240/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5768 - acc: 0.2213 - val_loss: 2.5732 - val_acc: 0.2270\n",
            "Epoch 241/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5679 - acc: 0.1920 - val_loss: 2.5131 - val_acc: 0.2454\n",
            "Epoch 242/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5822 - acc: 0.2050 - val_loss: 2.5781 - val_acc: 0.2393\n",
            "Epoch 243/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5713 - acc: 0.2137 - val_loss: 2.5503 - val_acc: 0.2331\n",
            "Epoch 244/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5734 - acc: 0.2148 - val_loss: 2.5232 - val_acc: 0.2638\n",
            "Epoch 245/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5835 - acc: 0.2007 - val_loss: 2.5924 - val_acc: 0.2393\n",
            "Epoch 246/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5585 - acc: 0.2148 - val_loss: 2.5361 - val_acc: 0.2577\n",
            "Epoch 247/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6136 - acc: 0.2007 - val_loss: 2.5450 - val_acc: 0.2638\n",
            "Epoch 248/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6222 - acc: 0.2007 - val_loss: 2.5827 - val_acc: 0.2331\n",
            "Epoch 249/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5794 - acc: 0.1974 - val_loss: 2.5663 - val_acc: 0.2454\n",
            "Epoch 250/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5753 - acc: 0.2223 - val_loss: 2.5544 - val_acc: 0.2270\n",
            "Epoch 251/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5696 - acc: 0.2115 - val_loss: 2.5650 - val_acc: 0.2393\n",
            "Epoch 252/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5839 - acc: 0.2007 - val_loss: 2.5417 - val_acc: 0.2515\n",
            "Epoch 253/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6078 - acc: 0.2202 - val_loss: 2.5525 - val_acc: 0.2331\n",
            "Epoch 254/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5650 - acc: 0.2148 - val_loss: 2.5611 - val_acc: 0.2270\n",
            "Epoch 255/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5654 - acc: 0.2093 - val_loss: 2.5767 - val_acc: 0.2209\n",
            "Epoch 256/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5504 - acc: 0.2180 - val_loss: 2.5388 - val_acc: 0.2393\n",
            "Epoch 257/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5794 - acc: 0.2148 - val_loss: 2.5433 - val_acc: 0.2270\n",
            "Epoch 258/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5535 - acc: 0.2028 - val_loss: 2.5280 - val_acc: 0.2393\n",
            "Epoch 259/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5635 - acc: 0.2061 - val_loss: 2.5404 - val_acc: 0.2331\n",
            "Epoch 260/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5835 - acc: 0.2104 - val_loss: 2.5601 - val_acc: 0.2331\n",
            "Epoch 261/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5763 - acc: 0.2082 - val_loss: 2.4920 - val_acc: 0.2638\n",
            "Epoch 262/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5645 - acc: 0.2137 - val_loss: 2.5254 - val_acc: 0.2454\n",
            "Epoch 263/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5685 - acc: 0.2082 - val_loss: 2.5963 - val_acc: 0.2393\n",
            "Epoch 264/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5871 - acc: 0.2137 - val_loss: 2.5040 - val_acc: 0.2638\n",
            "Epoch 265/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5814 - acc: 0.2007 - val_loss: 2.5603 - val_acc: 0.2393\n",
            "Epoch 266/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5760 - acc: 0.2082 - val_loss: 2.5550 - val_acc: 0.2270\n",
            "Epoch 267/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5571 - acc: 0.2072 - val_loss: 2.5402 - val_acc: 0.2331\n",
            "Epoch 268/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5740 - acc: 0.2050 - val_loss: 2.5482 - val_acc: 0.2454\n",
            "Epoch 269/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5508 - acc: 0.2093 - val_loss: 2.5417 - val_acc: 0.2393\n",
            "Epoch 270/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5481 - acc: 0.2072 - val_loss: 2.5215 - val_acc: 0.2393\n",
            "Epoch 271/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5339 - acc: 0.2126 - val_loss: 2.5298 - val_acc: 0.2331\n",
            "Epoch 272/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5587 - acc: 0.2126 - val_loss: 2.5215 - val_acc: 0.2270\n",
            "Epoch 273/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5727 - acc: 0.2137 - val_loss: 2.5002 - val_acc: 0.2515\n",
            "Epoch 274/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5599 - acc: 0.2039 - val_loss: 2.5821 - val_acc: 0.2209\n",
            "Epoch 275/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5659 - acc: 0.2050 - val_loss: 2.5376 - val_acc: 0.2454\n",
            "Epoch 276/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5232 - acc: 0.2278 - val_loss: 2.5540 - val_acc: 0.2331\n",
            "Epoch 277/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5480 - acc: 0.2223 - val_loss: 2.5175 - val_acc: 0.2331\n",
            "Epoch 278/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5661 - acc: 0.2050 - val_loss: 2.5574 - val_acc: 0.2270\n",
            "Epoch 279/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5783 - acc: 0.2039 - val_loss: 2.5556 - val_acc: 0.2209\n",
            "Epoch 280/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5447 - acc: 0.2082 - val_loss: 2.5392 - val_acc: 0.2270\n",
            "Epoch 281/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5682 - acc: 0.2039 - val_loss: 2.5554 - val_acc: 0.2331\n",
            "Epoch 282/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5563 - acc: 0.2082 - val_loss: 2.5118 - val_acc: 0.2454\n",
            "Epoch 283/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5256 - acc: 0.2202 - val_loss: 2.5751 - val_acc: 0.2331\n",
            "Epoch 284/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5582 - acc: 0.2148 - val_loss: 2.5034 - val_acc: 0.2393\n",
            "Epoch 285/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5505 - acc: 0.2169 - val_loss: 2.5399 - val_acc: 0.2393\n",
            "Epoch 286/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5584 - acc: 0.2234 - val_loss: 2.5366 - val_acc: 0.2515\n",
            "Epoch 287/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5586 - acc: 0.2202 - val_loss: 2.5473 - val_acc: 0.2331\n",
            "Epoch 288/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5603 - acc: 0.2148 - val_loss: 2.5302 - val_acc: 0.2393\n",
            "Epoch 289/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5731 - acc: 0.2223 - val_loss: 2.5677 - val_acc: 0.2331\n",
            "Epoch 290/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5347 - acc: 0.2126 - val_loss: 2.5072 - val_acc: 0.2454\n",
            "Epoch 291/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5649 - acc: 0.2148 - val_loss: 2.5365 - val_acc: 0.2577\n",
            "Epoch 292/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5687 - acc: 0.2093 - val_loss: 2.5122 - val_acc: 0.2393\n",
            "Epoch 293/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5571 - acc: 0.2072 - val_loss: 2.5340 - val_acc: 0.2393\n",
            "Epoch 294/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5286 - acc: 0.2299 - val_loss: 2.5181 - val_acc: 0.2393\n",
            "Epoch 295/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5713 - acc: 0.2061 - val_loss: 2.5181 - val_acc: 0.2454\n",
            "Epoch 296/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5508 - acc: 0.2213 - val_loss: 2.4935 - val_acc: 0.2577\n",
            "Epoch 297/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5351 - acc: 0.2180 - val_loss: 2.5231 - val_acc: 0.2515\n",
            "Epoch 298/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5388 - acc: 0.2104 - val_loss: 2.5335 - val_acc: 0.2393\n",
            "Epoch 299/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5332 - acc: 0.2148 - val_loss: 2.4796 - val_acc: 0.2883\n",
            "Epoch 300/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5511 - acc: 0.2115 - val_loss: 2.5969 - val_acc: 0.2331\n",
            "Epoch 301/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.5304 - acc: 0.2148 - val_loss: 2.4918 - val_acc: 0.2393\n",
            "Epoch 302/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.5306 - acc: 0.2137 - val_loss: 2.5500 - val_acc: 0.2331\n",
            "Epoch 303/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.5838 - acc: 0.2061 - val_loss: 2.5336 - val_acc: 0.2270\n",
            "Epoch 304/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5879 - acc: 0.2017 - val_loss: 2.5373 - val_acc: 0.2393\n",
            "Epoch 305/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5332 - acc: 0.2158 - val_loss: 2.4971 - val_acc: 0.2577\n",
            "Epoch 306/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5292 - acc: 0.2223 - val_loss: 2.5309 - val_acc: 0.2270\n",
            "Epoch 307/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5251 - acc: 0.2191 - val_loss: 2.4906 - val_acc: 0.2515\n",
            "Epoch 308/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5129 - acc: 0.2202 - val_loss: 2.4964 - val_acc: 0.2638\n",
            "Epoch 309/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5414 - acc: 0.2245 - val_loss: 2.5380 - val_acc: 0.2331\n",
            "Epoch 310/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5437 - acc: 0.2256 - val_loss: 2.5204 - val_acc: 0.2270\n",
            "Epoch 311/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5370 - acc: 0.2072 - val_loss: 2.5681 - val_acc: 0.2209\n",
            "Epoch 312/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5738 - acc: 0.2028 - val_loss: 2.5277 - val_acc: 0.2270\n",
            "Epoch 313/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5610 - acc: 0.2061 - val_loss: 2.5105 - val_acc: 0.2393\n",
            "Epoch 314/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.5556 - acc: 0.2169 - val_loss: 2.5180 - val_acc: 0.2331\n",
            "Epoch 315/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5569 - acc: 0.2180 - val_loss: 2.5358 - val_acc: 0.2331\n",
            "Epoch 316/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5543 - acc: 0.2158 - val_loss: 2.4948 - val_acc: 0.2577\n",
            "Epoch 317/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5302 - acc: 0.2202 - val_loss: 2.5298 - val_acc: 0.2577\n",
            "Epoch 318/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5533 - acc: 0.2158 - val_loss: 2.5240 - val_acc: 0.2331\n",
            "Epoch 319/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5736 - acc: 0.2115 - val_loss: 2.5402 - val_acc: 0.2393\n",
            "Epoch 320/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5228 - acc: 0.2169 - val_loss: 2.4767 - val_acc: 0.2577\n",
            "Epoch 321/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5788 - acc: 0.2234 - val_loss: 2.5171 - val_acc: 0.2577\n",
            "Epoch 322/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5334 - acc: 0.2148 - val_loss: 2.5197 - val_acc: 0.2393\n",
            "Epoch 323/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.6065 - acc: 0.2137 - val_loss: 2.5460 - val_acc: 0.2331\n",
            "Epoch 324/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5898 - acc: 0.2278 - val_loss: 2.4890 - val_acc: 0.2638\n",
            "Epoch 325/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5822 - acc: 0.2126 - val_loss: 2.5936 - val_acc: 0.1963\n",
            "Epoch 326/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5315 - acc: 0.2180 - val_loss: 2.5499 - val_acc: 0.2209\n",
            "Epoch 327/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5645 - acc: 0.2050 - val_loss: 2.4736 - val_acc: 0.2761\n",
            "Epoch 328/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5746 - acc: 0.2137 - val_loss: 2.6080 - val_acc: 0.2270\n",
            "Epoch 329/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5796 - acc: 0.2082 - val_loss: 2.5358 - val_acc: 0.2331\n",
            "Epoch 330/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5627 - acc: 0.2115 - val_loss: 2.6076 - val_acc: 0.2270\n",
            "Epoch 331/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5978 - acc: 0.2093 - val_loss: 2.4899 - val_acc: 0.2883\n",
            "Epoch 332/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5449 - acc: 0.2245 - val_loss: 2.5224 - val_acc: 0.2515\n",
            "Epoch 333/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5393 - acc: 0.2321 - val_loss: 2.5019 - val_acc: 0.2454\n",
            "Epoch 334/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4947 - acc: 0.2267 - val_loss: 2.4742 - val_acc: 0.2699\n",
            "Epoch 335/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5385 - acc: 0.2289 - val_loss: 2.4730 - val_acc: 0.2699\n",
            "Epoch 336/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5288 - acc: 0.2213 - val_loss: 2.5398 - val_acc: 0.2209\n",
            "Epoch 337/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5354 - acc: 0.2072 - val_loss: 2.4972 - val_acc: 0.2577\n",
            "Epoch 338/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5135 - acc: 0.2397 - val_loss: 2.4937 - val_acc: 0.2393\n",
            "Epoch 339/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5096 - acc: 0.2191 - val_loss: 2.5202 - val_acc: 0.2209\n",
            "Epoch 340/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5715 - acc: 0.2137 - val_loss: 2.5289 - val_acc: 0.2515\n",
            "Epoch 341/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.5375 - acc: 0.2017 - val_loss: 2.5530 - val_acc: 0.2270\n",
            "Epoch 342/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5427 - acc: 0.2169 - val_loss: 2.5209 - val_acc: 0.2331\n",
            "Epoch 343/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5841 - acc: 0.2148 - val_loss: 2.5787 - val_acc: 0.2270\n",
            "Epoch 344/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5216 - acc: 0.2158 - val_loss: 2.5286 - val_acc: 0.2147\n",
            "Epoch 345/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5320 - acc: 0.2213 - val_loss: 2.4810 - val_acc: 0.2699\n",
            "Epoch 346/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.5596 - acc: 0.2213 - val_loss: 2.5336 - val_acc: 0.2393\n",
            "Epoch 347/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5386 - acc: 0.2267 - val_loss: 2.5045 - val_acc: 0.2331\n",
            "Epoch 348/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5239 - acc: 0.2093 - val_loss: 2.5397 - val_acc: 0.2025\n",
            "Epoch 349/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5227 - acc: 0.2169 - val_loss: 2.5162 - val_acc: 0.2331\n",
            "Epoch 350/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5163 - acc: 0.2213 - val_loss: 2.5192 - val_acc: 0.2270\n",
            "Epoch 351/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4926 - acc: 0.2364 - val_loss: 2.4805 - val_acc: 0.2577\n",
            "Epoch 352/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4932 - acc: 0.2256 - val_loss: 2.5019 - val_acc: 0.2209\n",
            "Epoch 353/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5085 - acc: 0.2299 - val_loss: 2.4953 - val_acc: 0.2699\n",
            "Epoch 354/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5027 - acc: 0.2354 - val_loss: 2.4766 - val_acc: 0.2638\n",
            "Epoch 355/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5188 - acc: 0.2473 - val_loss: 2.4685 - val_acc: 0.2577\n",
            "Epoch 356/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4808 - acc: 0.2581 - val_loss: 2.4627 - val_acc: 0.2331\n",
            "Epoch 357/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4782 - acc: 0.2516 - val_loss: 2.5008 - val_acc: 0.2147\n",
            "Epoch 358/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5140 - acc: 0.2299 - val_loss: 2.4974 - val_acc: 0.2393\n",
            "Epoch 359/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5170 - acc: 0.2332 - val_loss: 2.4926 - val_acc: 0.2086\n",
            "Epoch 360/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4889 - acc: 0.2289 - val_loss: 2.4884 - val_acc: 0.2577\n",
            "Epoch 361/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5078 - acc: 0.2354 - val_loss: 2.4914 - val_acc: 0.2209\n",
            "Epoch 362/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5059 - acc: 0.2354 - val_loss: 2.4531 - val_acc: 0.2638\n",
            "Epoch 363/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4749 - acc: 0.2343 - val_loss: 2.4588 - val_acc: 0.2577\n",
            "Epoch 364/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4873 - acc: 0.2484 - val_loss: 2.4546 - val_acc: 0.2699\n",
            "Epoch 365/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4918 - acc: 0.2354 - val_loss: 2.4506 - val_acc: 0.2393\n",
            "Epoch 366/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4721 - acc: 0.2440 - val_loss: 2.4866 - val_acc: 0.2147\n",
            "Epoch 367/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5048 - acc: 0.2137 - val_loss: 2.4355 - val_acc: 0.2577\n",
            "Epoch 368/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5099 - acc: 0.2386 - val_loss: 2.4921 - val_acc: 0.2331\n",
            "Epoch 369/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4927 - acc: 0.2321 - val_loss: 2.4743 - val_acc: 0.2331\n",
            "Epoch 370/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4986 - acc: 0.2213 - val_loss: 2.4543 - val_acc: 0.2577\n",
            "Epoch 371/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4902 - acc: 0.2419 - val_loss: 2.4401 - val_acc: 0.2515\n",
            "Epoch 372/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4750 - acc: 0.2495 - val_loss: 2.5183 - val_acc: 0.2209\n",
            "Epoch 373/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4921 - acc: 0.2354 - val_loss: 2.4785 - val_acc: 0.2331\n",
            "Epoch 374/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4873 - acc: 0.2256 - val_loss: 2.5189 - val_acc: 0.2331\n",
            "Epoch 375/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5251 - acc: 0.2202 - val_loss: 2.5031 - val_acc: 0.2209\n",
            "Epoch 376/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5104 - acc: 0.2289 - val_loss: 2.4698 - val_acc: 0.2393\n",
            "Epoch 377/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4671 - acc: 0.2484 - val_loss: 2.4570 - val_acc: 0.2209\n",
            "Epoch 378/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4459 - acc: 0.2560 - val_loss: 2.4559 - val_acc: 0.2270\n",
            "Epoch 379/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4467 - acc: 0.2343 - val_loss: 2.4385 - val_acc: 0.2393\n",
            "Epoch 380/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.4606 - acc: 0.2343 - val_loss: 2.4528 - val_acc: 0.2331\n",
            "Epoch 381/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4781 - acc: 0.2375 - val_loss: 2.4217 - val_acc: 0.2577\n",
            "Epoch 382/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4913 - acc: 0.2375 - val_loss: 2.5314 - val_acc: 0.2086\n",
            "Epoch 383/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4797 - acc: 0.2397 - val_loss: 2.4602 - val_acc: 0.2761\n",
            "Epoch 384/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4823 - acc: 0.2169 - val_loss: 2.4810 - val_acc: 0.2393\n",
            "Epoch 385/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4732 - acc: 0.2451 - val_loss: 2.4699 - val_acc: 0.2577\n",
            "Epoch 386/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4666 - acc: 0.2473 - val_loss: 2.4777 - val_acc: 0.2270\n",
            "Epoch 387/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4735 - acc: 0.2419 - val_loss: 2.4464 - val_acc: 0.2454\n",
            "Epoch 388/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4390 - acc: 0.2473 - val_loss: 2.4649 - val_acc: 0.2209\n",
            "Epoch 389/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4385 - acc: 0.2451 - val_loss: 2.4514 - val_acc: 0.2270\n",
            "Epoch 390/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4267 - acc: 0.2462 - val_loss: 2.4337 - val_acc: 0.2454\n",
            "Epoch 391/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4390 - acc: 0.2408 - val_loss: 2.4345 - val_acc: 0.2331\n",
            "Epoch 392/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4894 - acc: 0.2321 - val_loss: 2.4677 - val_acc: 0.2515\n",
            "Epoch 393/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4709 - acc: 0.2386 - val_loss: 2.4841 - val_acc: 0.2331\n",
            "Epoch 394/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4440 - acc: 0.2343 - val_loss: 2.4587 - val_acc: 0.2393\n",
            "Epoch 395/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4416 - acc: 0.2505 - val_loss: 2.4425 - val_acc: 0.2515\n",
            "Epoch 396/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.4240 - acc: 0.2462 - val_loss: 2.4649 - val_acc: 0.2393\n",
            "Epoch 397/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4368 - acc: 0.2495 - val_loss: 2.4385 - val_acc: 0.2515\n",
            "Epoch 398/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4471 - acc: 0.2495 - val_loss: 2.4885 - val_acc: 0.2331\n",
            "Epoch 399/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4397 - acc: 0.2364 - val_loss: 2.4711 - val_acc: 0.2086\n",
            "Epoch 400/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4238 - acc: 0.2560 - val_loss: 2.4334 - val_acc: 0.2331\n",
            "Epoch 401/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3999 - acc: 0.2625 - val_loss: 2.4173 - val_acc: 0.2515\n",
            "Epoch 402/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4020 - acc: 0.2570 - val_loss: 2.3955 - val_acc: 0.2515\n",
            "Epoch 403/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3955 - acc: 0.2495 - val_loss: 2.4261 - val_acc: 0.2699\n",
            "Epoch 404/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4351 - acc: 0.2603 - val_loss: 2.4539 - val_acc: 0.2331\n",
            "Epoch 405/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4149 - acc: 0.2549 - val_loss: 2.4371 - val_acc: 0.2270\n",
            "Epoch 406/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4217 - acc: 0.2495 - val_loss: 2.3851 - val_acc: 0.2515\n",
            "Epoch 407/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4093 - acc: 0.2581 - val_loss: 2.4004 - val_acc: 0.2699\n",
            "Epoch 408/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4249 - acc: 0.2560 - val_loss: 2.4211 - val_acc: 0.2577\n",
            "Epoch 409/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5373 - acc: 0.2310 - val_loss: 2.5745 - val_acc: 0.2147\n",
            "Epoch 410/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5486 - acc: 0.2289 - val_loss: 2.4848 - val_acc: 0.2454\n",
            "Epoch 411/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4694 - acc: 0.2343 - val_loss: 2.4090 - val_acc: 0.2883\n",
            "Epoch 412/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5164 - acc: 0.2527 - val_loss: 2.4146 - val_acc: 0.2454\n",
            "Epoch 413/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4424 - acc: 0.2603 - val_loss: 2.4516 - val_acc: 0.2699\n",
            "Epoch 414/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4628 - acc: 0.2093 - val_loss: 2.4730 - val_acc: 0.2025\n",
            "Epoch 415/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4252 - acc: 0.2419 - val_loss: 2.4564 - val_acc: 0.2515\n",
            "Epoch 416/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4183 - acc: 0.2495 - val_loss: 2.3980 - val_acc: 0.2761\n",
            "Epoch 417/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4426 - acc: 0.2560 - val_loss: 2.4786 - val_acc: 0.2454\n",
            "Epoch 418/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4218 - acc: 0.2581 - val_loss: 2.4172 - val_acc: 0.2638\n",
            "Epoch 419/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4333 - acc: 0.2657 - val_loss: 2.4350 - val_acc: 0.2515\n",
            "Epoch 420/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4155 - acc: 0.2473 - val_loss: 2.4297 - val_acc: 0.2209\n",
            "Epoch 421/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.3935 - acc: 0.2581 - val_loss: 2.4179 - val_acc: 0.2454\n",
            "Epoch 422/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.3897 - acc: 0.2538 - val_loss: 2.4181 - val_acc: 0.2638\n",
            "Epoch 423/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.3904 - acc: 0.2614 - val_loss: 2.3917 - val_acc: 0.2515\n",
            "Epoch 424/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4129 - acc: 0.2581 - val_loss: 2.3750 - val_acc: 0.2699\n",
            "Epoch 425/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4116 - acc: 0.2733 - val_loss: 2.4285 - val_acc: 0.2331\n",
            "Epoch 426/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4164 - acc: 0.2484 - val_loss: 2.3966 - val_acc: 0.2699\n",
            "Epoch 427/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.3767 - acc: 0.2570 - val_loss: 2.3830 - val_acc: 0.2393\n",
            "Epoch 428/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3659 - acc: 0.2711 - val_loss: 2.3930 - val_acc: 0.2515\n",
            "Epoch 429/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3738 - acc: 0.2690 - val_loss: 2.3797 - val_acc: 0.2515\n",
            "Epoch 430/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4014 - acc: 0.2646 - val_loss: 2.3548 - val_acc: 0.2822\n",
            "Epoch 431/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.3996 - acc: 0.2538 - val_loss: 2.4045 - val_acc: 0.2577\n",
            "Epoch 432/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.3994 - acc: 0.2625 - val_loss: 2.4388 - val_acc: 0.2270\n",
            "Epoch 433/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3477 - acc: 0.2592 - val_loss: 2.4425 - val_acc: 0.2270\n",
            "Epoch 434/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3968 - acc: 0.2451 - val_loss: 2.3848 - val_acc: 0.2454\n",
            "Epoch 435/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3666 - acc: 0.2733 - val_loss: 2.4103 - val_acc: 0.2515\n",
            "Epoch 436/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.3822 - acc: 0.2386 - val_loss: 2.4101 - val_acc: 0.2393\n",
            "Epoch 437/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.3613 - acc: 0.2733 - val_loss: 2.4196 - val_acc: 0.2393\n",
            "Epoch 438/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3652 - acc: 0.2603 - val_loss: 2.3399 - val_acc: 0.2515\n",
            "Epoch 439/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3597 - acc: 0.2668 - val_loss: 2.3230 - val_acc: 0.2761\n",
            "Epoch 440/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.3890 - acc: 0.2495 - val_loss: 2.4263 - val_acc: 0.2209\n",
            "Epoch 441/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3794 - acc: 0.2668 - val_loss: 2.3935 - val_acc: 0.2638\n",
            "Epoch 442/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.3537 - acc: 0.2668 - val_loss: 2.4031 - val_acc: 0.2638\n",
            "Epoch 443/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4104 - acc: 0.2581 - val_loss: 2.5341 - val_acc: 0.1840\n",
            "Epoch 444/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4389 - acc: 0.2538 - val_loss: 2.3654 - val_acc: 0.2761\n",
            "Epoch 445/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4204 - acc: 0.2679 - val_loss: 2.3647 - val_acc: 0.2638\n",
            "Epoch 446/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.3706 - acc: 0.2538 - val_loss: 2.3032 - val_acc: 0.2699\n",
            "Epoch 447/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.3661 - acc: 0.2495 - val_loss: 2.3136 - val_acc: 0.2638\n",
            "Epoch 448/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3724 - acc: 0.2549 - val_loss: 2.3425 - val_acc: 0.2577\n",
            "Epoch 449/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3387 - acc: 0.2874 - val_loss: 2.3778 - val_acc: 0.2393\n",
            "Epoch 450/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3408 - acc: 0.2798 - val_loss: 2.3511 - val_acc: 0.2638\n",
            "Epoch 451/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.3071 - acc: 0.2874 - val_loss: 2.3007 - val_acc: 0.2761\n",
            "Epoch 452/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.3467 - acc: 0.2701 - val_loss: 2.3988 - val_acc: 0.2025\n",
            "Epoch 453/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4412 - acc: 0.2397 - val_loss: 2.3311 - val_acc: 0.2454\n",
            "Epoch 454/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3695 - acc: 0.2505 - val_loss: 2.3872 - val_acc: 0.2638\n",
            "Epoch 455/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3542 - acc: 0.2614 - val_loss: 2.3077 - val_acc: 0.2638\n",
            "Epoch 456/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3412 - acc: 0.2625 - val_loss: 2.2847 - val_acc: 0.2515\n",
            "Epoch 457/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3379 - acc: 0.2744 - val_loss: 2.3180 - val_acc: 0.2577\n",
            "Epoch 458/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.3436 - acc: 0.2744 - val_loss: 2.2832 - val_acc: 0.2883\n",
            "Epoch 459/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.3078 - acc: 0.2852 - val_loss: 2.3091 - val_acc: 0.2822\n",
            "Epoch 460/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3116 - acc: 0.2961 - val_loss: 2.2379 - val_acc: 0.2822\n",
            "Epoch 461/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.3057 - acc: 0.2896 - val_loss: 2.2729 - val_acc: 0.2699\n",
            "Epoch 462/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.3171 - acc: 0.2711 - val_loss: 2.2837 - val_acc: 0.2699\n",
            "Epoch 463/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.2792 - acc: 0.2733 - val_loss: 2.1978 - val_acc: 0.2883\n",
            "Epoch 464/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3100 - acc: 0.2755 - val_loss: 2.2528 - val_acc: 0.2699\n",
            "Epoch 465/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.2816 - acc: 0.2896 - val_loss: 2.1910 - val_acc: 0.2945\n",
            "Epoch 466/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.2782 - acc: 0.2939 - val_loss: 2.2236 - val_acc: 0.3190\n",
            "Epoch 467/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.2924 - acc: 0.3004 - val_loss: 2.1779 - val_acc: 0.3006\n",
            "Epoch 468/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.2338 - acc: 0.3124 - val_loss: 2.1567 - val_acc: 0.3067\n",
            "Epoch 469/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.2321 - acc: 0.2961 - val_loss: 2.1985 - val_acc: 0.3129\n",
            "Epoch 470/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.2511 - acc: 0.3200 - val_loss: 2.1485 - val_acc: 0.3436\n",
            "Epoch 471/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.2027 - acc: 0.3102 - val_loss: 2.0968 - val_acc: 0.3620\n",
            "Epoch 472/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.2364 - acc: 0.2907 - val_loss: 2.1326 - val_acc: 0.3374\n",
            "Epoch 473/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.2113 - acc: 0.3037 - val_loss: 2.1007 - val_acc: 0.3497\n",
            "Epoch 474/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1849 - acc: 0.2950 - val_loss: 2.1084 - val_acc: 0.2822\n",
            "Epoch 475/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.2682 - acc: 0.3037 - val_loss: 2.1258 - val_acc: 0.3252\n",
            "Epoch 476/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.2600 - acc: 0.2852 - val_loss: 2.1050 - val_acc: 0.3374\n",
            "Epoch 477/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.2354 - acc: 0.3026 - val_loss: 2.1363 - val_acc: 0.2945\n",
            "Epoch 478/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1938 - acc: 0.3189 - val_loss: 2.2180 - val_acc: 0.2883\n",
            "Epoch 479/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.2133 - acc: 0.2928 - val_loss: 2.2377 - val_acc: 0.3006\n",
            "Epoch 480/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.2195 - acc: 0.3037 - val_loss: 2.1319 - val_acc: 0.3313\n",
            "Epoch 481/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.2581 - acc: 0.2939 - val_loss: 2.2106 - val_acc: 0.3252\n",
            "Epoch 482/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.2351 - acc: 0.3015 - val_loss: 2.1859 - val_acc: 0.3067\n",
            "Epoch 483/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.1824 - acc: 0.3048 - val_loss: 2.1139 - val_acc: 0.3497\n",
            "Epoch 484/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1794 - acc: 0.3048 - val_loss: 2.0682 - val_acc: 0.3129\n",
            "Epoch 485/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.1924 - acc: 0.2918 - val_loss: 2.0890 - val_acc: 0.3129\n",
            "Epoch 486/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1368 - acc: 0.3189 - val_loss: 2.1262 - val_acc: 0.3129\n",
            "Epoch 487/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1524 - acc: 0.3156 - val_loss: 2.0968 - val_acc: 0.3436\n",
            "Epoch 488/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1625 - acc: 0.3124 - val_loss: 2.0923 - val_acc: 0.2945\n",
            "Epoch 489/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.1742 - acc: 0.2939 - val_loss: 2.0543 - val_acc: 0.3313\n",
            "Epoch 490/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.1352 - acc: 0.3265 - val_loss: 2.0655 - val_acc: 0.3313\n",
            "Epoch 491/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1950 - acc: 0.3015 - val_loss: 2.1182 - val_acc: 0.3190\n",
            "Epoch 492/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1191 - acc: 0.3145 - val_loss: 2.0712 - val_acc: 0.3681\n",
            "Epoch 493/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1455 - acc: 0.3232 - val_loss: 2.1159 - val_acc: 0.3190\n",
            "Epoch 494/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1565 - acc: 0.3254 - val_loss: 2.1313 - val_acc: 0.3558\n",
            "Epoch 495/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1334 - acc: 0.3134 - val_loss: 2.0519 - val_acc: 0.3436\n",
            "Epoch 496/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1338 - acc: 0.3091 - val_loss: 2.0367 - val_acc: 0.3436\n",
            "Epoch 497/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1043 - acc: 0.3341 - val_loss: 2.0988 - val_acc: 0.3374\n",
            "Epoch 498/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0936 - acc: 0.3341 - val_loss: 2.0507 - val_acc: 0.3313\n",
            "Epoch 499/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1046 - acc: 0.3167 - val_loss: 2.1216 - val_acc: 0.3067\n",
            "Epoch 500/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0977 - acc: 0.3243 - val_loss: 2.0834 - val_acc: 0.3436\n",
            "Epoch 501/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0794 - acc: 0.3351 - val_loss: 2.0528 - val_acc: 0.3313\n",
            "Epoch 502/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0645 - acc: 0.3330 - val_loss: 2.0641 - val_acc: 0.3067\n",
            "Epoch 503/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0732 - acc: 0.3275 - val_loss: 2.0079 - val_acc: 0.3374\n",
            "Epoch 504/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0813 - acc: 0.3286 - val_loss: 2.0539 - val_acc: 0.3313\n",
            "Epoch 505/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0400 - acc: 0.3547 - val_loss: 2.0264 - val_acc: 0.3436\n",
            "Epoch 506/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0860 - acc: 0.3124 - val_loss: 2.1598 - val_acc: 0.3190\n",
            "Epoch 507/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1103 - acc: 0.3091 - val_loss: 2.0928 - val_acc: 0.3313\n",
            "Epoch 508/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.0366 - acc: 0.3503 - val_loss: 1.9940 - val_acc: 0.3558\n",
            "Epoch 509/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0832 - acc: 0.3210 - val_loss: 1.9913 - val_acc: 0.3558\n",
            "Epoch 510/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0583 - acc: 0.3373 - val_loss: 2.0182 - val_acc: 0.3374\n",
            "Epoch 511/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0752 - acc: 0.3200 - val_loss: 2.0416 - val_acc: 0.3620\n",
            "Epoch 512/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.1531 - acc: 0.3124 - val_loss: 2.0432 - val_acc: 0.3313\n",
            "Epoch 513/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1091 - acc: 0.3351 - val_loss: 2.1164 - val_acc: 0.3313\n",
            "Epoch 514/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1059 - acc: 0.3254 - val_loss: 2.0624 - val_acc: 0.3252\n",
            "Epoch 515/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0389 - acc: 0.3275 - val_loss: 2.0947 - val_acc: 0.3313\n",
            "Epoch 516/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.0687 - acc: 0.3460 - val_loss: 1.9964 - val_acc: 0.3804\n",
            "Epoch 517/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.1108 - acc: 0.3200 - val_loss: 2.0128 - val_acc: 0.3313\n",
            "Epoch 518/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0990 - acc: 0.2961 - val_loss: 2.0370 - val_acc: 0.3129\n",
            "Epoch 519/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.0455 - acc: 0.3167 - val_loss: 2.0943 - val_acc: 0.3129\n",
            "Epoch 520/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0590 - acc: 0.3286 - val_loss: 2.0732 - val_acc: 0.3252\n",
            "Epoch 521/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0577 - acc: 0.3362 - val_loss: 2.0436 - val_acc: 0.3313\n",
            "Epoch 522/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0926 - acc: 0.3069 - val_loss: 2.0658 - val_acc: 0.3067\n",
            "Epoch 523/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0663 - acc: 0.3449 - val_loss: 2.0533 - val_acc: 0.3190\n",
            "Epoch 524/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1191 - acc: 0.3265 - val_loss: 2.0410 - val_acc: 0.3313\n",
            "Epoch 525/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1608 - acc: 0.3015 - val_loss: 1.9990 - val_acc: 0.3313\n",
            "Epoch 526/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0541 - acc: 0.3351 - val_loss: 2.0303 - val_acc: 0.3497\n",
            "Epoch 527/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0306 - acc: 0.3286 - val_loss: 2.0243 - val_acc: 0.3436\n",
            "Epoch 528/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.0130 - acc: 0.3427 - val_loss: 2.0663 - val_acc: 0.3374\n",
            "Epoch 529/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0232 - acc: 0.3221 - val_loss: 2.1786 - val_acc: 0.3129\n",
            "Epoch 530/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.0651 - acc: 0.3189 - val_loss: 2.0825 - val_acc: 0.3374\n",
            "Epoch 531/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0977 - acc: 0.3134 - val_loss: 2.0332 - val_acc: 0.3313\n",
            "Epoch 532/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0632 - acc: 0.3362 - val_loss: 2.0557 - val_acc: 0.3252\n",
            "Epoch 533/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.0956 - acc: 0.3200 - val_loss: 2.0768 - val_acc: 0.3374\n",
            "Epoch 534/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0776 - acc: 0.3189 - val_loss: 1.9820 - val_acc: 0.3129\n",
            "Epoch 535/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0082 - acc: 0.3200 - val_loss: 1.9840 - val_acc: 0.3436\n",
            "Epoch 536/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9964 - acc: 0.3633 - val_loss: 1.9925 - val_acc: 0.3620\n",
            "Epoch 537/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0096 - acc: 0.3482 - val_loss: 1.9300 - val_acc: 0.3374\n",
            "Epoch 538/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0024 - acc: 0.3514 - val_loss: 2.0901 - val_acc: 0.3190\n",
            "Epoch 539/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0373 - acc: 0.3416 - val_loss: 2.0286 - val_acc: 0.3497\n",
            "Epoch 540/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0585 - acc: 0.3503 - val_loss: 2.1072 - val_acc: 0.3129\n",
            "Epoch 541/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0285 - acc: 0.3178 - val_loss: 1.9693 - val_acc: 0.3436\n",
            "Epoch 542/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0169 - acc: 0.3319 - val_loss: 2.0566 - val_acc: 0.3129\n",
            "Epoch 543/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.0277 - acc: 0.3416 - val_loss: 2.0290 - val_acc: 0.3313\n",
            "Epoch 544/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.0154 - acc: 0.3384 - val_loss: 1.9865 - val_acc: 0.3558\n",
            "Epoch 545/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0700 - acc: 0.3243 - val_loss: 2.0099 - val_acc: 0.3190\n",
            "Epoch 546/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0727 - acc: 0.3395 - val_loss: 2.0187 - val_acc: 0.3436\n",
            "Epoch 547/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0073 - acc: 0.3492 - val_loss: 2.0305 - val_acc: 0.3129\n",
            "Epoch 548/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0028 - acc: 0.3438 - val_loss: 1.9758 - val_acc: 0.3313\n",
            "Epoch 549/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.9742 - acc: 0.3525 - val_loss: 2.0461 - val_acc: 0.3190\n",
            "Epoch 550/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9999 - acc: 0.3384 - val_loss: 1.9829 - val_acc: 0.3129\n",
            "Epoch 551/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9357 - acc: 0.3547 - val_loss: 1.9827 - val_acc: 0.3190\n",
            "Epoch 552/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9841 - acc: 0.3579 - val_loss: 1.9321 - val_acc: 0.3558\n",
            "Epoch 553/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9778 - acc: 0.3644 - val_loss: 1.9510 - val_acc: 0.3558\n",
            "Epoch 554/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9677 - acc: 0.3373 - val_loss: 1.9773 - val_acc: 0.3190\n",
            "Epoch 555/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9916 - acc: 0.3308 - val_loss: 2.0176 - val_acc: 0.3620\n",
            "Epoch 556/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0495 - acc: 0.3492 - val_loss: 2.0292 - val_acc: 0.3067\n",
            "Epoch 557/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1086 - acc: 0.3200 - val_loss: 1.9910 - val_acc: 0.3436\n",
            "Epoch 558/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.0480 - acc: 0.3351 - val_loss: 2.0872 - val_acc: 0.2945\n",
            "Epoch 559/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0200 - acc: 0.3384 - val_loss: 2.0273 - val_acc: 0.3313\n",
            "Epoch 560/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0048 - acc: 0.3330 - val_loss: 2.0510 - val_acc: 0.3006\n",
            "Epoch 561/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9756 - acc: 0.3406 - val_loss: 1.9798 - val_acc: 0.3313\n",
            "Epoch 562/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9255 - acc: 0.3644 - val_loss: 1.9373 - val_acc: 0.3558\n",
            "Epoch 563/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9425 - acc: 0.3601 - val_loss: 1.9818 - val_acc: 0.3558\n",
            "Epoch 564/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9140 - acc: 0.3601 - val_loss: 1.9435 - val_acc: 0.3620\n",
            "Epoch 565/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9575 - acc: 0.3427 - val_loss: 1.9912 - val_acc: 0.3497\n",
            "Epoch 566/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9971 - acc: 0.3265 - val_loss: 1.9721 - val_acc: 0.3558\n",
            "Epoch 567/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9787 - acc: 0.3449 - val_loss: 1.9518 - val_acc: 0.3497\n",
            "Epoch 568/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9376 - acc: 0.3492 - val_loss: 1.9749 - val_acc: 0.3374\n",
            "Epoch 569/800\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.9764 - acc: 0.3384 - val_loss: 1.9933 - val_acc: 0.3252\n",
            "Epoch 570/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9315 - acc: 0.3601 - val_loss: 2.0247 - val_acc: 0.3006\n",
            "Epoch 571/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9925 - acc: 0.3590 - val_loss: 1.9141 - val_acc: 0.3620\n",
            "Epoch 572/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9272 - acc: 0.3416 - val_loss: 1.9792 - val_acc: 0.3067\n",
            "Epoch 573/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9407 - acc: 0.3514 - val_loss: 2.0112 - val_acc: 0.3129\n",
            "Epoch 574/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9392 - acc: 0.3406 - val_loss: 1.9630 - val_acc: 0.3129\n",
            "Epoch 575/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9453 - acc: 0.3655 - val_loss: 1.9788 - val_acc: 0.3252\n",
            "Epoch 576/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9429 - acc: 0.3677 - val_loss: 2.0040 - val_acc: 0.3313\n",
            "Epoch 577/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9816 - acc: 0.3514 - val_loss: 1.9444 - val_acc: 0.3190\n",
            "Epoch 578/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9736 - acc: 0.3373 - val_loss: 1.9574 - val_acc: 0.3252\n",
            "Epoch 579/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9401 - acc: 0.3547 - val_loss: 1.9847 - val_acc: 0.3497\n",
            "Epoch 580/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9161 - acc: 0.3720 - val_loss: 1.9534 - val_acc: 0.3067\n",
            "Epoch 581/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9158 - acc: 0.3655 - val_loss: 1.9502 - val_acc: 0.3313\n",
            "Epoch 582/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9140 - acc: 0.3612 - val_loss: 1.9109 - val_acc: 0.4049\n",
            "Epoch 583/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8974 - acc: 0.3677 - val_loss: 1.9637 - val_acc: 0.3436\n",
            "Epoch 584/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8860 - acc: 0.3785 - val_loss: 1.9231 - val_acc: 0.3804\n",
            "Epoch 585/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8974 - acc: 0.3915 - val_loss: 1.9704 - val_acc: 0.3558\n",
            "Epoch 586/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9149 - acc: 0.3742 - val_loss: 1.9077 - val_acc: 0.3558\n",
            "Epoch 587/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8720 - acc: 0.3829 - val_loss: 1.9564 - val_acc: 0.3374\n",
            "Epoch 588/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9169 - acc: 0.3601 - val_loss: 1.8873 - val_acc: 0.3497\n",
            "Epoch 589/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8792 - acc: 0.3720 - val_loss: 1.9506 - val_acc: 0.3558\n",
            "Epoch 590/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8843 - acc: 0.3915 - val_loss: 1.9826 - val_acc: 0.3497\n",
            "Epoch 591/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9095 - acc: 0.3623 - val_loss: 1.9128 - val_acc: 0.3742\n",
            "Epoch 592/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9125 - acc: 0.3926 - val_loss: 1.9768 - val_acc: 0.3313\n",
            "Epoch 593/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9080 - acc: 0.3720 - val_loss: 1.9280 - val_acc: 0.3558\n",
            "Epoch 594/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9823 - acc: 0.3406 - val_loss: 1.9329 - val_acc: 0.3742\n",
            "Epoch 595/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9539 - acc: 0.3579 - val_loss: 1.9610 - val_acc: 0.3620\n",
            "Epoch 596/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9258 - acc: 0.3785 - val_loss: 1.9494 - val_acc: 0.3436\n",
            "Epoch 597/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8973 - acc: 0.3688 - val_loss: 1.9415 - val_acc: 0.3558\n",
            "Epoch 598/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9421 - acc: 0.3579 - val_loss: 1.8822 - val_acc: 0.3742\n",
            "Epoch 599/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9201 - acc: 0.3547 - val_loss: 1.9305 - val_acc: 0.3681\n",
            "Epoch 600/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9029 - acc: 0.3633 - val_loss: 1.9213 - val_acc: 0.3497\n",
            "Epoch 601/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9066 - acc: 0.3536 - val_loss: 1.8774 - val_acc: 0.3804\n",
            "Epoch 602/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9065 - acc: 0.3829 - val_loss: 1.8882 - val_acc: 0.3865\n",
            "Epoch 603/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9136 - acc: 0.3774 - val_loss: 1.8664 - val_acc: 0.3558\n",
            "Epoch 604/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8765 - acc: 0.3698 - val_loss: 1.9652 - val_acc: 0.3252\n",
            "Epoch 605/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8671 - acc: 0.3753 - val_loss: 1.8713 - val_acc: 0.3865\n",
            "Epoch 606/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8786 - acc: 0.3818 - val_loss: 1.8896 - val_acc: 0.3926\n",
            "Epoch 607/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9309 - acc: 0.3698 - val_loss: 1.8801 - val_acc: 0.3865\n",
            "Epoch 608/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8614 - acc: 0.3807 - val_loss: 1.8709 - val_acc: 0.3988\n",
            "Epoch 609/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8591 - acc: 0.3655 - val_loss: 1.9235 - val_acc: 0.3742\n",
            "Epoch 610/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8597 - acc: 0.3861 - val_loss: 1.9154 - val_acc: 0.3681\n",
            "Epoch 611/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8777 - acc: 0.3829 - val_loss: 1.8637 - val_acc: 0.3865\n",
            "Epoch 612/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9505 - acc: 0.3590 - val_loss: 1.9222 - val_acc: 0.3620\n",
            "Epoch 613/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0398 - acc: 0.3362 - val_loss: 1.9798 - val_acc: 0.3804\n",
            "Epoch 614/800\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.0328 - acc: 0.3395 - val_loss: 1.9923 - val_acc: 0.3620\n",
            "Epoch 615/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8718 - acc: 0.3915 - val_loss: 1.8710 - val_acc: 0.3926\n",
            "Epoch 616/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8503 - acc: 0.3818 - val_loss: 1.8616 - val_acc: 0.4110\n",
            "Epoch 617/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8538 - acc: 0.3861 - val_loss: 1.8393 - val_acc: 0.3988\n",
            "Epoch 618/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8726 - acc: 0.3698 - val_loss: 1.8467 - val_acc: 0.3988\n",
            "Epoch 619/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9450 - acc: 0.3362 - val_loss: 1.8369 - val_acc: 0.3620\n",
            "Epoch 620/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8904 - acc: 0.3731 - val_loss: 1.9357 - val_acc: 0.3865\n",
            "Epoch 621/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8850 - acc: 0.3872 - val_loss: 1.9367 - val_acc: 0.3436\n",
            "Epoch 622/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8809 - acc: 0.3829 - val_loss: 1.8651 - val_acc: 0.3988\n",
            "Epoch 623/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8399 - acc: 0.4035 - val_loss: 1.8517 - val_acc: 0.3804\n",
            "Epoch 624/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8593 - acc: 0.3796 - val_loss: 1.8244 - val_acc: 0.3742\n",
            "Epoch 625/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8554 - acc: 0.3850 - val_loss: 1.8839 - val_acc: 0.4110\n",
            "Epoch 626/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8416 - acc: 0.3894 - val_loss: 1.8719 - val_acc: 0.3804\n",
            "Epoch 627/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8377 - acc: 0.3970 - val_loss: 1.9243 - val_acc: 0.3742\n",
            "Epoch 628/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8006 - acc: 0.3926 - val_loss: 1.8765 - val_acc: 0.4172\n",
            "Epoch 629/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8809 - acc: 0.3872 - val_loss: 1.9192 - val_acc: 0.3436\n",
            "Epoch 630/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.9259 - acc: 0.3503 - val_loss: 2.0213 - val_acc: 0.3620\n",
            "Epoch 631/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9410 - acc: 0.3579 - val_loss: 1.9663 - val_acc: 0.3313\n",
            "Epoch 632/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9138 - acc: 0.3579 - val_loss: 1.9256 - val_acc: 0.3865\n",
            "Epoch 633/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8715 - acc: 0.3829 - val_loss: 1.8461 - val_acc: 0.3742\n",
            "Epoch 634/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8108 - acc: 0.4002 - val_loss: 1.8567 - val_acc: 0.3926\n",
            "Epoch 635/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8266 - acc: 0.3818 - val_loss: 1.8735 - val_acc: 0.3804\n",
            "Epoch 636/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7746 - acc: 0.4165 - val_loss: 1.8494 - val_acc: 0.4172\n",
            "Epoch 637/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7755 - acc: 0.4132 - val_loss: 1.8123 - val_acc: 0.4356\n",
            "Epoch 638/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8070 - acc: 0.3742 - val_loss: 1.8065 - val_acc: 0.4110\n",
            "Epoch 639/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7869 - acc: 0.3970 - val_loss: 1.7996 - val_acc: 0.4172\n",
            "Epoch 640/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8218 - acc: 0.3905 - val_loss: 2.0028 - val_acc: 0.3436\n",
            "Epoch 641/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8202 - acc: 0.3926 - val_loss: 1.9246 - val_acc: 0.3620\n",
            "Epoch 642/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8441 - acc: 0.3991 - val_loss: 1.9792 - val_acc: 0.3497\n",
            "Epoch 643/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8454 - acc: 0.3731 - val_loss: 1.8268 - val_acc: 0.3988\n",
            "Epoch 644/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8338 - acc: 0.3709 - val_loss: 1.8452 - val_acc: 0.4049\n",
            "Epoch 645/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8259 - acc: 0.3861 - val_loss: 1.8040 - val_acc: 0.4049\n",
            "Epoch 646/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7932 - acc: 0.4013 - val_loss: 1.8714 - val_acc: 0.4233\n",
            "Epoch 647/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8466 - acc: 0.3796 - val_loss: 1.8712 - val_acc: 0.3804\n",
            "Epoch 648/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8384 - acc: 0.3926 - val_loss: 1.8945 - val_acc: 0.3988\n",
            "Epoch 649/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8178 - acc: 0.3980 - val_loss: 1.8242 - val_acc: 0.3926\n",
            "Epoch 650/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8350 - acc: 0.4013 - val_loss: 1.8112 - val_acc: 0.3865\n",
            "Epoch 651/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8242 - acc: 0.3861 - val_loss: 1.8445 - val_acc: 0.4356\n",
            "Epoch 652/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8070 - acc: 0.4002 - val_loss: 1.8486 - val_acc: 0.3926\n",
            "Epoch 653/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7776 - acc: 0.3948 - val_loss: 1.8821 - val_acc: 0.3926\n",
            "Epoch 654/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7740 - acc: 0.4024 - val_loss: 1.8298 - val_acc: 0.3926\n",
            "Epoch 655/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7392 - acc: 0.4024 - val_loss: 1.8466 - val_acc: 0.4110\n",
            "Epoch 656/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7570 - acc: 0.3959 - val_loss: 1.7934 - val_acc: 0.4356\n",
            "Epoch 657/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7724 - acc: 0.4154 - val_loss: 1.8292 - val_acc: 0.3988\n",
            "Epoch 658/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8068 - acc: 0.4046 - val_loss: 1.8409 - val_acc: 0.3926\n",
            "Epoch 659/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8096 - acc: 0.4100 - val_loss: 1.8303 - val_acc: 0.3988\n",
            "Epoch 660/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7779 - acc: 0.4002 - val_loss: 1.7907 - val_acc: 0.3804\n",
            "Epoch 661/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7494 - acc: 0.4056 - val_loss: 1.8280 - val_acc: 0.3988\n",
            "Epoch 662/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7919 - acc: 0.3991 - val_loss: 1.8968 - val_acc: 0.4110\n",
            "Epoch 663/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7732 - acc: 0.3959 - val_loss: 1.8947 - val_acc: 0.3988\n",
            "Epoch 664/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8265 - acc: 0.3839 - val_loss: 1.8469 - val_acc: 0.3865\n",
            "Epoch 665/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7745 - acc: 0.4121 - val_loss: 1.8589 - val_acc: 0.3988\n",
            "Epoch 666/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7612 - acc: 0.3905 - val_loss: 1.7773 - val_acc: 0.4294\n",
            "Epoch 667/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7550 - acc: 0.3905 - val_loss: 1.7965 - val_acc: 0.3988\n",
            "Epoch 668/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7849 - acc: 0.3883 - val_loss: 1.8018 - val_acc: 0.3742\n",
            "Epoch 669/800\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7211 - acc: 0.4078 - val_loss: 1.7845 - val_acc: 0.4233\n",
            "Epoch 670/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8144 - acc: 0.3872 - val_loss: 1.8888 - val_acc: 0.4110\n",
            "Epoch 671/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8060 - acc: 0.3905 - val_loss: 1.8322 - val_acc: 0.3558\n",
            "Epoch 672/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7853 - acc: 0.4111 - val_loss: 1.8652 - val_acc: 0.4233\n",
            "Epoch 673/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7896 - acc: 0.3894 - val_loss: 1.8835 - val_acc: 0.4110\n",
            "Epoch 674/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7565 - acc: 0.4165 - val_loss: 1.9223 - val_acc: 0.3804\n",
            "Epoch 675/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7792 - acc: 0.3970 - val_loss: 1.8042 - val_acc: 0.4172\n",
            "Epoch 676/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7518 - acc: 0.4078 - val_loss: 1.8626 - val_acc: 0.3804\n",
            "Epoch 677/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7820 - acc: 0.4013 - val_loss: 1.7972 - val_acc: 0.4049\n",
            "Epoch 678/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7845 - acc: 0.3959 - val_loss: 1.8754 - val_acc: 0.3804\n",
            "Epoch 679/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7664 - acc: 0.4046 - val_loss: 1.9038 - val_acc: 0.3988\n",
            "Epoch 680/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7709 - acc: 0.4154 - val_loss: 1.8622 - val_acc: 0.3804\n",
            "Epoch 681/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7447 - acc: 0.4176 - val_loss: 1.8728 - val_acc: 0.3988\n",
            "Epoch 682/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8383 - acc: 0.4176 - val_loss: 1.8758 - val_acc: 0.3804\n",
            "Epoch 683/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7833 - acc: 0.4067 - val_loss: 1.8240 - val_acc: 0.4294\n",
            "Epoch 684/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8451 - acc: 0.4035 - val_loss: 1.9070 - val_acc: 0.3374\n",
            "Epoch 685/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8161 - acc: 0.4121 - val_loss: 1.8633 - val_acc: 0.3865\n",
            "Epoch 686/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7399 - acc: 0.4121 - val_loss: 1.8213 - val_acc: 0.3988\n",
            "Epoch 687/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6937 - acc: 0.4208 - val_loss: 1.8483 - val_acc: 0.3804\n",
            "Epoch 688/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7267 - acc: 0.4295 - val_loss: 1.7598 - val_acc: 0.4172\n",
            "Epoch 689/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7156 - acc: 0.4197 - val_loss: 1.8210 - val_acc: 0.3926\n",
            "Epoch 690/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7234 - acc: 0.4187 - val_loss: 1.8387 - val_acc: 0.3865\n",
            "Epoch 691/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7775 - acc: 0.4089 - val_loss: 1.8283 - val_acc: 0.3988\n",
            "Epoch 692/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6835 - acc: 0.4208 - val_loss: 1.8336 - val_acc: 0.4233\n",
            "Epoch 693/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7300 - acc: 0.4165 - val_loss: 1.8193 - val_acc: 0.3742\n",
            "Epoch 694/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7536 - acc: 0.4002 - val_loss: 1.8567 - val_acc: 0.3742\n",
            "Epoch 695/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6784 - acc: 0.4132 - val_loss: 1.8575 - val_acc: 0.3865\n",
            "Epoch 696/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7160 - acc: 0.4252 - val_loss: 1.8386 - val_acc: 0.3988\n",
            "Epoch 697/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7237 - acc: 0.3991 - val_loss: 1.8816 - val_acc: 0.4049\n",
            "Epoch 698/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7608 - acc: 0.3970 - val_loss: 1.8851 - val_acc: 0.3804\n",
            "Epoch 699/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6917 - acc: 0.4089 - val_loss: 1.8563 - val_acc: 0.3865\n",
            "Epoch 700/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6766 - acc: 0.4284 - val_loss: 1.8189 - val_acc: 0.3988\n",
            "Epoch 701/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6816 - acc: 0.4187 - val_loss: 1.8680 - val_acc: 0.3926\n",
            "Epoch 702/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7487 - acc: 0.4154 - val_loss: 1.8105 - val_acc: 0.3988\n",
            "Epoch 703/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7135 - acc: 0.4111 - val_loss: 1.9122 - val_acc: 0.3620\n",
            "Epoch 704/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7816 - acc: 0.3980 - val_loss: 1.8620 - val_acc: 0.4172\n",
            "Epoch 705/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7991 - acc: 0.3959 - val_loss: 1.8377 - val_acc: 0.4233\n",
            "Epoch 706/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7259 - acc: 0.4111 - val_loss: 1.8213 - val_acc: 0.4233\n",
            "Epoch 707/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6846 - acc: 0.4230 - val_loss: 1.8521 - val_acc: 0.3804\n",
            "Epoch 708/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6813 - acc: 0.4208 - val_loss: 1.8417 - val_acc: 0.4233\n",
            "Epoch 709/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6912 - acc: 0.4154 - val_loss: 1.9021 - val_acc: 0.3804\n",
            "Epoch 710/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7570 - acc: 0.4078 - val_loss: 1.9332 - val_acc: 0.3926\n",
            "Epoch 711/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7660 - acc: 0.3937 - val_loss: 1.9849 - val_acc: 0.3681\n",
            "Epoch 712/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7773 - acc: 0.4208 - val_loss: 1.8482 - val_acc: 0.3988\n",
            "Epoch 713/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7809 - acc: 0.4024 - val_loss: 1.8439 - val_acc: 0.3926\n",
            "Epoch 714/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7500 - acc: 0.4013 - val_loss: 1.8404 - val_acc: 0.3804\n",
            "Epoch 715/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7617 - acc: 0.4013 - val_loss: 1.8019 - val_acc: 0.4172\n",
            "Epoch 716/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7575 - acc: 0.4024 - val_loss: 1.8502 - val_acc: 0.3804\n",
            "Epoch 717/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7457 - acc: 0.4100 - val_loss: 1.8350 - val_acc: 0.3865\n",
            "Epoch 718/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7424 - acc: 0.4078 - val_loss: 1.8429 - val_acc: 0.3865\n",
            "Epoch 719/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7283 - acc: 0.4024 - val_loss: 1.9094 - val_acc: 0.3374\n",
            "Epoch 720/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7507 - acc: 0.3905 - val_loss: 1.8392 - val_acc: 0.3620\n",
            "Epoch 721/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6894 - acc: 0.4262 - val_loss: 1.8159 - val_acc: 0.3865\n",
            "Epoch 722/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7145 - acc: 0.4111 - val_loss: 1.8975 - val_acc: 0.3620\n",
            "Epoch 723/800\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.6780 - acc: 0.4317 - val_loss: 1.8557 - val_acc: 0.3804\n",
            "Epoch 724/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7169 - acc: 0.4165 - val_loss: 1.7338 - val_acc: 0.4294\n",
            "Epoch 725/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6879 - acc: 0.4078 - val_loss: 1.7972 - val_acc: 0.4049\n",
            "Epoch 726/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6987 - acc: 0.4143 - val_loss: 1.8487 - val_acc: 0.3681\n",
            "Epoch 727/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7273 - acc: 0.4165 - val_loss: 1.7765 - val_acc: 0.4172\n",
            "Epoch 728/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7386 - acc: 0.4165 - val_loss: 1.8698 - val_acc: 0.3988\n",
            "Epoch 729/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7628 - acc: 0.4132 - val_loss: 1.8221 - val_acc: 0.4110\n",
            "Epoch 730/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7238 - acc: 0.4187 - val_loss: 1.8338 - val_acc: 0.3926\n",
            "Epoch 731/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7592 - acc: 0.4056 - val_loss: 1.8413 - val_acc: 0.4356\n",
            "Epoch 732/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7789 - acc: 0.4100 - val_loss: 1.9659 - val_acc: 0.4110\n",
            "Epoch 733/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7686 - acc: 0.4208 - val_loss: 1.8406 - val_acc: 0.4356\n",
            "Epoch 734/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7309 - acc: 0.4056 - val_loss: 1.8215 - val_acc: 0.4417\n",
            "Epoch 735/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7270 - acc: 0.4089 - val_loss: 1.8587 - val_acc: 0.4172\n",
            "Epoch 736/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7196 - acc: 0.4360 - val_loss: 1.8439 - val_acc: 0.3865\n",
            "Epoch 737/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7294 - acc: 0.4262 - val_loss: 1.8825 - val_acc: 0.4233\n",
            "Epoch 738/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7191 - acc: 0.4197 - val_loss: 1.8707 - val_acc: 0.4356\n",
            "Epoch 739/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7267 - acc: 0.4024 - val_loss: 1.8574 - val_acc: 0.3988\n",
            "Epoch 740/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6974 - acc: 0.4067 - val_loss: 1.8086 - val_acc: 0.4294\n",
            "Epoch 741/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7488 - acc: 0.4013 - val_loss: 1.8503 - val_acc: 0.3926\n",
            "Epoch 742/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6454 - acc: 0.4317 - val_loss: 1.8725 - val_acc: 0.3865\n",
            "Epoch 743/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6718 - acc: 0.4219 - val_loss: 1.8795 - val_acc: 0.3804\n",
            "Epoch 744/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6905 - acc: 0.4230 - val_loss: 1.7982 - val_acc: 0.4233\n",
            "Epoch 745/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7077 - acc: 0.4121 - val_loss: 1.8892 - val_acc: 0.3742\n",
            "Epoch 746/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7129 - acc: 0.4208 - val_loss: 1.7914 - val_acc: 0.3926\n",
            "Epoch 747/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6661 - acc: 0.4436 - val_loss: 1.9536 - val_acc: 0.4110\n",
            "Epoch 748/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6574 - acc: 0.4306 - val_loss: 1.8997 - val_acc: 0.4049\n",
            "Epoch 749/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7152 - acc: 0.4176 - val_loss: 1.8058 - val_acc: 0.4172\n",
            "Epoch 750/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6938 - acc: 0.4230 - val_loss: 1.8744 - val_acc: 0.4049\n",
            "Epoch 751/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7302 - acc: 0.4187 - val_loss: 1.8744 - val_acc: 0.3681\n",
            "Epoch 752/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6816 - acc: 0.4414 - val_loss: 1.8339 - val_acc: 0.4110\n",
            "Epoch 753/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6742 - acc: 0.4165 - val_loss: 1.8476 - val_acc: 0.3926\n",
            "Epoch 754/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6508 - acc: 0.4252 - val_loss: 1.9210 - val_acc: 0.3865\n",
            "Epoch 755/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7294 - acc: 0.4165 - val_loss: 1.9231 - val_acc: 0.3620\n",
            "Epoch 756/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6614 - acc: 0.4262 - val_loss: 1.7958 - val_acc: 0.4233\n",
            "Epoch 757/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7056 - acc: 0.4295 - val_loss: 1.7986 - val_acc: 0.4172\n",
            "Epoch 758/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7078 - acc: 0.4284 - val_loss: 1.7948 - val_acc: 0.4233\n",
            "Epoch 759/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6458 - acc: 0.4338 - val_loss: 1.8420 - val_acc: 0.4110\n",
            "Epoch 760/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6608 - acc: 0.4273 - val_loss: 1.8363 - val_acc: 0.4356\n",
            "Epoch 761/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6742 - acc: 0.4197 - val_loss: 1.8787 - val_acc: 0.4294\n",
            "Epoch 762/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6457 - acc: 0.4165 - val_loss: 1.7934 - val_acc: 0.3926\n",
            "Epoch 763/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6735 - acc: 0.4382 - val_loss: 1.9695 - val_acc: 0.3742\n",
            "Epoch 764/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6669 - acc: 0.4208 - val_loss: 1.7875 - val_acc: 0.4172\n",
            "Epoch 765/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6552 - acc: 0.4295 - val_loss: 1.7900 - val_acc: 0.4172\n",
            "Epoch 766/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6746 - acc: 0.4143 - val_loss: 1.8773 - val_acc: 0.3681\n",
            "Epoch 767/800\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6376 - acc: 0.4360 - val_loss: 1.9336 - val_acc: 0.3988\n",
            "Epoch 768/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6337 - acc: 0.4349 - val_loss: 1.8510 - val_acc: 0.4356\n",
            "Epoch 769/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6251 - acc: 0.4317 - val_loss: 1.9061 - val_acc: 0.4110\n",
            "Epoch 770/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6114 - acc: 0.4414 - val_loss: 1.8476 - val_acc: 0.4172\n",
            "Epoch 771/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6900 - acc: 0.4230 - val_loss: 1.8246 - val_acc: 0.4233\n",
            "Epoch 772/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6501 - acc: 0.4382 - val_loss: 1.9220 - val_acc: 0.4172\n",
            "Epoch 773/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6919 - acc: 0.4328 - val_loss: 1.8873 - val_acc: 0.3558\n",
            "Epoch 774/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6985 - acc: 0.4165 - val_loss: 1.8614 - val_acc: 0.3804\n",
            "Epoch 775/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6108 - acc: 0.4100 - val_loss: 1.8169 - val_acc: 0.4233\n",
            "Epoch 776/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6122 - acc: 0.4393 - val_loss: 1.8666 - val_acc: 0.3926\n",
            "Epoch 777/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6647 - acc: 0.4035 - val_loss: 1.8419 - val_acc: 0.3926\n",
            "Epoch 778/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6631 - acc: 0.4338 - val_loss: 1.8692 - val_acc: 0.4417\n",
            "Epoch 779/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6796 - acc: 0.4241 - val_loss: 1.9716 - val_acc: 0.4356\n",
            "Epoch 780/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7005 - acc: 0.4284 - val_loss: 1.9147 - val_acc: 0.3865\n",
            "Epoch 781/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6825 - acc: 0.4208 - val_loss: 1.8190 - val_acc: 0.3988\n",
            "Epoch 782/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6649 - acc: 0.4425 - val_loss: 1.8057 - val_acc: 0.3865\n",
            "Epoch 783/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6490 - acc: 0.4338 - val_loss: 1.9256 - val_acc: 0.4172\n",
            "Epoch 784/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5947 - acc: 0.4469 - val_loss: 1.9575 - val_acc: 0.4049\n",
            "Epoch 785/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6598 - acc: 0.4382 - val_loss: 1.9170 - val_acc: 0.3926\n",
            "Epoch 786/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5845 - acc: 0.4371 - val_loss: 1.8243 - val_acc: 0.4417\n",
            "Epoch 787/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6512 - acc: 0.4046 - val_loss: 1.8232 - val_acc: 0.4049\n",
            "Epoch 788/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6475 - acc: 0.4284 - val_loss: 1.9221 - val_acc: 0.3742\n",
            "Epoch 789/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6562 - acc: 0.4382 - val_loss: 1.9979 - val_acc: 0.3436\n",
            "Epoch 790/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6667 - acc: 0.4208 - val_loss: 1.9033 - val_acc: 0.4294\n",
            "Epoch 791/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6120 - acc: 0.4534 - val_loss: 1.8356 - val_acc: 0.3926\n",
            "Epoch 792/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6271 - acc: 0.4512 - val_loss: 1.8105 - val_acc: 0.4049\n",
            "Epoch 793/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6424 - acc: 0.4284 - val_loss: 1.7787 - val_acc: 0.4172\n",
            "Epoch 794/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6950 - acc: 0.4241 - val_loss: 1.8472 - val_acc: 0.3988\n",
            "Epoch 795/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6637 - acc: 0.4328 - val_loss: 1.9049 - val_acc: 0.3681\n",
            "Epoch 796/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6474 - acc: 0.4555 - val_loss: 1.8299 - val_acc: 0.4172\n",
            "Epoch 797/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6179 - acc: 0.4490 - val_loss: 1.9505 - val_acc: 0.3742\n",
            "Epoch 798/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6302 - acc: 0.4436 - val_loss: 1.9026 - val_acc: 0.3865\n",
            "Epoch 799/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6550 - acc: 0.4436 - val_loss: 1.9225 - val_acc: 0.4294\n",
            "Epoch 800/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6352 - acc: 0.4414 - val_loss: 1.9114 - val_acc: 0.4110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1h9jelike7x"
      },
      "source": [
        "## Summarize model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehU85QNcDH8A",
        "outputId": "a11b3b79-2b35-441d-d53e-70880ff2c64e"
      },
      "source": [
        "model.summary()\n",
        "get_test_accuracy(model, test_data, test_targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 200)               60200     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 24)                3096      \n",
            "=================================================================\n",
            "Total params: 185,936\n",
            "Trainable params: 185,936\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test Accuracy: 0.379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3JjHtTsXFz2P",
        "outputId": "e4bd4473-57af-40b9-e487-430929b01aea"
      },
      "source": [
        "plt.clf()\n",
        "try:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EN60xiZ54w5"
      },
      "source": [
        "## Mapper Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bpAM87f6LeO"
      },
      "source": [
        "import sklearn\n",
        "import kmapper as km"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5EA0sfQE4z0"
      },
      "source": [
        "file = os.listdir(\"./SCOP40mini\")[10]\n",
        "\n",
        "structure_id = os.path.splitext(file)[0]\n",
        "structure = parser.get_structure(structure_id, \"./SCOP40mini/\" + file)\n",
        "\n",
        "# We grab the SCOP sccs to build the classes\n",
        "sccs = parser.get_header()['astral']['SCOP-sccs']\n",
        "fold = sccs.rsplit('.', 2)[0]\n",
        "superfamily = sccs.rsplit('.', 1)[0]\n",
        "family = sccs\n",
        "\n",
        "# Generate a list of its atoms' coordinates in R^3\n",
        "coords = []\n",
        "for atom in structure.get_atoms():\n",
        "    coords.append(list(atom.get_vector()))\n",
        "coords = np.array(coords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Eax_ti8E650",
        "outputId": "48014ee6-d724-4be0-953b-63a754024f40"
      },
      "source": [
        "mapper = km.KeplerMapper(verbose=2)\n",
        "lens = mapper.fit_transform(coords)\n",
        "\n",
        "graph = mapper.map(\n",
        "    lens,\n",
        "    coords,\n",
        "    clusterer=sklearn.cluster.DBSCAN(eps=0.2, min_samples=1),\n",
        "    cover=km.Cover(5, 0.7),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KeplerMapper(verbose=2)\n",
            "..Composing projection pipeline of length 1:\n",
            "\tProjections: sum\n",
            "\tDistance matrices: False\n",
            "\tScalers: MinMaxScaler(copy=True, feature_range=(0, 1))\n",
            "..Projecting on data shaped (1253, 3)\n",
            "\n",
            "..Projecting data using: sum\n",
            "\n",
            "..Scaling with: MinMaxScaler(copy=True, feature_range=(0, 1))\n",
            "\n",
            "Mapping on data shaped (1253, 3) using lens shaped (1253, 1)\n",
            "\n",
            "Minimal points in hypercube before clustering: 1\n",
            "Creating 5 hypercubes.\n",
            "   > Found 524 clusters in hypercube 0.\n",
            "   > Found 808 clusters in hypercube 1.\n",
            "   > Found 1078 clusters in hypercube 2.\n",
            "   > Found 884 clusters in hypercube 3.\n",
            "   > Found 540 clusters in hypercube 4.\n",
            "\n",
            "Created 4159 edges and 3834 nodes in 0:00:04.936415.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQJn7eTbE9mx",
        "outputId": "f29e1dfb-f3c3-48a9-b54f-8834f43bec67"
      },
      "source": [
        "mapper.visualize(\n",
        "    graph, path_html=\"atom.html\", custom_tooltips=np.arange(len(lens))\n",
        ")\n",
        "km.drawing.draw_matplotlib(graph)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote visualization to: atom.html\n",
            "no display found. Using non-interactive Agg backend\n"
          ]
        }
      ]
    }
  ]
}